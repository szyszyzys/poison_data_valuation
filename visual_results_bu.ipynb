{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-15T23:39:37.577236800Z",
     "start_time": "2025-05-15T23:39:37.323088800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preprocessing summary_avg.csv ---\n",
      "Column 'ATTACK_METHOD' before mapping. Unique values (as str): ['single', 'nan']\n",
      "Column 'ATTACK_METHOD' mapped. New unique values: ['Data Poison' 'No Attack']\n",
      "Warning: Column 'attack_objective' for categorical mapping not found in DataFrame.\n",
      "Column 'AGGREGATION_METHOD' before mapping. Unique values (as str): ['martfl']\n",
      "Column 'AGGREGATION_METHOD' mapped. New unique values: ['MartFL']\n",
      "Column 'IS_SYBIL' before mapping. Unique values (as str): ['False', 'mimic']\n",
      "Column 'IS_SYBIL' mapped. New unique values: ['False' 'mimic']\n",
      "Processing float column: ADV_RATE with precision 1\n",
      "  Column 'ADV_RATE' rounded. NaNs after rounding: 0\n",
      "Processing float column: discovery_quality with precision 1\n",
      "  Column 'discovery_quality' rounded. NaNs after rounding: 0\n",
      "Processing float column: FINAL_MAIN_ACC with precision 4\n",
      "  Column 'FINAL_MAIN_ACC' rounded. NaNs after rounding: 0\n",
      "Processing float column: FINAL_ASR with precision 4\n",
      "  Column 'FINAL_ASR' rounded. NaNs after rounding: 0\n",
      "Processing float column: PAYMENT_GINI_COEFFICIENT with precision 3\n",
      "  Column 'PAYMENT_GINI_COEFFICIENT' rounded. NaNs after rounding: 0\n",
      "Processing float column: AVG_BENIGN_PAYMENT_GINI with precision 3\n",
      "  Column 'AVG_BENIGN_PAYMENT_GINI' rounded. NaNs after rounding: 0\n",
      "Processing float column: AVG_ADVERSARY_SELECTION_RATE with precision 3\n",
      "  Column 'AVG_ADVERSARY_SELECTION_RATE' rounded. NaNs after rounding: 0\n",
      "Processing float column: AVG_BENIGN_SELLER_SELECTION_RATE with precision 3\n",
      "  Column 'AVG_BENIGN_SELLER_SELECTION_RATE' rounded. NaNs after rounding: 0\n",
      "Processing float column: AVG_COST_PER_ROUND with precision 2\n",
      "  Column 'AVG_COST_PER_ROUND' rounded. NaNs after rounding: 0\n",
      "Processing float column: COST_OF_CONVERGENCE with precision 0\n",
      "  Column 'COST_OF_CONVERGENCE' rounded. NaNs after rounding: 33\n",
      "Processing float column: TOTAL_COST with precision 0\n",
      "  Column 'TOTAL_COST' rounded. NaNs after rounding: 0\n",
      "Processing float column: NO_ATTACK_DESIG_MAL_SEL_RATE_0.1 with precision 3\n",
      "  Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1' rounded. NaNs after rounding: 90\n",
      "Processing float column: NO_ATTACK_DESIG_MAL_SEL_RATE_0.2 with precision 3\n",
      "  Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2' rounded. NaNs after rounding: 90\n",
      "Processing float column: NO_ATTACK_DESIG_MAL_SEL_RATE_0.3 with precision 3\n",
      "  Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3' rounded. NaNs after rounding: 90\n",
      "Processing float column: NO_ATTACK_DESIG_MAL_SEL_RATE_0.4 with precision 3\n",
      "  Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4' rounded. NaNs after rounding: 90\n",
      "Warning: Column 'AVG_COST_PER_ROUND_BENIGN' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_COST_PER_ROUND_MALICIOUS' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Set ADV_RATE to 0.0 for 'No Attack' scenarios.\n",
      "Deriving cost composition (benign/malicious) from AVG_COST_PER_ROUND and AVG_ADVERSARY_SELECTION_RATE.\n",
      "Derived and processed cost composition columns.\n",
      "Processed summary_df_avg shape: (186, 48)\n",
      "\n",
      "First 5 rows of processed summary_df_avg (after potential derivation):\n"
     ]
    },
    {
     "data": {
      "text/plain": "   run AGGREGATION_METHOD DATA_SPLIT_MODE  discovery_quality buyer_data_mode  \\\n0    2             MartFL       discovery                0.1          random   \n1    9             MartFL       discovery                0.1          biased   \n2    3             MartFL       discovery                1.0          random   \n3    9             MartFL       discovery                1.0          biased   \n4    0             MartFL       discovery               10.0          random   \n\n   N_CLIENTS ATTACK_METHOD  TRIGGER_RATE IS_SYBIL  ADV_RATE  ...  \\\n0       30.0   Data Poison           0.1    False       0.2  ...   \n1       30.0   Data Poison           0.1    False       0.2  ...   \n2       30.0   Data Poison           0.1    False       0.2  ...   \n3       30.0   Data Poison           0.1    False       0.2  ...   \n4       30.0   Data Poison           0.1    False       0.2  ...   \n\n   ROUNDS_TO_85ACC COST_TO_85ACC  ROUNDS_TO_90ACC COST_TO_90ACC  \\\n0        20.333333    395.666667              NaN           NaN   \n1        28.300000    528.900000              NaN           NaN   \n2        18.250000    320.750000              NaN           NaN   \n3        25.300000    448.800000              NaN           NaN   \n4              NaN           NaN              NaN           NaN   \n\n   NO_ATTACK_DESIG_MAL_SEL_RATE_0.1  NO_ATTACK_DESIG_MAL_SEL_RATE_0.2  \\\n0                               NaN                               NaN   \n1                               NaN                               NaN   \n2                               NaN                               NaN   \n3                               NaN                               NaN   \n4                               NaN                               NaN   \n\n   NO_ATTACK_DESIG_MAL_SEL_RATE_0.3  NO_ATTACK_DESIG_MAL_SEL_RATE_0.4  \\\n0                               NaN                               NaN   \n1                               NaN                               NaN   \n2                               NaN                               NaN   \n3                               NaN                               NaN   \n4                               NaN                               NaN   \n\n   AVG_COST_PER_ROUND_MALICIOUS  AVG_COST_PER_ROUND_BENIGN  \n0                          1.84                      13.40  \n1                          1.82                      14.17  \n2                          2.53                      12.29  \n3                          2.54                      13.35  \n4                          5.27                       6.88  \n\n[5 rows x 48 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run</th>\n      <th>AGGREGATION_METHOD</th>\n      <th>DATA_SPLIT_MODE</th>\n      <th>discovery_quality</th>\n      <th>buyer_data_mode</th>\n      <th>N_CLIENTS</th>\n      <th>ATTACK_METHOD</th>\n      <th>TRIGGER_RATE</th>\n      <th>IS_SYBIL</th>\n      <th>ADV_RATE</th>\n      <th>...</th>\n      <th>ROUNDS_TO_85ACC</th>\n      <th>COST_TO_85ACC</th>\n      <th>ROUNDS_TO_90ACC</th>\n      <th>COST_TO_90ACC</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.1</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.2</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.3</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.4</th>\n      <th>AVG_COST_PER_ROUND_MALICIOUS</th>\n      <th>AVG_COST_PER_ROUND_BENIGN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>MartFL</td>\n      <td>discovery</td>\n      <td>0.1</td>\n      <td>random</td>\n      <td>30.0</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>20.333333</td>\n      <td>395.666667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.84</td>\n      <td>13.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>MartFL</td>\n      <td>discovery</td>\n      <td>0.1</td>\n      <td>biased</td>\n      <td>30.0</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>28.300000</td>\n      <td>528.900000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.82</td>\n      <td>14.17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>MartFL</td>\n      <td>discovery</td>\n      <td>1.0</td>\n      <td>random</td>\n      <td>30.0</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>18.250000</td>\n      <td>320.750000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.53</td>\n      <td>12.29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>MartFL</td>\n      <td>discovery</td>\n      <td>1.0</td>\n      <td>biased</td>\n      <td>30.0</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>25.300000</td>\n      <td>448.800000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.54</td>\n      <td>13.35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>MartFL</td>\n      <td>discovery</td>\n      <td>10.0</td>\n      <td>random</td>\n      <td>30.0</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.27</td>\n      <td>6.88</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Info of processed summary_df_avg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186 entries, 0 to 185\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   run                                     186 non-null    int64  \n",
      " 1   AGGREGATION_METHOD                      186 non-null    object \n",
      " 2   DATA_SPLIT_MODE                         186 non-null    object \n",
      " 3   discovery_quality                       186 non-null    float64\n",
      " 4   buyer_data_mode                         186 non-null    object \n",
      " 5   N_CLIENTS                               186 non-null    float64\n",
      " 6   ATTACK_METHOD                           186 non-null    object \n",
      " 7   TRIGGER_RATE                            186 non-null    float64\n",
      " 8   IS_SYBIL                                186 non-null    object \n",
      " 9   ADV_RATE                                186 non-null    float64\n",
      " 10  CHANGE_BASE                             186 non-null    bool   \n",
      " 11  TRIGGER_MODE                            186 non-null    object \n",
      " 12  benign_rounds                           186 non-null    float64\n",
      " 13  trigger_mode                            186 non-null    object \n",
      " 14  MAX_ASR                                 186 non-null    float64\n",
      " 15  FINAL_ASR                               186 non-null    float64\n",
      " 16  FINAL_MAIN_ACC                          186 non-null    float64\n",
      " 17  FINAL_CLEAN_ACC                         186 non-null    float64\n",
      " 18  FINAL_TRIGGERED_ACC                     186 non-null    float64\n",
      " 19  AVG_SELECTED_DISTRIBUTION_SIMILARITY    186 non-null    float64\n",
      " 20  AVG_UNSELECTED_DISTRIBUTION_SIMILARITY  186 non-null    float64\n",
      " 21  AVG_ADVERSARY_SELECTION_RATE            186 non-null    float64\n",
      " 22  AVG_BENIGN_SELECTION_RATE               186 non-null    float64\n",
      " 23  AVG_COST_PER_ROUND                      186 non-null    float64\n",
      " 24  COST_OF_CONVERGENCE                     153 non-null    float64\n",
      " 25  TARGET_ACC_FOR_COC                      186 non-null    float64\n",
      " 26  COC_TARGET_REACHED_ROUND                186 non-null    float64\n",
      " 27  PAYMENT_GINI_COEFFICIENT                186 non-null    float64\n",
      " 28  TOTAL_COST                              186 non-null    float64\n",
      " 29  TOTAL_ROUNDS                            186 non-null    float64\n",
      " 30  AVG_BENIGN_SELLER_SELECTION_RATE        186 non-null    float64\n",
      " 31  AVG_BENIGN_PAYMENT_GINI                 186 non-null    float64\n",
      " 32  ROUNDS_TO_70ACC                         180 non-null    float64\n",
      " 33  COST_TO_70ACC                           180 non-null    float64\n",
      " 34  ROUNDS_TO_75ACC                         177 non-null    float64\n",
      " 35  COST_TO_75ACC                           177 non-null    float64\n",
      " 36  ROUNDS_TO_80ACC                         153 non-null    float64\n",
      " 37  COST_TO_80ACC                           153 non-null    float64\n",
      " 38  ROUNDS_TO_85ACC                         129 non-null    float64\n",
      " 39  COST_TO_85ACC                           129 non-null    float64\n",
      " 40  ROUNDS_TO_90ACC                         0 non-null      float64\n",
      " 41  COST_TO_90ACC                           0 non-null      float64\n",
      " 42  NO_ATTACK_DESIG_MAL_SEL_RATE_0.1        96 non-null     float64\n",
      " 43  NO_ATTACK_DESIG_MAL_SEL_RATE_0.2        96 non-null     float64\n",
      " 44  NO_ATTACK_DESIG_MAL_SEL_RATE_0.3        96 non-null     float64\n",
      " 45  NO_ATTACK_DESIG_MAL_SEL_RATE_0.4        96 non-null     float64\n",
      " 46  AVG_COST_PER_ROUND_MALICIOUS            186 non-null    float64\n",
      " 47  AVG_COST_PER_ROUND_BENIGN               186 non-null    float64\n",
      "dtypes: bool(1), float64(39), int64(1), object(7)\n",
      "memory usage: 68.6+ KB\n",
      "\n",
      "all_rounds.csv loaded successfully.\n",
      "Column 'ATTACK_METHOD' before mapping. Unique values (as str): ['single', 'nan']\n",
      "Column 'ATTACK_METHOD' mapped. New unique values: ['Data Poison' 'No Attack']\n",
      "Warning: Column 'attack_objective' for categorical mapping not found in DataFrame.\n",
      "Column 'AGGREGATION_METHOD' before mapping. Unique values (as str): ['martfl']\n",
      "Column 'AGGREGATION_METHOD' mapped. New unique values: ['MartFL']\n",
      "Column 'IS_SYBIL' before mapping. Unique values (as str): ['False', 'mimic']\n",
      "Column 'IS_SYBIL' mapped. New unique values: ['False' 'mimic']\n",
      "Processing float column: ADV_RATE with precision 1\n",
      "  Column 'ADV_RATE' rounded. NaNs after rounding: 0\n",
      "Processing float column: discovery_quality with precision 1\n",
      "  Column 'discovery_quality' rounded. NaNs after rounding: 0\n",
      "Warning: Column 'FINAL_MAIN_ACC' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'FINAL_ASR' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'PAYMENT_GINI_COEFFICIENT' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_BENIGN_PAYMENT_GINI' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_ADVERSARY_SELECTION_RATE' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_BENIGN_SELLER_SELECTION_RATE' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_COST_PER_ROUND' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'COST_OF_CONVERGENCE' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'TOTAL_COST' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_COST_PER_ROUND_BENIGN' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_COST_PER_ROUND_MALICIOUS' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Set ADV_RATE to 0.0 for 'No Attack' scenarios.\n",
      "Processed all_rounds_df shape: (75795, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zeyu song\\AppData\\Local\\Temp\\ipykernel_1046860\\1487679822.py:202: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_rounds_df_raw = pd.read_csv(f\"{OUTPUT_DIR}/all_rounds.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "   run  round ATTACK_METHOD  TRIGGER_RATE IS_SYBIL  ADV_RATE  CHANGE_BASE  \\\n0    0      0   Data Poison           0.1    False       0.2         True   \n1    0      1   Data Poison           0.1    False       0.2         True   \n2    0      2   Data Poison           0.1    False       0.2         True   \n3    0      3   Data Poison           0.1    False       0.2         True   \n4    0      4   Data Poison           0.1    False       0.2         True   \n\n  TRIGGER_MODE  benign_rounds trigger_mode  ...  \\\n0       static              0       static  ...   \n1       static              0       static  ...   \n2       static              0       static  ...   \n3       static              0       static  ...   \n4       static              0       static  ...   \n\n  NO_ATTACK_DESIG_MAL_SEL_RATE_0.2_ROUND  \\\n0                                    NaN   \n1                                    NaN   \n2                                    NaN   \n3                                    NaN   \n4                                    NaN   \n\n  NO_ATTACK_DESIG_MAL_SEL_RATE_0.3_ROUND  \\\n0                                    NaN   \n1                                    NaN   \n2                                    NaN   \n3                                    NaN   \n4                                    NaN   \n\n   NO_ATTACK_DESIG_MAL_SEL_RATE_0.4_ROUND main_acc  main_loss  clean_acc  \\\n0                                     NaN   0.5518   1.175421     0.5518   \n1                                     NaN   0.6757   0.824391     0.6757   \n2                                     NaN   0.7089   0.709304     0.7089   \n3                                     NaN   0.7316   0.654981     0.7316   \n4                                     NaN   0.7550   0.616033     0.7550   \n\n  triggered_acc     asr  avg_selected_data_distribution_similarity  \\\n0        0.5701  0.1184                                   0.998623   \n1        0.6704  0.1236                                   0.998641   \n2        0.6917  0.1114                                   0.998603   \n3        0.7118  0.0949                                   0.998700   \n4        0.7322  0.1147                                   0.998637   \n\n   avg_unselected_data_distribution_similarity  \n0                                     0.998623  \n1                                     0.998623  \n2                                     0.998623  \n3                                     0.998623  \n4                                     0.998623  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run</th>\n      <th>round</th>\n      <th>ATTACK_METHOD</th>\n      <th>TRIGGER_RATE</th>\n      <th>IS_SYBIL</th>\n      <th>ADV_RATE</th>\n      <th>CHANGE_BASE</th>\n      <th>TRIGGER_MODE</th>\n      <th>benign_rounds</th>\n      <th>trigger_mode</th>\n      <th>...</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.2_ROUND</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.3_ROUND</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.4_ROUND</th>\n      <th>main_acc</th>\n      <th>main_loss</th>\n      <th>clean_acc</th>\n      <th>triggered_acc</th>\n      <th>asr</th>\n      <th>avg_selected_data_distribution_similarity</th>\n      <th>avg_unselected_data_distribution_similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.5518</td>\n      <td>1.175421</td>\n      <td>0.5518</td>\n      <td>0.5701</td>\n      <td>0.1184</td>\n      <td>0.998623</td>\n      <td>0.998623</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.6757</td>\n      <td>0.824391</td>\n      <td>0.6757</td>\n      <td>0.6704</td>\n      <td>0.1236</td>\n      <td>0.998641</td>\n      <td>0.998623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.7089</td>\n      <td>0.709304</td>\n      <td>0.7089</td>\n      <td>0.6917</td>\n      <td>0.1114</td>\n      <td>0.998603</td>\n      <td>0.998623</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.7316</td>\n      <td>0.654981</td>\n      <td>0.7316</td>\n      <td>0.7118</td>\n      <td>0.0949</td>\n      <td>0.998700</td>\n      <td>0.998623</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>Data Poison</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.7550</td>\n      <td>0.616033</td>\n      <td>0.7550</td>\n      <td>0.7322</td>\n      <td>0.1147</td>\n      <td>0.998637</td>\n      <td>0.998623</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processed Summary Data Verification (Post-Preprocessing & Derivation) ---\n",
      "Unique values in 'AGGREGATION_METHOD': ['MartFL']\n",
      "  NaNs in 'AGGREGATION_METHOD': 0\n",
      "Unique values in 'ATTACK_METHOD': ['Data Poison', 'No Attack']\n",
      "  NaNs in 'ATTACK_METHOD': 0\n",
      "Unique values in 'IS_SYBIL': ['False', 'mimic']\n",
      "  NaNs in 'IS_SYBIL': 0\n",
      "Unique values in 'ADV_RATE': [np.float64(0.0), np.float64(0.2), np.float64(0.3), np.float64(0.4)]\n",
      "  NaNs in 'ADV_RATE': 0\n",
      "VERIFICATION WARNING: Column 'BENIGN_PAYMENT_GINI_COEFFICIENT' NOT FOUND in processed summary_df_avg.\n",
      "Unique values in 'AVG_BENIGN_SELLER_SELECTION_RATE': [np.float64(0.22), np.float64(0.225), np.float64(0.246), np.float64(0.262), np.float64(0.292), np.float64(0.295), np.float64(0.298), np.float64(0.304), np.float64(0.328), np.float64(0.329), np.float64(0.33), np.float64(0.34), np.float64(0.341), np.float64(0.347), np.float64(0.355), np.float64(0.357), np.float64(0.362), np.float64(0.365), np.float64(0.374), np.float64(0.387), np.float64(0.391), np.float64(0.398), np.float64(0.403), np.float64(0.409), np.float64(0.41), np.float64(0.414), np.float64(0.424), np.float64(0.429), np.float64(0.434), np.float64(0.449), np.float64(0.452), np.float64(0.456), np.float64(0.462), np.float64(0.47), np.float64(0.478), np.float64(0.482), np.float64(0.487), np.float64(0.488), np.float64(0.489), np.float64(0.493), np.float64(0.495), np.float64(0.499), np.float64(0.5), np.float64(0.502), np.float64(0.503), np.float64(0.504), np.float64(0.506), np.float64(0.509), np.float64(0.511), np.float64(0.515), np.float64(0.52), np.float64(0.525), np.float64(0.531), np.float64(0.534), np.float64(0.545), np.float64(0.549), np.float64(0.55), np.float64(0.551), np.float64(0.552), np.float64(0.553), np.float64(0.554), np.float64(0.557), np.float64(0.56), np.float64(0.562), np.float64(0.564), np.float64(0.565), np.float64(0.567), np.float64(0.568), np.float64(0.569), np.float64(0.577), np.float64(0.578), np.float64(0.579), np.float64(0.583), np.float64(0.584), np.float64(0.598), np.float64(0.603), np.float64(0.605), np.float64(0.616), np.float64(0.623), np.float64(0.626), np.float64(0.634), np.float64(0.638), np.float64(0.645), np.float64(0.657), np.float64(0.668), np.float64(0.671), np.float64(0.675), np.float64(0.678), np.float64(0.68), np.float64(0.683), np.float64(0.684), np.float64(0.69), np.float64(0.693), np.float64(0.697), np.float64(0.712), np.float64(0.715), np.float64(0.73), np.float64(0.733), np.float64(0.742)]\n",
      "  NaNs in 'AVG_BENIGN_SELLER_SELECTION_RATE': 0\n",
      "Unique values in 'AVG_ADVERSARY_SELECTION_RATE': [np.float64(0.0), np.float64(0.007), np.float64(0.038), np.float64(0.039), np.float64(0.04), np.float64(0.041), np.float64(0.044), np.float64(0.051), np.float64(0.06), np.float64(0.064), np.float64(0.065), np.float64(0.069), np.float64(0.071), np.float64(0.073), np.float64(0.077), np.float64(0.084), np.float64(0.09), np.float64(0.094), np.float64(0.097), np.float64(0.1), np.float64(0.101), np.float64(0.103), np.float64(0.104), np.float64(0.107), np.float64(0.11), np.float64(0.114), np.float64(0.115), np.float64(0.121), np.float64(0.133), np.float64(0.144), np.float64(0.147), np.float64(0.152), np.float64(0.154), np.float64(0.16), np.float64(0.162), np.float64(0.163), np.float64(0.171), np.float64(0.173), np.float64(0.174), np.float64(0.176), np.float64(0.179), np.float64(0.191), np.float64(0.193), np.float64(0.194), np.float64(0.197), np.float64(0.202), np.float64(0.204), np.float64(0.206), np.float64(0.21), np.float64(0.211), np.float64(0.212), np.float64(0.215), np.float64(0.221), np.float64(0.222), np.float64(0.224), np.float64(0.234), np.float64(0.239), np.float64(0.246), np.float64(0.249), np.float64(0.26), np.float64(0.274), np.float64(0.276), np.float64(0.279), np.float64(0.284), np.float64(0.288), np.float64(0.29), np.float64(0.293), np.float64(0.295), np.float64(0.297), np.float64(0.3), np.float64(0.303), np.float64(0.305), np.float64(0.308), np.float64(0.327), np.float64(0.335), np.float64(0.356), np.float64(0.358), np.float64(0.362), np.float64(0.363), np.float64(0.374), np.float64(0.382), np.float64(0.384), np.float64(0.394), np.float64(0.397), np.float64(0.399), np.float64(0.401), np.float64(0.402), np.float64(0.403), np.float64(0.404), np.float64(0.418), np.float64(0.421), np.float64(0.425), np.float64(0.43), np.float64(0.434), np.float64(0.438), np.float64(0.452), np.float64(0.456), np.float64(0.477), np.float64(0.49), np.float64(0.51), np.float64(0.521), np.float64(0.56), np.float64(0.568), np.float64(0.717)]\n",
      "  NaNs in 'AVG_ADVERSARY_SELECTION_RATE': 0\n",
      "Unique values in 'AVG_COST_PER_ROUND_BENIGN': [np.float64(2.91), np.float64(3.68), np.float64(4.45), np.float64(4.97), np.float64(5.12), np.float64(5.34), np.float64(5.41), np.float64(5.69), np.float64(5.76), np.float64(5.93), np.float64(6.26), np.float64(6.27), np.float64(6.4), np.float64(6.5), np.float64(6.68), np.float64(6.72), np.float64(6.82), np.float64(6.88), np.float64(7.07), np.float64(7.08), np.float64(7.37), np.float64(7.63), np.float64(7.68), np.float64(7.8), np.float64(7.85), np.float64(7.89), np.float64(7.99), np.float64(8.1), np.float64(8.38), np.float64(8.69), np.float64(8.87), np.float64(9.02), np.float64(9.12), np.float64(9.25), np.float64(9.4), np.float64(9.73), np.float64(9.75), np.float64(9.9), np.float64(10.0), np.float64(10.21), np.float64(10.22), np.float64(10.28), np.float64(10.29), np.float64(10.54), np.float64(10.65), np.float64(10.66), np.float64(10.7), np.float64(10.93), np.float64(11.17), np.float64(11.18), np.float64(11.41), np.float64(11.52), np.float64(11.61), np.float64(11.76), np.float64(11.88), np.float64(12.02), np.float64(12.09), np.float64(12.18), np.float64(12.19), np.float64(12.29), np.float64(12.34), np.float64(12.48), np.float64(12.57), np.float64(12.59), np.float64(12.65), np.float64(12.88), np.float64(13.21), np.float64(13.35), np.float64(13.4), np.float64(13.44), np.float64(13.45), np.float64(13.57), np.float64(13.64), np.float64(14.17), np.float64(14.27), np.float64(14.4), np.float64(14.43), np.float64(14.49), np.float64(14.76), np.float64(15.12), np.float64(15.35), np.float64(15.8), np.float64(16.15), np.float64(16.18), np.float64(16.26), np.float64(16.29), np.float64(16.51), np.float64(16.59), np.float64(16.85), np.float64(17.0), np.float64(17.04), np.float64(17.16), np.float64(17.25)]\n",
      "  NaNs in 'AVG_COST_PER_ROUND_BENIGN': 0\n",
      "Unique values in 'AVG_COST_PER_ROUND_MALICIOUS': [np.float64(0.0), np.float64(0.05), np.float64(0.64), np.float64(0.66), np.float64(0.69), np.float64(0.7), np.float64(0.73), np.float64(0.78), np.float64(0.83), np.float64(0.92), np.float64(0.99), np.float64(1.01), np.float64(1.06), np.float64(1.11), np.float64(1.13), np.float64(1.2), np.float64(1.22), np.float64(1.23), np.float64(1.33), np.float64(1.37), np.float64(1.45), np.float64(1.47), np.float64(1.48), np.float64(1.54), np.float64(1.58), np.float64(1.66), np.float64(1.71), np.float64(1.78), np.float64(1.82), np.float64(1.84), np.float64(1.85), np.float64(1.9), np.float64(1.94), np.float64(2.0), np.float64(2.1), np.float64(2.18), np.float64(2.34), np.float64(2.53), np.float64(2.54), np.float64(2.6), np.float64(2.64), np.float64(2.99), np.float64(3.04), np.float64(3.05), np.float64(3.19), np.float64(3.2), np.float64(3.22), np.float64(3.23), np.float64(3.24), np.float64(3.26), np.float64(3.36), np.float64(3.46), np.float64(3.64), np.float64(3.75), np.float64(3.95), np.float64(4.05), np.float64(4.12), np.float64(4.14), np.float64(4.16), np.float64(4.18), np.float64(4.29), np.float64(4.3), np.float64(4.78), np.float64(4.83), np.float64(4.84), np.float64(4.9), np.float64(4.98), np.float64(5.15), np.float64(5.25), np.float64(5.27), np.float64(5.36), np.float64(5.41), np.float64(5.44), np.float64(5.54), np.float64(5.63), np.float64(5.68), np.float64(5.71), np.float64(5.84), np.float64(6.32), np.float64(6.44), np.float64(7.07), np.float64(7.38), np.float64(8.23)]\n",
      "  NaNs in 'AVG_COST_PER_ROUND_MALICIOUS': 0\n",
      "Unique values in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1': [np.float64(0.09), np.float64(0.097), np.float64(0.1), np.float64(0.104), np.float64(0.107), np.float64(0.114), np.float64(0.115)]\n",
      "  NaNs in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1': 90\n",
      "Unique values in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2': [np.float64(0.162), np.float64(0.173), np.float64(0.193), np.float64(0.197), np.float64(0.206), np.float64(0.211), np.float64(0.221)]\n",
      "  NaNs in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2': 90\n",
      "Unique values in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3': [np.float64(0.206), np.float64(0.224), np.float64(0.293), np.float64(0.295), np.float64(0.303), np.float64(0.305), np.float64(0.327)]\n",
      "  NaNs in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3': 90\n",
      "Unique values in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4': [np.float64(0.249), np.float64(0.29), np.float64(0.394), np.float64(0.397), np.float64(0.401), np.float64(0.403), np.float64(0.438)]\n",
      "  NaNs in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4': 90\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_DIR = \"./results\"  # Or your actual path\n",
    "# TARGET_ACCURACY_COC = 0.8 # Not used in Gini/Selection plots, but good to have if other plots use it\n",
    "\n",
    "# --- Helper Function for Preprocessing ---\n",
    "def preprocess_experiment_data(df, float_cols_precision=None, categorical_maps=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Preprocesses a DataFrame by converting columns, rounding floats, and mapping categoricals.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        if verbose: print(\"Input DataFrame is empty. Skipping preprocessing.\")\n",
    "        return df.copy() # Return a copy even if empty\n",
    "\n",
    "    processed_df = df.copy()\n",
    "\n",
    "    # 1. Map categorical values\n",
    "    if categorical_maps:\n",
    "        for col, value_map in categorical_maps.items():\n",
    "            if col in processed_df.columns:\n",
    "                original_unique_vals_str = list(map(str, processed_df[col].unique())) # For robust printing\n",
    "                if verbose: print(f\"Column '{col}' before mapping. Unique values (as str): {original_unique_vals_str}\")\n",
    "                # Handle NaN mapping first if present in keys\n",
    "                if np.nan in value_map:\n",
    "                    processed_df[col] = processed_df[col].fillna(value_map[np.nan])\n",
    "                    value_map_no_nan = {k: v for k, v in value_map.items() if not pd.isna(k)}\n",
    "                    if value_map_no_nan:\n",
    "                         processed_df[col] = processed_df[col].replace(value_map_no_nan)\n",
    "                else: # No specific NaN mapping, just replace\n",
    "                    processed_df[col] = processed_df[col].replace(value_map)\n",
    "                if verbose: print(f\"Column '{col}' mapped. New unique values: {processed_df[col].unique()}\")\n",
    "            elif verbose: print(f\"Warning: Column '{col}' for categorical mapping not found in DataFrame.\")\n",
    "\n",
    "    # 2. Convert to numeric and round specified float columns\n",
    "    if float_cols_precision:\n",
    "        for col, precision in float_cols_precision.items():\n",
    "            if col in processed_df.columns: # Check if column exists BEFORE trying to process\n",
    "                if verbose: print(f\"Processing float column: {col} with precision {precision}\")\n",
    "                original_nan_count = processed_df[col].isna().sum()\n",
    "                numeric_col = pd.to_numeric(processed_df[col], errors='coerce')\n",
    "                coerced_nan_count = numeric_col.isna().sum()\n",
    "                if verbose and coerced_nan_count > original_nan_count:\n",
    "                    print(f\"  Warning: Column '{col}' had {coerced_nan_count - original_nan_count} new NaNs after to_numeric (were {original_nan_count}).\")\n",
    "                \n",
    "                processed_df[col] = numeric_col.round(precision)\n",
    "                if verbose: print(f\"  Column '{col}' rounded. NaNs after rounding: {processed_df[col].isna().sum()}\")\n",
    "            elif verbose: print(f\"Warning: Column '{col}' (listed in FLOAT_PRECISIONS) not found in DataFrame.\")\n",
    "\n",
    "    # 3. Specific logic: Set ADV_RATE to 0.0 for 'No Attack' scenarios\n",
    "    if 'ATTACK_METHOD' in processed_df.columns and 'ADV_RATE' in processed_df.columns:\n",
    "        if 'No Attack' in processed_df['ATTACK_METHOD'].unique(): # Check if 'No Attack' exists after mapping\n",
    "            # Ensure ADV_RATE is numeric before this assignment\n",
    "            if not pd.api.types.is_numeric_dtype(processed_df['ADV_RATE']):\n",
    "                processed_df['ADV_RATE'] = pd.to_numeric(processed_df['ADV_RATE'], errors='coerce')\n",
    "            \n",
    "            processed_df.loc[processed_df['ATTACK_METHOD'] == 'No Attack', 'ADV_RATE'] = 0.0\n",
    "            if verbose: print(\"Set ADV_RATE to 0.0 for 'No Attack' scenarios.\")\n",
    "        elif verbose: print(\"'No Attack' not found in ATTACK_METHOD after mapping; ADV_RATE for 'No Attack' not set to 0.\")\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# --- Define Preprocessing Parameters ---\n",
    "FLOAT_PRECISIONS = {\n",
    "    'ADV_RATE': 1,\n",
    "    'discovery_quality': 1,\n",
    "    'FINAL_MAIN_ACC': 4,\n",
    "    'FINAL_ASR': 4,\n",
    "    'PAYMENT_GINI_COEFFICIENT': 3,\n",
    "    'AVG_BENIGN_PAYMENT_GINI': 3, # Assuming this is AVG_BENIGN_PAYMENT_GINI from your CSV\n",
    "    'AVG_ADVERSARY_SELECTION_RATE': 3, # This is the proportion of *selected* clients that are adversaries\n",
    "    'AVG_BENIGN_SELLER_SELECTION_RATE': 3, # This might be rate among available benign, or proportion of selected\n",
    "    'AVG_COST_PER_ROUND': 2, # Overall average cost per round\n",
    "    'COST_OF_CONVERGENCE': 0, # Assuming integer rounds/costs\n",
    "    'TOTAL_COST': 0,        # Assuming integer rounds/costs\n",
    "    'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1': 3,\n",
    "    'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2': 3,\n",
    "    'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3': 3,\n",
    "    'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4': 3,\n",
    "    # Add derived columns here if you want them rounded by the helper,\n",
    "    # otherwise, round them after derivation.\n",
    "    'AVG_COST_PER_ROUND_BENIGN': 2,\n",
    "    'AVG_COST_PER_ROUND_MALICIOUS': 2\n",
    "}\n",
    "\n",
    "CATEGORICAL_MAPPINGS = {\n",
    "    'ATTACK_METHOD': {\n",
    "        'single': 'Data Poison', \n",
    "        np.nan: 'No Attack',  # Handles empty cells in CSV read as pandas NaN\n",
    "        'None': 'No Attack',   # Handles cells with string 'None'\n",
    "        'no_attack': 'No Attack' # Handles cells with string 'no_attack'\n",
    "    },\n",
    "    \n",
    "    'attack_objective': {\n",
    "        \n",
    "        np.nan: 'None',  # Handles empty cells in CSV read as pandas NaN\n",
    "        'None': 'None',   # Handles cells with string 'None'\n",
    "        'no_attack': 'None', # Handles cells with string 'no_attack'\n",
    "        'backdoor': \"Backdoor\",\n",
    "        'label_flip': \"Label-Flipping\",\n",
    "    },\n",
    "    'AGGREGATION_METHOD': {\n",
    "        'martfl': \"MartFL\",\n",
    "        'fedavg': 'FedAvg', \n",
    "        'fltrust': 'FLTrust',\n",
    "        'skymask' : 'SkyMask',\n",
    "    },\n",
    "    'IS_SYBIL': {\n",
    "        # Assuming your CSV has string 'False' and string 'mimic'\n",
    "        # If it's boolean True/False, you'd map them:\n",
    "        # True: 'mimic', \n",
    "        # False: 'False' # Keep 'False' as string 'False' for consistency\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Load and Preprocess Data ---\n",
    "summary_df_avg = pd.DataFrame() # Initialize as empty\n",
    "\n",
    "try:\n",
    "    summary_df_avg_raw = pd.read_csv(f\"{OUTPUT_DIR}/summary_avg.csv\")\n",
    "    print(\"--- Preprocessing summary_avg.csv ---\")\n",
    "    summary_df_avg = preprocess_experiment_data(\n",
    "        summary_df_avg_raw,\n",
    "        float_cols_precision=FLOAT_PRECISIONS,\n",
    "        categorical_maps=CATEGORICAL_MAPPINGS,\n",
    "        verbose=True # Enable verbose output for debugging\n",
    "    )\n",
    "    \n",
    "    # --- DERIVE COST COMPOSITION COLUMNS (Benign vs. Malicious Cost per Round) ---\n",
    "    cost_benign_col = 'AVG_COST_PER_ROUND_BENIGN'\n",
    "    cost_mal_col = 'AVG_COST_PER_ROUND_MALICIOUS'\n",
    "    \n",
    "    # Check if derivation is sensible (i.e., source columns exist)\n",
    "    if 'AVG_COST_PER_ROUND' in summary_df_avg.columns and \\\n",
    "       'AVG_ADVERSARY_SELECTION_RATE' in summary_df_avg.columns:\n",
    "        \n",
    "        print(\"Deriving cost composition (benign/malicious) from AVG_COST_PER_ROUND and AVG_ADVERSARY_SELECTION_RATE.\")\n",
    "        \n",
    "        # Ensure source columns are numeric (they should be after preprocess_experiment_data if listed in FLOAT_PRECISIONS)\n",
    "        # If not listed, convert them here explicitly before use.\n",
    "        for col_to_check in ['AVG_COST_PER_ROUND', 'AVG_ADVERSARY_SELECTION_RATE']:\n",
    "            if col_to_check not in FLOAT_PRECISIONS: # If not already processed by helper\n",
    "                 if col_to_check in summary_df_avg.columns:\n",
    "                    summary_df_avg[col_to_check] = pd.to_numeric(summary_df_avg[col_to_check], errors='coerce')\n",
    "                    print(f\"  Ensured column '{col_to_check}' is numeric for derivation.\")\n",
    "                 else:\n",
    "                    print(f\"  Warning: Source column '{col_to_check}' for derivation not found.\")\n",
    "                    # Create empty columns to prevent later key errors if derivation fails\n",
    "                    summary_df_avg[cost_mal_col] = np.nan\n",
    "                    summary_df_avg[cost_benign_col] = np.nan\n",
    "\n",
    "\n",
    "        # For \"No Attack\" runs, AVG_ADVERSARY_SELECTION_RATE should be 0 for this calculation.\n",
    "        # The preprocess_experiment_data sets ADV_RATE to 0.\n",
    "        # Your data generation script should ensure AVG_ADVERSARY_SELECTION_RATE is 0 for No Attack runs.\n",
    "        # If it might be NaN for No Attack runs, fill it with 0 before calculation.\n",
    "        adv_sel_rate_for_calc = summary_df_avg['AVG_ADVERSARY_SELECTION_RATE'].copy()\n",
    "        # If ATTACK_METHOD is 'No Attack', this rate is definitionally 0.\n",
    "        # Also, if it's NaN for an attack run (shouldn't happen if data is good), treat as 0 for safety here.\n",
    "        adv_sel_rate_for_calc[summary_df_avg['ATTACK_METHOD'] == 'No Attack'] = 0.0\n",
    "        adv_sel_rate_for_calc.fillna(0.0, inplace=True) # Fill any other NaNs with 0 to avoid NaN propagation\n",
    "\n",
    "        # Calculate derived costs\n",
    "        summary_df_avg[cost_mal_col] = summary_df_avg['AVG_COST_PER_ROUND'] * adv_sel_rate_for_calc\n",
    "        summary_df_avg[cost_benign_col] = summary_df_avg['AVG_COST_PER_ROUND'] * (1 - adv_sel_rate_for_calc)\n",
    "        \n",
    "        # Round the newly derived columns if they weren't already in FLOAT_PRECISIONS\n",
    "        # or if derivation might have introduced new float precision issues.\n",
    "        if cost_mal_col in summary_df_avg.columns:\n",
    "            summary_df_avg[cost_mal_col] = summary_df_avg[cost_mal_col].round(FLOAT_PRECISIONS.get(cost_mal_col, 2))\n",
    "        if cost_benign_col in summary_df_avg.columns:\n",
    "            summary_df_avg[cost_benign_col] = summary_df_avg[cost_benign_col].round(FLOAT_PRECISIONS.get(cost_benign_col, 2))\n",
    "        print(\"Derived and processed cost composition columns.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Warning: Cannot derive cost composition. Missing 'AVG_COST_PER_ROUND' or 'AVG_ADVERSARY_SELECTION_RATE'.\")\n",
    "        # Ensure columns exist as NaN if derivation fails, for consistency in later plotting cells\n",
    "        if cost_mal_col not in summary_df_avg.columns: summary_df_avg[cost_mal_col] = np.nan\n",
    "        if cost_benign_col not in summary_df_avg.columns: summary_df_avg[cost_benign_col] = np.nan\n",
    "\n",
    "\n",
    "    print(f\"Processed summary_df_avg shape: {summary_df_avg.shape}\")\n",
    "    if not summary_df_avg.empty:\n",
    "        print(\"\\nFirst 5 rows of processed summary_df_avg (after potential derivation):\")\n",
    "        display(summary_df_avg.head())\n",
    "        print(\"\\nInfo of processed summary_df_avg:\")\n",
    "        summary_df_avg.info()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"CRITICAL ERROR: summary_avg.csv not found in {OUTPUT_DIR}. Cannot proceed with plotting.\")\n",
    "    summary_df_avg = pd.DataFrame() # Ensure it's an empty DF if load fails\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: An error occurred during summary_df_avg loading or preprocessing: {e}\")\n",
    "    summary_df_avg = pd.DataFrame()\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"muted\")\n",
    "try:\n",
    "    all_rounds_df_raw = pd.read_csv(f\"{OUTPUT_DIR}/all_rounds.csv\")\n",
    "    print(\"\\nall_rounds.csv loaded successfully.\")\n",
    "    all_rounds_df = preprocess_experiment_data(\n",
    "        all_rounds_df_raw,\n",
    "        float_cols_precision=FLOAT_PRECISIONS,\n",
    "        categorical_maps=CATEGORICAL_MAPPINGS\n",
    "    )\n",
    "    print(f\"Processed all_rounds_df shape: {all_rounds_df.shape}\")\n",
    "    if not all_rounds_df.empty: display(all_rounds_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: all_rounds.csv not found in {OUTPUT_DIR}. Please check the path.\")\n",
    "    all_rounds_df = pd.DataFrame()\n",
    "\n",
    "# Set a consistent style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# --- Verification ---\n",
    "if not summary_df_avg.empty:\n",
    "    print(\"\\n--- Processed Summary Data Verification (Post-Preprocessing & Derivation) ---\")\n",
    "    check_cols = [\n",
    "        'AGGREGATION_METHOD', 'ATTACK_METHOD', 'IS_SYBIL', 'ADV_RATE',\n",
    "        'BENIGN_PAYMENT_GINI_COEFFICIENT', # This is your AVG_BENIGN_PAYMENT_GINI\n",
    "        'AVG_BENIGN_SELLER_SELECTION_RATE', \n",
    "        'AVG_ADVERSARY_SELECTION_RATE',\n",
    "        'AVG_COST_PER_ROUND_BENIGN', # New derived/processed\n",
    "        'AVG_COST_PER_ROUND_MALICIOUS', # New derived/processed\n",
    "        'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1', 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2',\n",
    "        'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3', 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4'\n",
    "    ]\n",
    "    for col in check_cols:\n",
    "        if col in summary_df_avg.columns:\n",
    "            unique_vals = summary_df_avg[col].unique()\n",
    "            try:\n",
    "                if pd.api.types.is_numeric_dtype(summary_df_avg[col].dtype) and not summary_df_avg[col].empty:\n",
    "                    valid_numeric_vals = summary_df_avg[col].dropna().unique()\n",
    "                    unique_vals = sorted(list(valid_numeric_vals)) if len(valid_numeric_vals) > 0 else []\n",
    "                elif not summary_df_avg[col].empty:\n",
    "                    # Attempt to sort strings, handle mixed types by converting all to string for sorting\n",
    "                    unique_vals = sorted(list(map(str, unique_vals)))\n",
    "            except TypeError:\n",
    "                 print(f\"    (Could not sort unique values for {col} due to mixed types or NaNs)\")\n",
    "                 pass \n",
    "            print(f\"Unique values in '{col}': {unique_vals}\")\n",
    "            print(f\"  NaNs in '{col}': {summary_df_avg[col].isna().sum()}\")\n",
    "        else:\n",
    "            print(f\"VERIFICATION WARNING: Column '{col}' NOT FOUND in processed summary_df_avg.\")\n",
    "else:\n",
    "    print(\"\\nsummary_df_avg is empty. Verification skipped. Subsequent plots will likely fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TARGET_DATASET = \"TREC\"\n",
    "AGG_METHOD_TO_ANALYZE = 'MartFL'  # or 'fltrust', 'fedavg'\n",
    "ATTACK_TO_ANALYZE = 'Backdoor'  # or 'None'\n",
    "adv_rates_to_plot_on_x_for_attack = [0.2, 0.3, 0.4]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-15T23:39:37.589304200Z",
     "start_time": "2025-05-15T23:39:37.574940900Z"
    }
   },
   "id": "c91c75d9d2757ed2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os  # For creating directories\n",
    "\n",
    "\n",
    "def save_figure_as_pdf(fig, output_directory, base_filename, current_aggregation_method=\"MartFL\",\n",
    "                       adv_rate_config=None, attack_method_config=None, is_sybil_config=None,\n",
    "                       other_details=None, dpi=300):\n",
    "    \"\"\"\n",
    "    Saves the given matplotlib figure as a PDF with a descriptive filename.\n",
    "\n",
    "    Args:\n",
    "        fig (matplotlib.figure.Figure): The figure object to save.\n",
    "        output_directory (str): The directory where the figure will be saved.\n",
    "        base_filename (str): A base name for the figure (e.g., \"coc_vs_adv_rate\").\n",
    "        current_aggregation_method (str, optional): Aggregator name. Defaults to \"MartFL\".\n",
    "        adv_rate_config (float, optional): Specific ADV_RATE if the plot is for a fixed rate.\n",
    "        attack_method_config (str, optional): Specific ATTACK_METHOD if fixed.\n",
    "        is_sybil_config (str/bool, optional): Specific IS_SYBIL state if fixed.\n",
    "        other_details (str, optional): Any other specific details for the filename.\n",
    "        dpi (int, optional): Dots per inch for the saved figure.\n",
    "    \"\"\"\n",
    "    if not fig:\n",
    "        print(\"Error: No figure object provided to save_figure_as_pdf.\")\n",
    "        return\n",
    "\n",
    "    # Sanitize components for filename\n",
    "    agg_method_safe = current_aggregation_method.replace(\" \", \"_\").lower()\n",
    "    base_filename_safe = base_filename.replace(\" \", \"_\").replace(\"/\", \"_\").lower()\n",
    "\n",
    "    filename_parts = [agg_method_safe, base_filename_safe]\n",
    "\n",
    "    if attack_method_config and attack_method_config != 'No Attack':  # Only add attack details if an attack is present\n",
    "        attack_safe = str(attack_method_config).replace(\" \", \"_\").lower()\n",
    "        filename_parts.append(f\"atk_{attack_safe}\")\n",
    "        if is_sybil_config is not None:\n",
    "            sybil_safe = str(is_sybil_config).lower()\n",
    "            filename_parts.append(f\"syb_{sybil_safe}\")\n",
    "        if adv_rate_config is not None:\n",
    "            filename_parts.append(f\"adv{str(adv_rate_config).replace('.', 'p')}\")  # e.g., adv0p3\n",
    "\n",
    "    if other_details:\n",
    "        details_safe = str(other_details).replace(\" \", \"_\").lower()\n",
    "        filename_parts.append(details_safe)\n",
    "\n",
    "    final_filename = \"_\".join(filename_parts) + \".pdf\"\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    full_save_path = os.path.join(output_directory, final_filename)\n",
    "\n",
    "    try:\n",
    "        # Use bbox_inches='tight' to minimize whitespace and ensure everything fits\n",
    "        # pad_inches can add a little padding if 'tight' is too tight.\n",
    "        fig.savefig(full_save_path, bbox_inches='tight', pad_inches=0.1, dpi=dpi)\n",
    "        print(f\"Figure saved successfully to: {full_save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving figure to {full_save_path}: {e}\")\n",
    "\n",
    "\n",
    "FIGURE_SAVE_DIR = os.path.join(OUTPUT_DIR, \"paper_figures\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-15T23:39:37.589304200Z",
     "start_time": "2025-05-15T23:39:37.580236500Z"
    }
   },
   "id": "455d27b1974c26ce"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# Global font and style adjustments for compact multi-plot figure (e.g., 4 in a row)\n",
    "mpl.rcParams.update({\n",
    "    'font.size': 20,\n",
    "    'axes.labelsize': 20,\n",
    "    'axes.titlesize': 20,\n",
    "    'xtick.labelsize': 15,\n",
    "    'ytick.labelsize': 15,\n",
    "    'legend.fontsize': 15,\n",
    "    'legend.title_fontsize': 15,\n",
    "    'font.weight': 'bold',\n",
    "    'axes.labelweight': 'bold',\n",
    "    'pdf.fonttype': 42,  # Ensure text is editable in PDFs\n",
    "    'ps.fonttype': 42,\n",
    "})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7.5, 5)  # adjust to your preferred size\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-15T23:39:37.589304200Z",
     "start_time": "2025-05-15T23:39:37.583616300Z"
    }
   },
   "id": "26f7476ada7ccab7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     run AGGREGATION_METHOD DATA_SPLIT_MODE  discovery_quality  \\\n",
      "90     9             MartFL       discovery                0.1   \n",
      "91     9             MartFL       discovery                0.1   \n",
      "92     3             MartFL       discovery                1.0   \n",
      "93     1             MartFL       discovery                1.0   \n",
      "94     0             MartFL       discovery               10.0   \n",
      "..   ...                ...             ...                ...   \n",
      "181    9             MartFL       discovery                0.1   \n",
      "182    3             MartFL       discovery                1.0   \n",
      "183    9             MartFL       discovery                1.0   \n",
      "184    0             MartFL       discovery               10.0   \n",
      "185    9             MartFL       discovery               10.0   \n",
      "\n",
      "    buyer_data_mode  N_CLIENTS ATTACK_METHOD  TRIGGER_RATE IS_SYBIL  ADV_RATE  \\\n",
      "90           random       30.0     No Attack           0.0    False       0.0   \n",
      "91           biased       30.0     No Attack           0.0    False       0.0   \n",
      "92           random       30.0     No Attack           0.0    False       0.0   \n",
      "93           biased       30.0     No Attack           0.0    False       0.0   \n",
      "94           random       30.0     No Attack           0.0    False       0.0   \n",
      "..              ...        ...           ...           ...      ...       ...   \n",
      "181          biased       30.0     No Attack           0.0    mimic       0.0   \n",
      "182          random       30.0     No Attack           0.0    mimic       0.0   \n",
      "183          biased       30.0     No Attack           0.0    mimic       0.0   \n",
      "184          random       30.0     No Attack           0.0    mimic       0.0   \n",
      "185          biased       30.0     No Attack           0.0    mimic       0.0   \n",
      "\n",
      "     ...  ROUNDS_TO_85ACC COST_TO_85ACC  ROUNDS_TO_90ACC COST_TO_90ACC  \\\n",
      "90   ...             18.8        420.30              NaN           NaN   \n",
      "91   ...             28.1        586.40              NaN           NaN   \n",
      "92   ...             17.0        337.25              NaN           NaN   \n",
      "93   ...             23.0        462.00              NaN           NaN   \n",
      "94   ...              NaN           NaN              NaN           NaN   \n",
      "..   ...              ...           ...              ...           ...   \n",
      "181  ...             28.1        586.40              NaN           NaN   \n",
      "182  ...             17.0        337.25              NaN           NaN   \n",
      "183  ...             24.6        486.30              NaN           NaN   \n",
      "184  ...              NaN           NaN              NaN           NaN   \n",
      "185  ...              NaN           NaN              NaN           NaN   \n",
      "\n",
      "     NO_ATTACK_DESIG_MAL_SEL_RATE_0.1  NO_ATTACK_DESIG_MAL_SEL_RATE_0.2  \\\n",
      "90                              0.100                             0.197   \n",
      "91                              0.097                             0.193   \n",
      "92                              0.114                             0.221   \n",
      "93                              0.107                             0.211   \n",
      "94                              0.115                             0.173   \n",
      "..                                ...                               ...   \n",
      "181                             0.097                             0.193   \n",
      "182                             0.114                             0.221   \n",
      "183                             0.104                             0.206   \n",
      "184                             0.115                             0.173   \n",
      "185                             0.090                             0.162   \n",
      "\n",
      "     NO_ATTACK_DESIG_MAL_SEL_RATE_0.3  NO_ATTACK_DESIG_MAL_SEL_RATE_0.4  \\\n",
      "90                              0.293                             0.394   \n",
      "91                              0.295                             0.397   \n",
      "92                              0.327                             0.438   \n",
      "93                              0.305                             0.403   \n",
      "94                              0.206                             0.249   \n",
      "..                                ...                               ...   \n",
      "181                             0.295                             0.397   \n",
      "182                             0.327                             0.438   \n",
      "183                             0.303                             0.401   \n",
      "184                             0.206                             0.249   \n",
      "185                             0.224                             0.290   \n",
      "\n",
      "     AVG_COST_PER_ROUND_MALICIOUS  AVG_COST_PER_ROUND_BENIGN  \n",
      "90                            0.0                      17.16  \n",
      "91                            0.0                      17.25  \n",
      "92                            0.0                      16.85  \n",
      "93                            0.0                      17.04  \n",
      "94                            0.0                      12.19  \n",
      "..                            ...                        ...  \n",
      "181                           0.0                      17.25  \n",
      "182                           0.0                      16.85  \n",
      "183                           0.0                      16.51  \n",
      "184                           0.0                      12.19  \n",
      "185                           0.0                      10.54  \n",
      "\n",
      "[96 rows x 48 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'attack_objective'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Users\\Public\\minikuda\\envs\\poison_data_valuation_new\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3804\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3805\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._engine.get_loc(casted_key)\n\u001B[32m   3806\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'attack_objective'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 23\u001B[39m\n\u001B[32m     19\u001B[39m     no_attack_avg_acc = np.nan\n\u001B[32m     20\u001B[39m     no_attack_avg_asr = np.nan\n\u001B[32m     22\u001B[39m backdoor_attack_filtered = plot_data[\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m     (plot_data[\u001B[33m'\u001B[39m\u001B[33mattack_objective\u001B[39m\u001B[33m'\u001B[39m] == \u001B[33m'\u001B[39m\u001B[33mBackdoor\u001B[39m\u001B[33m'\u001B[39m) &\n\u001B[32m     24\u001B[39m     (plot_data[\u001B[33m'\u001B[39m\u001B[33mADV_RATE\u001B[39m\u001B[33m'\u001B[39m].isin(adv_rates_to_plot_on_x_for_attack))\n\u001B[32m     25\u001B[39m     ].copy()\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m backdoor_attack_filtered.empty:\n\u001B[32m     28\u001B[39m     backdoor_attack_avg_perf = backdoor_attack_filtered.groupby(\u001B[33m'\u001B[39m\u001B[33mADV_RATE\u001B[39m\u001B[33m'\u001B[39m, as_index=\u001B[38;5;28;01mFalse\u001B[39;00m)[\n\u001B[32m     29\u001B[39m         [\u001B[33m'\u001B[39m\u001B[33mFINAL_MAIN_ACC\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mFINAL_ASR\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     30\u001B[39m     ].mean().sort_values(by=\u001B[33m'\u001B[39m\u001B[33mADV_RATE\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Users\\Public\\minikuda\\envs\\poison_data_valuation_new\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4100\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4102\u001B[39m indexer = \u001B[38;5;28mself\u001B[39m.columns.get_loc(key)\n\u001B[32m   4103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4104\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Users\\Public\\minikuda\\envs\\poison_data_valuation_new\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3808\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3809\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3810\u001B[39m     ):\n\u001B[32m   3811\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3814\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3815\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3816\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3817\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'attack_objective'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D  # For custom legend\n",
    "\n",
    "# --- Assume summary_df_avg is loaded and your PREPROCESSING function is defined and used ---\n",
    "# summary_df_avg = preprocess_experiment_data(...) # From your previous cell\n",
    "\n",
    "if not summary_df_avg.empty:\n",
    "    # --- Data Preparation ---\n",
    "    plot_data = summary_df_avg.copy()\n",
    "    # plot_data = plot_data[plot_data['DATASET'] == TARGET_DATASET]\n",
    "    no_attack_perf = plot_data[plot_data['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "    print(no_attack_perf)\n",
    "    if not no_attack_perf.empty:\n",
    "        no_attack_avg_acc = no_attack_perf['FINAL_MAIN_ACC'].mean()\n",
    "        no_attack_avg_asr = 0.1  # ASR for No Attack is 0\n",
    "    else:\n",
    "        no_attack_avg_acc = np.nan\n",
    "        no_attack_avg_asr = np.nan\n",
    "\n",
    "    backdoor_attack_filtered = plot_data[\n",
    "        (plot_data['attack_objective'] == 'Backdoor') &\n",
    "        (plot_data['ADV_RATE'].isin(adv_rates_to_plot_on_x_for_attack))\n",
    "        ].copy()\n",
    "\n",
    "    if not backdoor_attack_filtered.empty:\n",
    "        backdoor_attack_avg_perf = backdoor_attack_filtered.groupby('ADV_RATE', as_index=False)[\n",
    "            ['FINAL_MAIN_ACC', 'FINAL_ASR']\n",
    "        ].mean().sort_values(by='ADV_RATE')\n",
    "        adv_rates_with_backdoor_data = sorted(backdoor_attack_avg_perf['ADV_RATE'].unique())\n",
    "    else:\n",
    "        backdoor_attack_avg_perf = pd.DataFrame(columns=['ADV_RATE', 'FINAL_MAIN_ACC', 'FINAL_ASR'])\n",
    "        adv_rates_with_backdoor_data = []\n",
    "        print(f\"Warning: No 'Backdoor' data found for ADV_RATEs {adv_rates_to_plot_on_x_for_attack}.\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    # Font sizes for paper\n",
    "    TITLE_FONT_SIZE = 14\n",
    "    AXIS_LABEL_FONT_SIZE = 12\n",
    "    TICK_LABEL_FONT_SIZE = 10\n",
    "    LEGEND_FONT_SIZE = 9\n",
    "    LEGEND_TITLE_FONT_SIZE = 10\n",
    "    LINE_WIDTH = 2.0  # Slightly reduced from 2.5 for typical paper figs\n",
    "    MARKER_SIZE = 6  # Slightly reduced\n",
    "\n",
    "    fig, ax1 = plt.subplots()  # Adjusted for paper\n",
    "\n",
    "    main_acc_color_attack = 'mediumblue'\n",
    "    asr_color_attack = 'crimson'\n",
    "    no_attack_acc_color = 'dimgray'  # Changed for better contrast with blue/red\n",
    "    no_attack_asr_color = 'salmon'  # Changed for better contrast\n",
    "\n",
    "    legend_elements = []\n",
    "    x_min_for_no_attack_line = min(adv_rates_with_backdoor_data) if adv_rates_with_backdoor_data else 0.2\n",
    "    x_max_for_no_attack_line = max(adv_rates_with_backdoor_data) if adv_rates_with_backdoor_data else 0.4\n",
    "\n",
    "    # 1. Plot \"No Attack\" Main Accuracy\n",
    "    if pd.notna(no_attack_avg_acc):\n",
    "        ax1.hlines(y=no_attack_avg_acc, xmin=x_min_for_no_attack_line, xmax=x_max_for_no_attack_line,\n",
    "                   color=no_attack_acc_color, linestyle=(0, (5, 5)), linewidth=LINE_WIDTH)  # Dash-dot style\n",
    "        legend_elements.append(Line2D([0], [0], color=no_attack_acc_color, linestyle=(0, (5, 5)), lw=LINE_WIDTH,\n",
    "                                      label=f'No Atk. Acc. ({no_attack_avg_acc:.2f})'))\n",
    "\n",
    "    # 2. Plot \"Backdoor\" Main Accuracy\n",
    "    if not backdoor_attack_avg_perf.empty:\n",
    "        ax1.plot(backdoor_attack_avg_perf['ADV_RATE'], backdoor_attack_avg_perf['FINAL_MAIN_ACC'],\n",
    "                 color=main_acc_color_attack, linestyle='-', marker='o',\n",
    "                 linewidth=LINE_WIDTH, markersize=MARKER_SIZE)\n",
    "        legend_elements.append(Line2D([0], [0], color=main_acc_color_attack, linestyle='-', marker='o', lw=LINE_WIDTH,\n",
    "                                      label='Backdoor Main Acc.'))\n",
    "\n",
    "    ax1.set_xlabel('Adversary Rate')\n",
    "    ax1.set_ylabel('Main Accuracy', color=main_acc_color_attack)  # Color matches line\n",
    "    ax1.tick_params(axis='y', labelcolor=main_acc_color_attack)\n",
    "    ax1.set_ylim(0, 1.05)\n",
    "    ax1.grid(True, which='major', linestyle=':', linewidth=0.5, axis='y')\n",
    "\n",
    "    # 3. Second y-axis for ASR\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # 4. Plot \"No Attack\" ASR\n",
    "    if pd.notna(no_attack_avg_asr):\n",
    "        ax2.hlines(y=no_attack_avg_asr, xmin=x_min_for_no_attack_line, xmax=x_max_for_no_attack_line,\n",
    "                   color=no_attack_asr_color, linestyle=(0, (5, 5)), linewidth=LINE_WIDTH)  # Dash-dot style\n",
    "        legend_elements.append(Line2D([0], [0], color=no_attack_asr_color, linestyle=(0, (5, 5)), lw=LINE_WIDTH,\n",
    "                                      label=f'No Atk. ASR ({no_attack_avg_asr:.2f})'))\n",
    "\n",
    "    # 5. Plot \"Backdoor\" ASR\n",
    "    if not backdoor_attack_avg_perf.empty:\n",
    "        ax2.plot(backdoor_attack_avg_perf['ADV_RATE'], backdoor_attack_avg_perf['FINAL_ASR'],\n",
    "                 color=asr_color_attack, linestyle='--', marker='s',\n",
    "                 linewidth=LINE_WIDTH, markersize=MARKER_SIZE)\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=asr_color_attack, linestyle='--', marker='s', lw=LINE_WIDTH, label='Backdoor ASR'))\n",
    "\n",
    "    ax2.set_ylabel('Attack Success Rate (ASR)', color=asr_color_attack)  # Color matches line\n",
    "    ax2.tick_params(axis='y', labelcolor=asr_color_attack)\n",
    "    ax2.set_ylim(0, 1.05)\n",
    "\n",
    "    # 6. X-axis ticks\n",
    "    if adv_rates_with_backdoor_data:\n",
    "        ax1.set_xticks(ticks=adv_rates_with_backdoor_data)\n",
    "        ax1.set_xticklabels(labels=[f'{r:.1f}' for r in adv_rates_with_backdoor_data])\n",
    "    else:\n",
    "        ax1.set_xticks(ticks=[0.2, 0.3, 0.4])  # Fallback\n",
    "        ax1.set_xticklabels(labels=['0.2', '0.3', '0.4'])\n",
    "    ax1.tick_params(axis='x',)  # Ensure x-tick label size\n",
    "    ax1.grid(True, which='major', linestyle='--', linewidth=0.5, axis='x')\n",
    "\n",
    "    # Legend: More compact, 2 columns below plot\n",
    "    if legend_elements:\n",
    "        legend_elements.sort(key=lambda x: (\"No Attack\" not in x.get_label(), \"Main Acc\" not in x.get_label()))\n",
    "        fig.legend(handles=legend_elements,\n",
    "                   loc='lower center',  # Place below plot\n",
    "                   bbox_to_anchor=(0.5, 0.3),  # Adjust y for spacing below x-axis label\n",
    "                   ncol=2,  # Try 2 columns for 4 items\n",
    "                   frameon=False)  # Remove legend frame for cleaner look in paper\n",
    "\n",
    "    # fig.suptitle(f'{current_aggregation_method}: Performance vs. ASR', fontsize=TITLE_FONT_SIZE, y=0.98,\n",
    "    #              fontweight='bold')\n",
    "    plt.tight_layout(\n",
    "        rect=[0, 0.1, 1, 0.95])  # Adjust rect for suptitle and bottom legend (0.1 at bottom for legend space)\n",
    "    # plt.savefig(f\"{current_aggregation_method}_perf_vs_asr.pdf\", bbox_inches='tight') # Example save\n",
    "    \n",
    "    plt.show()\n",
    "    save_figure_as_pdf(\n",
    "        fig=fig, \n",
    "        output_directory=FIGURE_SAVE_DIR, \n",
    "        base_filename=\"coc_vs_adv_rate\", # Base name describing the plot\n",
    "        current_aggregation_method=AGG_METHOD_TO_ANALYZE,\n",
    "        # other_details=f\"target{int(TARGET_ACCURACY_COC*100)}acc\" # Example other detail\n",
    "    )\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"summary_df_avg is empty or became empty after preprocessing. Skipping Plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-15T23:40:00.945985900Z",
     "start_time": "2025-05-15T23:40:00.814058900Z"
    }
   },
   "id": "31c99e8039d4d5bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "if not summary_df_avg.empty:\n",
    "    # --- Data Preparation ---\n",
    "    plot_data = summary_df_avg.copy() # Assuming it's preprocessed\n",
    "    current_aggregation_method = \"MartFL\" # For title\n",
    "\n",
    "    # Ensure COST_OF_CONVERGENCE_PLOT is ready (handling NaNs as per previous logic)\n",
    "    if 'COST_OF_CONVERGENCE' in plot_data.columns:\n",
    "        plot_data['COST_OF_CONVERGENCE'] = pd.to_numeric(plot_data['COST_OF_CONVERGENCE'], errors='coerce')\n",
    "        if 'TOTAL_COST' in plot_data.columns:\n",
    "            plot_data['TOTAL_COST'] = pd.to_numeric(plot_data['TOTAL_COST'], errors='coerce')\n",
    "            plot_data['COST_OF_CONVERGENCE_PLOT'] = plot_data['COST_OF_CONVERGENCE'].fillna(plot_data['TOTAL_COST'])\n",
    "        else:\n",
    "            plot_data['COST_OF_CONVERGENCE_PLOT'] = plot_data['COST_OF_CONVERGENCE']\n",
    "        if plot_data['COST_OF_CONVERGENCE_PLOT'].isna().any():\n",
    "             print(f\"Warning: {plot_data['COST_OF_CONVERGENCE_PLOT'].isna().sum()} NaN CoC values still present.\")\n",
    "    else:\n",
    "        print(\"COST_OF_CONVERGENCE column not found. Cannot plot.\")\n",
    "        plot_data['COST_OF_CONVERGENCE_PLOT'] = np.nan # Ensure column exists\n",
    "\n",
    "    # 1. \"No Attack\" CoC Baseline (Averaged over IS_SYBIL)\n",
    "    no_attack_coc_data = plot_data[plot_data['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "    if not no_attack_coc_data.empty:\n",
    "        # We want a single CoC value for \"No Attack\" to serve as the baseline\n",
    "        no_attack_baseline_coc = no_attack_coc_data['COST_OF_CONVERGENCE_PLOT'].mean()\n",
    "    else:\n",
    "        no_attack_baseline_coc = np.nan\n",
    "\n",
    "    # 2. \"Backdoor Attack\" CoC Data, averaged over IS_SYBIL for each ADV_RATE\n",
    "    adv_rates_to_plot_on_x_for_attack = [0.1, 0.2, 0.3, 0.4]\n",
    "    backdoor_attack_filtered = plot_data[\n",
    "        (plot_data['ATTACK_METHOD'] == 'Backdoor') &\n",
    "        (plot_data['ADV_RATE'].isin(adv_rates_to_plot_on_x_for_attack))\n",
    "    ].copy()\n",
    "\n",
    "    if not backdoor_attack_filtered.empty:\n",
    "        # Average CoC for \"Backdoor\" attack at each ADV_RATE (averaging out IS_SYBIL here)\n",
    "        backdoor_avg_coc_vs_adv_rate = backdoor_attack_filtered.groupby('ADV_RATE', as_index=False)[\n",
    "            'COST_OF_CONVERGENCE_PLOT'\n",
    "        ].mean().sort_values(by='ADV_RATE')\n",
    "        adv_rates_with_backdoor_coc_data = sorted(backdoor_avg_coc_vs_adv_rate['ADV_RATE'].unique())\n",
    "        print(f\"Plotting averaged 'Backdoor' CoC. ADV_RATEs: {adv_rates_with_backdoor_coc_data}\")\n",
    "    else:\n",
    "        backdoor_avg_coc_vs_adv_rate = pd.DataFrame(columns=['ADV_RATE', 'COST_OF_CONVERGENCE_PLOT'])\n",
    "        adv_rates_with_backdoor_coc_data = []\n",
    "        print(f\"Warning: No 'Backdoor' CoC data for ADV_RATEs {adv_rates_to_plot_on_x_for_attack}.\")\n",
    "\n",
    "    fig, ax = plt.subplots() # Slightly adjusted figsize\n",
    "\n",
    "    # Colors and styles\n",
    "    backdoor_coc_color = 'orangered'\n",
    "    no_attack_coc_color = 'dimgray'\n",
    "\n",
    "    legend_elements = []\n",
    "\n",
    "    # 1. Plot \"No Attack\" CoC as a HORIZONTAL BASELINE LINE\n",
    "    # Spanning from the first to the last ADV_RATE of the attack data\n",
    "    if pd.notna(no_attack_baseline_coc) and adv_rates_with_backdoor_coc_data:\n",
    "        xmin_hline = min(adv_rates_with_backdoor_coc_data)\n",
    "        xmax_hline = max(adv_rates_with_backdoor_coc_data)\n",
    "        ax.hlines(y=no_attack_baseline_coc,\n",
    "                  xmin=xmin_hline, xmax=xmax_hline,\n",
    "                  color=no_attack_coc_color,\n",
    "                  linestyle='--', # Dashed line for baseline\n",
    "                  linewidth=LINE_WIDTH,\n",
    "                  label=f'No Attack ({no_attack_baseline_coc:.0f})') # For legend\n",
    "        legend_elements.append(Line2D([0], [0], color=no_attack_coc_color, linestyle='--', lw=LINE_WIDTH, label=f'No Attack ({no_attack_baseline_coc:.0f})'))\n",
    "    elif pd.notna(no_attack_baseline_coc): # If no attack data, plot as a point at x=0.1 (or another sensible default)\n",
    "        ax.plot([0.1], [no_attack_baseline_coc], marker='D', markersize=MARKER_SIZE+1, color=no_attack_coc_color, linestyle='None', label=f'No Attack ({no_attack_baseline_coc:.0f})')\n",
    "        legend_elements.append(Line2D([0], [0], color=no_attack_coc_color, marker='D', markersize=MARKER_SIZE+1, linestyle='None', label=f'No Attack ({no_attack_baseline_coc:.0f})'))\n",
    "\n",
    "\n",
    "    # 2. Plot \"Backdoor Attack\" CoC (averaged over IS_SYBIL)\n",
    "    if not backdoor_avg_coc_vs_adv_rate.empty:\n",
    "        ax.plot(\n",
    "            backdoor_avg_coc_vs_adv_rate['ADV_RATE'],\n",
    "            backdoor_avg_coc_vs_adv_rate['COST_OF_CONVERGENCE_PLOT'],\n",
    "            color=backdoor_coc_color,\n",
    "            linestyle='-',\n",
    "            marker='o',\n",
    "            linewidth=LINE_WIDTH,\n",
    "            markersize=MARKER_SIZE,\n",
    "            label='Backdoor Attack' # For legend\n",
    "        )\n",
    "        legend_elements.append(Line2D([0], [0], color=backdoor_coc_color, linestyle='-', marker='o', lw=LINE_WIDTH, label='Backdoor Attack'))\n",
    "\n",
    "    ax.set_xlabel('Adversary Rate (Backdoor Attack)', )\n",
    "    ax.set_ylabel(f'Cost of Convergence (Payments)',)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONT_SIZE, pad=6)\n",
    "\n",
    "\n",
    "    # Log Scale for Y-axis (CoC)\n",
    "    valid_coc_values_plot = pd.concat([\n",
    "        pd.Series([no_attack_baseline_coc] if pd.notna(no_attack_baseline_coc) else []),\n",
    "        backdoor_avg_coc_vs_adv_rate['COST_OF_CONVERGENCE_PLOT'] if not backdoor_avg_coc_vs_adv_rate.empty else pd.Series([])\n",
    "    ]).dropna()\n",
    "\n",
    "    if not valid_coc_values_plot.empty and (valid_coc_values_plot > 0).all():\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_ylabel(f'Cost of Convergence (Payments)', fontsize=AXIS_LABEL_FONT_SIZE)\n",
    "        # For log scale, ensure y-grid lines are appropriate\n",
    "        ax.grid(True, which=\"both\", ls=\":\", linewidth=0.5, axis='y') # Minor ticks for log\n",
    "    elif not valid_coc_values_plot.empty:\n",
    "        min_coc_val = valid_coc_values_plot.min()\n",
    "        ax.set_ylim(bottom=max(0, min_coc_val * 0.8 if pd.notna(min_coc_val) else 0)) # Start y a bit below min\n",
    "        ax.grid(True, which=\"major\", ls=\":\", linewidth=0.5, axis='y')\n",
    "    else:\n",
    "        ax.grid(True, which=\"major\", ls=\":\", linewidth=0.5, axis='y')\n",
    "\n",
    "\n",
    "    # X-axis Ticks: Only show 0.1, 0.2, 0.3, 0.4\n",
    "    if adv_rates_with_backdoor_coc_data:\n",
    "        ax.set_xticks(ticks=adv_rates_with_backdoor_coc_data)\n",
    "        ax.set_xticklabels(labels=[f'{r:.1f}' for r in adv_rates_with_backdoor_coc_data])\n",
    "    elif pd.notna(no_attack_baseline_coc) : # If only no_attack_data, show a default x point\n",
    "        ax.set_xticks(ticks=[0.1]) # Or a sensible single point\n",
    "        ax.set_xticklabels(labels=['Baseline Ref.'])\n",
    "    else: # Fallback\n",
    "        ax.set_xticks(ticks=adv_rates_to_plot_on_x_for_attack)\n",
    "        ax.set_xticklabels(labels=[f'{r:.1f}' for r in adv_rates_to_plot_on_x_for_attack])\n",
    "\n",
    "    ax.grid(True, which='major', linestyle='--', linewidth=0.5, axis='x') # Grid for x-axis\n",
    "\n",
    "\n",
    "    # Legend: Simple, 2 items\n",
    "    if legend_elements:\n",
    "        ax.legend(handles=legend_elements,\n",
    "                  loc='best', # Let matplotlib decide best location inside plot\n",
    "                  frameon=True, edgecolor='lightgray') # Add a light frame\n",
    "\n",
    "    # fig.suptitle(f'{current_aggregation_method}: Impact on Convergence Speed (Cost)',\n",
    "    #              fontsize=TITLE_FONT_SIZE, y=0.98, fontweight='bold')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.94]) # Adjust for suptitle\n",
    "    # plt.savefig(f\"{current_aggregation_method}_coc_speed_impact.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    save_figure_as_pdf(\n",
    "        fig=fig, \n",
    "        output_directory=FIGURE_SAVE_DIR, \n",
    "        base_filename=\"convergence_cost\", # Base name describing the plot\n",
    "        current_aggregation_method=current_aggregation_method,\n",
    "        # other_details=f\"target{int(TARGET_ACCURACY_COC*100)}acc\" # Example other detail\n",
    "    )\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"summary_df_avg is empty or became empty after preprocessing. Skipping Plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.466753500Z"
    }
   },
   "id": "904af344040bd4a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# This cell depends on 'summary_df_avg' being loaded and preprocessed in Cell 1.\n",
    "\n",
    "if 'summary_df_avg' in locals() and not summary_df_avg.empty:\n",
    "    plot_data_coc = summary_df_avg.copy()\n",
    "    # Assuming AGGREGATION_METHOD is constant or you filter for a specific one\n",
    "    aggregation_methods_present = plot_data_coc['AGGREGATION_METHOD'].unique()\n",
    "    current_aggregation_method = AGG_METHOD_TO_ANALYZE\n",
    "    if len(aggregation_methods_present) > 1:\n",
    "        print(f\"Warning (CoC Plot): Multiple aggregation methods. Plotting for '{current_aggregation_method}'.\")\n",
    "        plot_data_coc = plot_data_coc[plot_data_coc['AGGREGATION_METHOD'] == current_aggregation_method]\n",
    "\n",
    "    TARGET_ACCURACY_COC = 0.85 # Ensure this matches your experiment setup for the title\n",
    "\n",
    "    # Ensure COST_OF_CONVERGENCE_PLOT column is ready from Cell 1\n",
    "    if 'COST_OF_CONVERGENCE_PLOT' not in plot_data_coc.columns:\n",
    "        if 'COST_OF_CONVERGENCE' in plot_data_coc.columns: # Attempt to create it if base column exists\n",
    "            plot_data_coc['COST_OF_CONVERGENCE'] = pd.to_numeric(plot_data_coc['COST_OF_CONVERGENCE'], errors='coerce')\n",
    "            if 'TOTAL_COST' in plot_data_coc.columns:\n",
    "                 plot_data_coc['TOTAL_COST'] = pd.to_numeric(plot_data_coc['TOTAL_COST'], errors='coerce')\n",
    "                 plot_data_coc['COST_OF_CONVERGENCE_PLOT'] = plot_data_coc['COST_OF_CONVERGENCE'].fillna(plot_data_coc['TOTAL_COST'])\n",
    "            else:\n",
    "                 plot_data_coc['COST_OF_CONVERGENCE_PLOT'] = plot_data_coc['COST_OF_CONVERGENCE']\n",
    "            plot_data_coc.dropna(subset=['COST_OF_CONVERGENCE_PLOT'], inplace=True)\n",
    "        else:\n",
    "            print(\"Error (CoC Plot): 'COST_OF_CONVERGENCE' or 'COST_OF_CONVERGENCE_PLOT' not found.\")\n",
    "            plot_data_coc = pd.DataFrame() # Prevent plotting\n",
    "\n",
    "    if not plot_data_coc.empty and 'COST_OF_CONVERGENCE_PLOT' in plot_data_coc.columns and not plot_data_coc['COST_OF_CONVERGENCE_PLOT'].isna().all():\n",
    "        no_attack_coc_data = plot_data_coc[plot_data_coc['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "        no_attack_baseline_coc = no_attack_coc_data['COST_OF_CONVERGENCE_PLOT'].mean() if not no_attack_coc_data.empty else np.nan\n",
    "\n",
    "        adv_rates_to_plot_on_x = [0.1, 0.2, 0.3, 0.4]\n",
    "        backdoor_attack_coc_filtered = plot_data_coc[\n",
    "            (plot_data_coc['attack_objective'] == 'Backdoor') &\n",
    "            (plot_data_coc['ADV_RATE'].isin(adv_rates_to_plot_on_x))\n",
    "        ].copy()\n",
    "\n",
    "        backdoor_coc_by_sybil = pd.DataFrame()\n",
    "        adv_rates_present_coc = []\n",
    "        if not backdoor_attack_coc_filtered.empty:\n",
    "            backdoor_coc_by_sybil = backdoor_attack_coc_filtered.groupby(\n",
    "                ['ADV_RATE', 'IS_SYBIL'], as_index=False\n",
    "            )['COST_OF_CONVERGENCE_PLOT'].mean().sort_values(by=['IS_SYBIL', 'ADV_RATE'])\n",
    "            adv_rates_present_coc = sorted(backdoor_coc_by_sybil['ADV_RATE'].unique())\n",
    "\n",
    "        # --- Plotting CoC ---\n",
    "        if not backdoor_coc_by_sybil.empty or pd.notna(no_attack_baseline_coc):\n",
    "            TITLE_FONT_SIZE = 14; AXIS_LABEL_FONT_SIZE = 12; TICK_LABEL_FONT_SIZE = 11\n",
    "            LEGEND_FONT_SIZE = 10; LINE_WIDTH = 2.2; MARKER_SIZE = 7\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            colors = { 'No Attack': 'dimgray', 'Backdoor (Standard)': 'saddlebrown', 'Backdoor (Sybil)': 'darkgoldenrod' }\n",
    "            linestyles = { 'No Attack': (0, (5, 2)), 'Backdoor (Standard)': '-', 'Backdoor (Sybil)': '--' }\n",
    "            markers = { 'Backdoor (Standard)': 'o', 'Backdoor (Sybil)': 's' }\n",
    "            legend_elements_coc = []\n",
    "\n",
    "            xmin_hline = min(adv_rates_present_coc) if adv_rates_present_coc else min(adv_rates_to_plot_on_x)\n",
    "            xmax_hline = max(adv_rates_present_coc) if adv_rates_present_coc else max(adv_rates_to_plot_on_x)\n",
    "\n",
    "            if pd.notna(no_attack_baseline_coc):\n",
    "                ax.hlines(y=no_attack_baseline_coc, xmin=xmin_hline, xmax=xmax_hline, color=colors['No Attack'], linestyle=linestyles['No Attack'], linewidth=LINE_WIDTH)\n",
    "                legend_elements_coc.append(Line2D([0],[0],color=colors['No Attack'],lw=LINE_WIDTH,ls=linestyles['No Attack'],label=f'No Attack (CoC: {no_attack_baseline_coc:.0f})'))\n",
    "            if not backdoor_coc_by_sybil.empty:\n",
    "                data_std = backdoor_coc_by_sybil[backdoor_coc_by_sybil['IS_SYBIL'] == 'False'] # Assumes 'False' for Standard\n",
    "                if not data_std.empty:\n",
    "                    ax.plot(data_std['ADV_RATE'], data_std['COST_OF_CONVERGENCE_PLOT'], color=colors['Backdoor (Standard)'], marker=markers['Backdoor (Standard)'], ls=linestyles['Backdoor (Standard)'], lw=LINE_WIDTH, ms=MARKER_SIZE)\n",
    "                    legend_elements_coc.append(Line2D([0],[0],color=colors['Backdoor (Standard)'],lw=LINE_WIDTH,marker=markers['Backdoor (Standard)'],ls=linestyles['Backdoor (Standard)'],label='Backdoor (Standard) CoC'))\n",
    "                data_mimic = backdoor_coc_by_sybil[backdoor_coc_by_sybil['IS_SYBIL'] == 'mimic']\n",
    "                if not data_mimic.empty:\n",
    "                    ax.plot(data_mimic['ADV_RATE'], data_mimic['COST_OF_CONVERGENCE_PLOT'], color=colors['Backdoor (Sybil)'], marker=markers['Backdoor (Sybil)'], ls=linestyles['Backdoor (Sybil)'], lw=LINE_WIDTH, ms=MARKER_SIZE)\n",
    "                    legend_elements_coc.append(Line2D([0],[0],color=colors['Backdoor (Sybil)'],lw=LINE_WIDTH,marker=markers['Backdoor (Sybil)'],ls=linestyles['Backdoor (Sybil)'],label='Backdoor (Sybil) CoC'))\n",
    "\n",
    "            ax.set_xlabel('Adversary Rate (Backdoor Attack)')\n",
    "            ax.set_ylabel(f'Cost of Convergence (Payments)',)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONT_SIZE, pad=6)\n",
    "            \n",
    "            # Log Scale for CoC\n",
    "            valid_coc_plot_vals_current = pd.concat([\n",
    "                pd.Series([no_attack_baseline_coc] if pd.notna(no_attack_baseline_coc) else []),\n",
    "                backdoor_coc_by_sybil['COST_OF_CONVERGENCE_PLOT'] if not backdoor_coc_by_sybil.empty else pd.Series([])\n",
    "            ]).dropna()\n",
    "            if not valid_coc_plot_vals_current.empty and (valid_coc_plot_vals_current > 0).all():\n",
    "                ax.set_yscale('log'); ax.set_ylabel(f'Cost of Convergence (Log Scale)',)\n",
    "            elif not valid_coc_plot_vals_current.empty :\n",
    "                min_val = valid_coc_plot_vals_current.min(); ax.set_ylim(bottom=max(0, min_val*0.9 if pd.notna(min_val) else 0))\n",
    "            \n",
    "            plot_xticks_coc = adv_rates_present_coc if adv_rates_present_coc else adv_rates_to_plot_on_x\n",
    "            if plot_xticks_coc: ax.set_xticks(ticks=plot_xticks_coc); ax.set_xticklabels(labels=[f'{r:.1f}' for r in plot_xticks_coc])\n",
    "            ax.grid(True, which=\"both\", ls=\":\", linewidth=0.5)\n",
    "            if legend_elements_coc:\n",
    "                ax.legend(handles=legend_elements_coc, title='Attack Condition (CoC)', loc='best', frameon=True, edgecolor='lightgray')\n",
    "            # fig.suptitle(f'{current_aggregation_method}: Attack Impact on Convergence Cost (to {TARGET_ACCURACY_COC*100:.0f}% Acc.)', fontsize=TITLE_FONT_SIZE, y=0.99, fontweight='bold')\n",
    "            plt.tight_layout(rect=[0,0,1,0.95])\n",
    "            fig = plt.gcf()\n",
    "            save_figure_as_pdf(\n",
    "                fig=fig, \n",
    "                output_directory=FIGURE_SAVE_DIR, \n",
    "                base_filename=\"convergence_cost_varying_adv\", # Base name describing the plot\n",
    "                current_aggregation_method=current_aggregation_method,\n",
    "                # other_details=f\"target{int(TARGET_ACCURACY_COC*100)}acc\" # Example other detail\n",
    "            )\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(\"Not enough data for CoC plot after filtering.\")\n",
    "else:\n",
    "    print(\"DataFrame 'summary_df_avg' is not available for CoC plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.467253500Z"
    }
   },
   "id": "6503e7452d61724c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Seaborn for barplot\n",
    "import numpy as np\n",
    "\n",
    "# This cell depends on 'summary_df_avg' being loaded and preprocessed by Cell 1,\n",
    "# and containing the 'ROUNDS_TO_XXACC' columns.\n",
    "\n",
    "if 'summary_df_avg' in locals() and not summary_df_avg.empty:\n",
    "    plot_data_milestones = summary_df_avg.copy()\n",
    "    current_aggregation_method = \"MartFL\" # Or get from df\n",
    "\n",
    "    # --- Configuration for this plot ---\n",
    "    # 1. CHOOSE THE FIXED ADVERSARY RATE for attack scenarios\n",
    "    FIXED_ADV_RATE_FOR_COMPARISON = 0.3 # Example: Compare at 30% adversary rate\n",
    "    \n",
    "    # 2. CHOOSE THE ACCURACY MILESTONES to display on the X-axis\n",
    "    # These must match the labels from your ROUNDS_TO_XXACC columns (e.g., \"70\", \"80\", \"85\")\n",
    "    milestone_acc_labels_to_plot = [\"70\", \"80\", \"85\"] # Example\n",
    "    milestone_cols_to_use = [f'COST_TO_{label}ACC' for label in milestone_acc_labels_to_plot]\n",
    "\n",
    "    # Verify all chosen milestone columns exist\n",
    "    missing_milestone_cols = [col for col in milestone_cols_to_use if col not in plot_data_milestones.columns]\n",
    "    if missing_milestone_cols:\n",
    "        print(f\"Error (Milestone Bar Plot): Columns missing: {', '.join(missing_milestone_cols)}. Cannot create plot.\")\n",
    "    elif plot_data_milestones[milestone_cols_to_use].isna().all().all():\n",
    "        print(f\"Error (Milestone Bar Plot): All chosen milestone columns are entirely NaN.\")\n",
    "    else:\n",
    "        # Ensure columns are numeric\n",
    "        for col in milestone_cols_to_use:\n",
    "            if col in plot_data_milestones.columns:\n",
    "                 plot_data_milestones[col] = pd.to_numeric(plot_data_milestones[col], errors='coerce')\n",
    "        \n",
    "        # --- Prepare Data for Bar Chart ---\n",
    "        data_for_bars = []\n",
    "\n",
    "        # 1. No Attack Data (ADV_RATE is 0.0)\n",
    "        no_attack_data = plot_data_milestones[plot_data_milestones['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "        if not no_attack_data.empty:\n",
    "            for col, acc_label in zip(milestone_cols_to_use, milestone_acc_labels_to_plot):\n",
    "                if col in no_attack_data.columns:\n",
    "                    avg_rounds = no_attack_data[col].mean() # Average over IS_SYBIL for No Attack\n",
    "                    if pd.notna(avg_rounds):\n",
    "                        data_for_bars.append({'Condition': 'No Attack', \n",
    "                                              'Milestone': f'{acc_label}% Acc', \n",
    "                                              'Rounds to Converge': avg_rounds})\n",
    "\n",
    "        # 2. Backdoor Attack (Standard) Data at FIXED_ADV_RATE_FOR_COMPARISON\n",
    "        std_backdoor_data = plot_data_milestones[\n",
    "            (plot_data_milestones['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_milestones['IS_SYBIL'] == 'False') &\n",
    "            (np.isclose(plot_data_milestones['ADV_RATE'], FIXED_ADV_RATE_FOR_COMPARISON))\n",
    "        ].copy()\n",
    "        if not std_backdoor_data.empty:\n",
    "            for col, acc_label in zip(milestone_cols_to_use, milestone_acc_labels_to_plot):\n",
    "                if col in std_backdoor_data.columns:\n",
    "                    avg_rounds = std_backdoor_data[col].mean() # Should be one value if adv_rate is fixed\n",
    "                    if pd.notna(avg_rounds):\n",
    "                        data_for_bars.append({'Condition': 'Backdoor (Standard)', \n",
    "                                              'Milestone': f'{acc_label}% Acc', \n",
    "                                              'Rounds to Converge': avg_rounds})\n",
    "\n",
    "        # 3. Backdoor Attack (Mimic) Data at FIXED_ADV_RATE_FOR_COMPARISON\n",
    "        mimic_backdoor_data = plot_data_milestones[\n",
    "            (plot_data_milestones['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_milestones['IS_SYBIL'] == 'mimic') &\n",
    "            (np.isclose(plot_data_milestones['ADV_RATE'], FIXED_ADV_RATE_FOR_COMPARISON))\n",
    "        ].copy()\n",
    "        if not mimic_backdoor_data.empty:\n",
    "            for col, acc_label in zip(milestone_cols_to_use, milestone_acc_labels_to_plot):\n",
    "                if col in mimic_backdoor_data.columns:\n",
    "                    avg_rounds = mimic_backdoor_data[col].mean()\n",
    "                    if pd.notna(avg_rounds):\n",
    "                        data_for_bars.append({'Condition': 'Backdoor (Sybil)', \n",
    "                                              'Milestone': f'{acc_label}% Acc', \n",
    "                                              'Rounds to Converge': avg_rounds})\n",
    "        \n",
    "        df_for_bars = pd.DataFrame(data_for_bars)\n",
    "\n",
    "        # --- Plotting Grouped Bar Chart ---\n",
    "        if not df_for_bars.empty:            \n",
    "            plt.figure(figsize=(9, 5.5)) # Adjust size for clarity\n",
    "\n",
    "            # Define a palette for the conditions\n",
    "            condition_palette = {\n",
    "                'No Attack': 'dimgray',\n",
    "                'Backdoor (Standard)': 'orangered',\n",
    "                'Backdoor (Sybil)': 'darkviolet'\n",
    "            }\n",
    "            \n",
    "            # Order for milestones on x-axis\n",
    "            milestone_order = [f\"{label}% Acc\" for label in milestone_acc_labels_to_plot]\n",
    "\n",
    "            sns.barplot(\n",
    "                data=df_for_bars,\n",
    "                x='Milestone',\n",
    "                y='Rounds to Converge',\n",
    "                hue='Condition', # This groups the bars\n",
    "                order=milestone_order, # Ensure milestones are in logical order\n",
    "                hue_order=['No Attack', 'Backdoor (Standard)', 'Backdoor (Sybil)'], # Consistent legend order\n",
    "                palette=condition_palette,\n",
    "            )\n",
    "\n",
    "            plt.xlabel('Target Accuracy Milestone')\n",
    "            plt.ylabel('Avg. Cost to Reach Milestone')\n",
    "            \n",
    "            max_rounds_plot = df_for_bars['Rounds to Converge'].max()\n",
    "            plt.ylim(0, max_rounds_plot * 1.15 if pd.notna(max_rounds_plot) else 200)\n",
    "\n",
    "\n",
    "            plt.grid(True, which='major', linestyle=':', linewidth=0.6, axis='y')\n",
    "            plt.gca().set_axisbelow(True) # Grid behind bars\n",
    "\n",
    "            plt.legend(title='Attack Scenario', loc='upper left', frameon=True, edgecolor='lightgray')\n",
    "            \n",
    "            attack_adv_rate_info = \"\"\n",
    "            if not no_attack_data.empty and (not std_backdoor_data.empty or not mimic_backdoor_data.empty):\n",
    "                attack_adv_rate_info = f\" (Attacks at {FIXED_ADV_RATE_FOR_COMPARISON*100:.0f}% Adversary Rate)\"\n",
    "\n",
    "\n",
    "            # plt.title(f'{current_aggregation_method}: Convergence Speed to Accuracy Milestones{attack_adv_rate_info}',\n",
    "            #           fontsize=TITLE_FONT_SIZE, y=1.02, fontweight='bold')\n",
    "            plt.tight_layout(rect=[0,0,1,0.96])\n",
    "            # plt.savefig(f\"{current_aggregation_method}_speed_to_milestones_adv{FIXED_ADV_RATE_FOR_COMPARISON}.pdf\", bbox_inches='tight')\n",
    "            fig = plt.gcf()\n",
    "            save_figure_as_pdf(\n",
    "                fig=fig, \n",
    "                output_directory=FIGURE_SAVE_DIR, \n",
    "                base_filename=\"milestone_cost\", # Base name describing the plot\n",
    "                current_aggregation_method=current_aggregation_method,\n",
    "                # other_details=f\"target{int(TARGET_ACCURACY_COC*100)}acc\" # Example other detail\n",
    "            )\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Not enough data to create the milestone speed bar chart after filtering.\")\n",
    "else:\n",
    "    print(\"DataFrame 'summary_df_avg' is not available. Skipping milestone speed plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.467753300Z"
    }
   },
   "id": "8a9c6b8a1148a596"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Seaborn for barplot\n",
    "import numpy as np\n",
    "\n",
    "# This cell depends on 'summary_df_avg' being loaded and preprocessed by Cell 1,\n",
    "# and containing the 'ROUNDS_TO_XXACC' columns.\n",
    "\n",
    "if 'summary_df_avg' in locals() and not summary_df_avg.empty:\n",
    "    plot_data_milestones = summary_df_avg.copy()\n",
    "    current_aggregation_method = \"MartFL\" # Or get from df\n",
    "\n",
    "    # --- Configuration for this plot ---\n",
    "    # 1. CHOOSE THE FIXED ADVERSARY RATE for attack scenarios\n",
    "    FIXED_ADV_RATE_FOR_COMPARISON = 0.3 # Example: Compare at 30% adversary rate\n",
    "    \n",
    "    # 2. CHOOSE THE ACCURACY MILESTONES to display on the X-axis\n",
    "    # These must match the labels from your ROUNDS_TO_XXACC columns (e.g., \"70\", \"80\", \"85\")\n",
    "    milestone_acc_labels_to_plot = [\"70\", \"80\", \"85\"] # Example\n",
    "    milestone_cols_to_use = [f'ROUNDS_TO_{label}ACC' for label in milestone_acc_labels_to_plot]\n",
    "\n",
    "    # Verify all chosen milestone columns exist\n",
    "    missing_milestone_cols = [col for col in milestone_cols_to_use if col not in plot_data_milestones.columns]\n",
    "    if missing_milestone_cols:\n",
    "        print(f\"Error (Milestone Bar Plot): Columns missing: {', '.join(missing_milestone_cols)}. Cannot create plot.\")\n",
    "    elif plot_data_milestones[milestone_cols_to_use].isna().all().all():\n",
    "        print(f\"Error (Milestone Bar Plot): All chosen milestone columns are entirely NaN.\")\n",
    "    else:\n",
    "        # Ensure columns are numeric\n",
    "        for col in milestone_cols_to_use:\n",
    "            if col in plot_data_milestones.columns:\n",
    "                 plot_data_milestones[col] = pd.to_numeric(plot_data_milestones[col], errors='coerce')\n",
    "        \n",
    "        # --- Prepare Data for Bar Chart ---\n",
    "        data_for_bars = []\n",
    "\n",
    "        # 1. No Attack Data (ADV_RATE is 0.0)\n",
    "        no_attack_data = plot_data_milestones[plot_data_milestones['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "        if not no_attack_data.empty:\n",
    "            for col, acc_label in zip(milestone_cols_to_use, milestone_acc_labels_to_plot):\n",
    "                if col in no_attack_data.columns:\n",
    "                    avg_rounds = no_attack_data[col].mean() # Average over IS_SYBIL for No Attack\n",
    "                    if pd.notna(avg_rounds):\n",
    "                        data_for_bars.append({'Condition': 'No Attack', \n",
    "                                              'Milestone': f'{acc_label}% Acc', \n",
    "                                              'Rounds to Converge': avg_rounds})\n",
    "\n",
    "        # 2. Backdoor Attack (Standard) Data at FIXED_ADV_RATE_FOR_COMPARISON\n",
    "        std_backdoor_data = plot_data_milestones[\n",
    "            (plot_data_milestones['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_milestones['IS_SYBIL'] == 'False') &\n",
    "            (np.isclose(plot_data_milestones['ADV_RATE'], FIXED_ADV_RATE_FOR_COMPARISON))\n",
    "        ].copy()\n",
    "        if not std_backdoor_data.empty:\n",
    "            for col, acc_label in zip(milestone_cols_to_use, milestone_acc_labels_to_plot):\n",
    "                if col in std_backdoor_data.columns:\n",
    "                    avg_rounds = std_backdoor_data[col].mean() # Should be one value if adv_rate is fixed\n",
    "                    if pd.notna(avg_rounds):\n",
    "                        data_for_bars.append({'Condition': 'Backdoor (Standard)', \n",
    "                                              'Milestone': f'{acc_label}% Acc', \n",
    "                                              'Rounds to Converge': avg_rounds})\n",
    "\n",
    "        # 3. Backdoor Attack (Mimic) Data at FIXED_ADV_RATE_FOR_COMPARISON\n",
    "        mimic_backdoor_data = plot_data_milestones[\n",
    "            (plot_data_milestones['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_milestones['IS_SYBIL'] == 'mimic') &\n",
    "            (np.isclose(plot_data_milestones['ADV_RATE'], FIXED_ADV_RATE_FOR_COMPARISON))\n",
    "        ].copy()\n",
    "        if not mimic_backdoor_data.empty:\n",
    "            for col, acc_label in zip(milestone_cols_to_use, milestone_acc_labels_to_plot):\n",
    "                if col in mimic_backdoor_data.columns:\n",
    "                    avg_rounds = mimic_backdoor_data[col].mean()\n",
    "                    if pd.notna(avg_rounds):\n",
    "                        data_for_bars.append({'Condition': 'Backdoor (Sybil)', \n",
    "                                              'Milestone': f'{acc_label}% Acc', \n",
    "                                              'Rounds to Converge': avg_rounds})\n",
    "        \n",
    "        df_for_bars = pd.DataFrame(data_for_bars)\n",
    "\n",
    "        # --- Plotting Grouped Bar Chart ---\n",
    "        if not df_for_bars.empty:\n",
    "            \n",
    "            plt.figure(figsize=(9, 5.5)) # Adjust size for clarity\n",
    "\n",
    "            # Define a palette for the conditions\n",
    "            condition_palette = {\n",
    "                'No Attack': 'dimgray',\n",
    "                'Backdoor (Standard)': 'orangered',\n",
    "                'Backdoor (Sybil)': 'darkviolet'\n",
    "            }\n",
    "            \n",
    "            # Order for milestones on x-axis\n",
    "            milestone_order = [f\"{label}% Acc\" for label in milestone_acc_labels_to_plot]\n",
    "\n",
    "            sns.barplot(\n",
    "                data=df_for_bars,\n",
    "                x='Milestone',\n",
    "                y='Rounds to Converge',\n",
    "                hue='Condition', # This groups the bars\n",
    "                order=milestone_order, # Ensure milestones are in logical order\n",
    "                hue_order=['No Attack', 'Backdoor (Standard)', 'Backdoor (Sybil)'], # Consistent legend order\n",
    "                palette=condition_palette,\n",
    "                # errorbar=None # If summary_df_avg already contains averages\n",
    "            )\n",
    "\n",
    "            plt.xlabel('Target Accuracy Milestone')\n",
    "            plt.ylabel('Avg. Rounds to Reach Milestone')\n",
    "            \n",
    "            # Set y-limit (optional, adjust based on your data)\n",
    "            max_rounds_plot = df_for_bars['Rounds to Converge'].max()\n",
    "            plt.ylim(0, max_rounds_plot * 1.15 if pd.notna(max_rounds_plot) else 200)\n",
    "\n",
    "\n",
    "            plt.grid(True, which='major', linestyle=':', linewidth=0.6, axis='y')\n",
    "            plt.gca().set_axisbelow(True) # Grid behind bars\n",
    "\n",
    "            plt.legend(title='Attack Scenario', loc='upper left', frameon=True, edgecolor='lightgray')\n",
    "            \n",
    "            attack_adv_rate_info = \"\"\n",
    "            if not no_attack_data.empty and (not std_backdoor_data.empty or not mimic_backdoor_data.empty):\n",
    "                attack_adv_rate_info = f\" (Attacks at {FIXED_ADV_RATE_FOR_COMPARISON*100:.0f}% Adversary Rate)\"\n",
    "\n",
    "\n",
    "            # plt.title(f'{current_aggregation_method}: Convergence Speed to Accuracy Milestones{attack_adv_rate_info}',\n",
    "            #           fontsize=TITLE_FONT_SIZE, y=1.02, fontweight='bold')\n",
    "            plt.tight_layout(rect=[0,0,1,0.96])\n",
    "            # plt.savefig(f\"{current_aggregation_method}_speed_to_milestones_adv{FIXED_ADV_RATE_FOR_COMPARISON}.pdf\", bbox_inches='tight')\n",
    "            fig = plt.gcf()\n",
    "            save_figure_as_pdf(\n",
    "                fig=fig, \n",
    "                output_directory=FIGURE_SAVE_DIR, \n",
    "                base_filename=\"milestone_round\", # Base name describing the plot\n",
    "                current_aggregation_method=current_aggregation_method,\n",
    "                # other_details=f\"target{int(TARGET_ACCURACY_COC*100)}acc\" # Example other detail\n",
    "            )\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            print(\"Not enough data to create the milestone speed bar chart after filtering.\")\n",
    "else:\n",
    "    print(\"DataFrame 'summary_df_avg' is not available. Skipping milestone speed plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.468253700Z"
    }
   },
   "id": "a018806bc89f10b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# This cell depends on 'summary_df_avg' being loaded and preprocessed in Cell 1.\n",
    "# It requires 'AVG_COST_PER_ROUND_BENIGN' and 'AVG_COST_PER_ROUND_MALICIOUS'\n",
    "# (which may have been derived in Cell 1).\n",
    "\n",
    "if 'summary_df_avg' in locals() and not summary_df_avg.empty:\n",
    "    plot_data_cost_bar = summary_df_avg.copy()\n",
    "    current_aggregation_method = \"MartFL\" # Assuming 'MartFL'\n",
    "\n",
    "    # --- Columns needed for cost composition ---\n",
    "    cost_benign_col = 'AVG_COST_PER_ROUND_BENIGN'\n",
    "    cost_mal_col = 'AVG_COST_PER_ROUND_MALICIOUS'\n",
    "    \n",
    "    # Verify required columns exist and are not all NaN\n",
    "    if not (cost_benign_col in plot_data_cost_bar.columns and cost_mal_col in plot_data_cost_bar.columns):\n",
    "        print(f\"Error (Cost Bar Plot): Cost composition columns ('{cost_benign_col}', '{cost_mal_col}') not found. Check Cell 1 derivation.\")\n",
    "    elif plot_data_cost_bar[[cost_benign_col, cost_mal_col]].isna().all().all():\n",
    "        print(f\"Error (Cost Bar Plot): Cost composition columns are entirely NaN.\")\n",
    "    else:\n",
    "        # Ensure columns are numeric (already handled by preprocess_experiment_data if listed in FLOAT_PRECISIONS)\n",
    "        # Drop rows if either essential cost component is NaN for this plot\n",
    "        plot_data_cost_bar.dropna(subset=[cost_benign_col, cost_mal_col], how='any', inplace=True)\n",
    "\n",
    "        # --- Prepare Data for the 3 Scenarios for Bar Chart ---\n",
    "        # 1. No Attack Scenario (ADV_RATE is 0.0 for these)\n",
    "        no_attack_cost_data = plot_data_cost_bar[plot_data_cost_bar['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "        # Average over IS_SYBIL for a single \"No Attack\" bar\n",
    "        avg_no_attack_cost_benign = no_attack_cost_data[cost_benign_col].mean() if not no_attack_cost_data.empty else 0\n",
    "        avg_no_attack_cost_mal = no_attack_cost_data[cost_mal_col].mean() if not no_attack_cost_data.empty else 0 # Should be 0\n",
    "\n",
    "        # 2. Backdoor Attack (Standard) - at a specific ADV_RATE\n",
    "        REPRESENTATIVE_ADV_RATE_FOR_ATTACK = 0.3 # Or choose another representative rate\n",
    "        \n",
    "        std_backdoor_data = plot_data_cost_bar[\n",
    "            (plot_data_cost_bar['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_cost_bar['IS_SYBIL'] == 'False') & # Standard\n",
    "            (np.isclose(plot_data_cost_bar['ADV_RATE'], REPRESENTATIVE_ADV_RATE_FOR_ATTACK))\n",
    "        ].copy()\n",
    "        avg_std_backdoor_cost_benign = std_backdoor_data[cost_benign_col].mean() if not std_backdoor_data.empty else 0\n",
    "        avg_std_backdoor_cost_mal = std_backdoor_data[cost_mal_col].mean() if not std_backdoor_data.empty else 0\n",
    "\n",
    "        # 3. Backdoor Attack (Mimic) - at the same representative ADV_RATE\n",
    "        mimic_backdoor_data = plot_data_cost_bar[\n",
    "            (plot_data_cost_bar['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_cost_bar['IS_SYBIL'] == 'mimic') &\n",
    "            (np.isclose(plot_data_cost_bar['ADV_RATE'], REPRESENTATIVE_ADV_RATE_FOR_ATTACK))\n",
    "        ].copy()\n",
    "        avg_mimic_backdoor_cost_benign = mimic_backdoor_data[cost_benign_col].mean() if not mimic_backdoor_data.empty else 0\n",
    "        avg_mimic_backdoor_cost_mal = mimic_backdoor_data[cost_mal_col].mean() if not mimic_backdoor_data.empty else 0\n",
    "\n",
    "        # --- Data for Bar Chart ---\n",
    "        scenarios = ['No Attack', f'Backdoor (Std)\\nADV_RATE={REPRESENTATIVE_ADV_RATE_FOR_ATTACK}', \n",
    "                     f'Backdoor (Sybil)\\nADV_RATE={REPRESENTATIVE_ADV_RATE_FOR_ATTACK}']\n",
    "        benign_costs = [avg_no_attack_cost_benign, avg_std_backdoor_cost_benign, avg_mimic_backdoor_cost_benign]\n",
    "        malicious_costs = [avg_no_attack_cost_mal, avg_std_backdoor_cost_mal, avg_mimic_backdoor_cost_mal]\n",
    "\n",
    "        # --- Plotting Stacked Bar Chart ---\n",
    "        if any(pd.notna(c) for c in benign_costs + malicious_costs) and any(c > 0 for c in benign_costs + malicious_costs):\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            x_pos = np.arange(len(scenarios))\n",
    "\n",
    "            bar1 = ax.bar(x_pos, benign_costs, label='Cost from Benign Sellers', color='cornflowerblue', alpha=0.9)\n",
    "            bar2 = ax.bar(x_pos, malicious_costs, bottom=benign_costs, label='Cost from Malicious Sellers', color='salmon', alpha=0.9)\n",
    "\n",
    "            ax.set_xlabel('Attack Scenario', )\n",
    "            ax.set_ylabel('Avg. Cost per Round (Selections)')\n",
    "            ax.tick_params(axis='y')\n",
    "            \n",
    "            ax.set_xticks(x_pos)\n",
    "            ax.set_xticklabels(scenarios, rotation=0, ha=\"center\")\n",
    "\n",
    "            # Add values on top of bars for total cost\n",
    "            for i in range(len(x_pos)):\n",
    "                total_height = (benign_costs[i] if pd.notna(benign_costs[i]) else 0) + \\\n",
    "                               (malicious_costs[i] if pd.notna(malicious_costs[i]) else 0)\n",
    "                if total_height > 0: # Only add text if bar has height\n",
    "                     ax.text(x_pos[i], total_height + 0.02 * (ax.get_ylim()[1] - ax.get_ylim()[0]), # Position above bar\n",
    "                            f'{total_height:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "            ax.grid(True, which='major', linestyle=':', linewidth=0.6, axis='y'); ax.set_axisbelow(True)\n",
    "            ax.legend(title='Cost Component', loc='upper left', frameon=True, edgecolor='lightgray')\n",
    "            # fig.suptitle(f'{current_aggregation_method}: Composition of Avg. Cost per Round by Attack Scenario', fontsize=TITLE_FONT_SIZE, y=0.98, fontweight='bold')\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            fig = plt.gcf()\n",
    "            save_figure_as_pdf(\n",
    "                fig=fig, \n",
    "                output_directory=FIGURE_SAVE_DIR, \n",
    "                base_filename=\"convergence_cost_component_varying_adv\", # Base name describing the plot\n",
    "                current_aggregation_method=current_aggregation_method,\n",
    "                # other_details=f\"target{int(TARGET_ACCURACY_COC*100)}acc\" # Example other detail\n",
    "            )\n",
    "        else:\n",
    "            print(\"Not enough data to plot Cost Composition bar chart after filtering for specific scenarios.\")\n",
    "else:\n",
    "    print(\"DataFrame 'summary_df_avg' is not available. Skipping Cost Composition plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.468754600Z"
    }
   },
   "id": "2c14d0f8466973a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# This cell depends on 'all_rounds_df' being loaded and preprocessed by Cell 1.\n",
    "# It should contain per-round 'main_acc', 'asr', 'round', 'AGGREGATION_METHOD',\n",
    "# and other CONFIG_ columns like 'ADV_RATE', 'ATTACK_METHOD', 'IS_SYBIL', etc.\n",
    "\n",
    "# --- Example: For standalone testing, ensure all_rounds_df exists ---\n",
    "# if 'all_rounds_df' not in locals() or all_rounds_df.empty:\n",
    "#     print(\"INFO: 'all_rounds_df' not found or empty. Creating a dummy DataFrame for demonstration.\")\n",
    "#     num_rounds_dummy = 50; agg_methods_dummy = ['MartFL', 'FedAvg']\n",
    "#     dummy_round_data_list = []\n",
    "#     for agg_m in agg_methods_dummy:\n",
    "#         for r in range(num_rounds_dummy):\n",
    "#             dummy_round_data_list.append({\n",
    "#                 'AGGREGATION_METHOD': agg_m, 'ATTACK_METHOD': 'Backdoor', 'IS_SYBIL': 'mimic',\n",
    "#                 'ADV_RATE': 0.3, 'buyer_data_mode': 'random', 'discovery_quality': 1.0, 'round': r,\n",
    "#                 'main_acc': 0.5 + (r/num_rounds_dummy*0.3) + np.random.normal(0,0.02) - (0.05 if agg_m=='FedAvg' else 0),\n",
    "#                 'asr': 0.6 - (r/num_rounds_dummy*0.4) + np.random.normal(0,0.03) + (0.1 if agg_m=='FedAvg' else 0),\n",
    "#                 'cost_per_round': 10 + np.random.randint(-2,2)\n",
    "#             })\n",
    "#     all_rounds_df = pd.DataFrame(dummy_round_data_list)\n",
    "#     for col in ['main_acc', 'asr', 'cost_per_round']:\n",
    "#          all_rounds_df[col] = pd.to_numeric(all_rounds_df[col], errors='coerce').clip(0,1) # Clip acc/asr to 0-1\n",
    "#     all_rounds_df['round'] = pd.to_numeric(all_rounds_df['round'], errors='coerce')\n",
    "\n",
    "\n",
    "if 'all_rounds_df' in locals() and not all_rounds_df.empty:\n",
    "    # --- Configuration for this specific plot instance ---\n",
    "    # Define the FIXED parameters for which you want to see the time series\n",
    "    CONFIG_ADV_RATE = 0.3\n",
    "    CONFIG_ATTACK_METHOD = 'Backdoor' # Ensure this is after mapping in Cell 1\n",
    "    CONFIG_IS_SYBIL = 'mimic'         # Ensure this is after mapping in Cell 1\n",
    "    CONFIG_BUYER_MODE = 'random'      # Example\n",
    "    CONFIG_DISCOVERY_QUALITY = 1.0    # Example\n",
    "    # CONFIG_DATASET = 'FMNIST' # Optional filter\n",
    "\n",
    "    # Filter data for the specific configuration\n",
    "    # Note: Ensure column names and values match those in your preprocessed all_rounds_df\n",
    "    query_parts = [\n",
    "        f\"ADV_RATE == {CONFIG_ADV_RATE}\",\n",
    "        f\"ATTACK_METHOD == '{CONFIG_ATTACK_METHOD}'\",\n",
    "        f\"IS_SYBIL == '{CONFIG_IS_SYBIL}'\",\n",
    "        f\"buyer_data_mode == '{CONFIG_BUYER_MODE}'\",\n",
    "        f\"discovery_quality == {CONFIG_DISCOVERY_QUALITY}\"\n",
    "    ]\n",
    "    # if CONFIG_DATASET: query_parts.append(f\"dataset_name == '{CONFIG_DATASET}'\") # Example if dataset_name column exists\n",
    "\n",
    "    # Check if all config columns exist before querying\n",
    "    config_cols_for_query = ['ADV_RATE', 'ATTACK_METHOD', 'IS_SYBIL', 'buyer_data_mode', 'discovery_quality'] # Add others if used\n",
    "    missing_query_cols = [col for col in config_cols_for_query if col not in all_rounds_df.columns]\n",
    "    if missing_query_cols:\n",
    "        print(f\"Error (Time Series Plot): Config columns missing from all_rounds_df: {missing_query_cols}\")\n",
    "        base_time_series_df = pd.DataFrame() # Prevent error\n",
    "    else:\n",
    "        try:\n",
    "            base_time_series_df = all_rounds_df.query(\" & \".join(query_parts)).copy()\n",
    "        except pd.errors.UndefinedVariableError as e:\n",
    "            print(f\"Error querying DataFrame (check column names and quoting): {e}\")\n",
    "            base_time_series_df = pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during DataFrame query: {e}\")\n",
    "            base_time_series_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    if not base_time_series_df.empty:\n",
    "        # The 'hue' for seaborn lineplot will be 'AGGREGATION_METHOD'.\n",
    "        # Group by 'AGGREGATION_METHOD' and 'round' to average if multiple runs exist FOR THE SAME AGG METHOD\n",
    "        # under the exact same CONFIG_... settings.\n",
    "        # If 'run' column (from process_single_experiment) is part of all_rounds_df and you averaged runs already to get summary_df_avg,\n",
    "        # then for all_rounds_df, each (AGG_METHOD, round) under a config might be unique if it's from one specific run's log.\n",
    "        # If multiple runs were concatenated into all_rounds_df, then averaging is needed.\n",
    "        \n",
    "        grouping_cols = ['AGGREGATION_METHOD', 'round']\n",
    "        # Add other columns to grouping_cols if they vary within this slice and you want separate lines for them.\n",
    "        # Example: if 'CHANGE_BASE' is a relevant varying parameter for MartFL:\n",
    "        # if 'CHANGE_BASE' in base_time_series_df.columns and 'MartFL' in base_time_series_df['AGGREGATION_METHOD'].unique():\n",
    "        #    grouping_cols.insert(1, 'CHANGE_BASE')\n",
    "\n",
    "        metrics_to_avg = ['main_acc', 'asr'] # Add 'cost_per_round' if you want to plot it\n",
    "        # Check if metrics_to_avg exist\n",
    "        missing_metric_cols = [col for col in metrics_to_avg if col not in base_time_series_df.columns]\n",
    "        if missing_metric_cols:\n",
    "            print(f\"Error (Time Series Plot): Metric columns missing: {missing_metric_cols}\")\n",
    "            averaged_time_series_df = pd.DataFrame()\n",
    "        else:\n",
    "            # Ensure metrics are numeric before averaging\n",
    "            for col in metrics_to_avg:\n",
    "                base_time_series_df[col] = pd.to_numeric(base_time_series_df[col], errors='coerce')\n",
    "            base_time_series_df.dropna(subset=metrics_to_avg, how='any', inplace=True) # Drop if key metrics are NaN\n",
    "\n",
    "            if not base_time_series_df.empty:\n",
    "                averaged_time_series_df = base_time_series_df.groupby(grouping_cols, as_index=False)[metrics_to_avg].mean()\n",
    "            else:\n",
    "                averaged_time_series_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        if not averaged_time_series_df.empty:\n",
    "            LINE_WIDTH = 2.0 \n",
    "\n",
    "            # Determine number of subplots based on metrics to plot\n",
    "            num_subplots = len(metrics_to_avg)\n",
    "            fig, axes = plt.subplots(num_subplots, 1, figsize=(7, 3.5 * num_subplots), sharex=True) # Compact width\n",
    "            if num_subplots == 1: axes = [axes] # Make iterable\n",
    "\n",
    "            # Determine if legend is needed\n",
    "            unique_aggregators = averaged_time_series_df['AGGREGATION_METHOD'].nunique()\n",
    "            show_legend = unique_aggregators > 1\n",
    "\n",
    "            # Define a palette if multiple aggregators\n",
    "            palette = sns.color_palette(\"tab10\", unique_aggregators) if show_legend else None\n",
    "\n",
    "            # Plot Main Accuracy\n",
    "            if 'main_acc' in averaged_time_series_df.columns:\n",
    "                sns.lineplot(data=averaged_time_series_df, x=\"round\", y=\"main_acc\",\n",
    "                             hue=\"AGGREGATION_METHOD\" if show_legend else None, \n",
    "                             palette=palette,\n",
    "                             linewidth=LINE_WIDTH, ax=axes[0], \n",
    "                             legend=\"brief\" if show_legend and num_subplots > 1 else \"full\" if show_legend else False, # Legend on first plot\n",
    "                             errorbar=('ci', 95) # If groupby averages multiple original runs\n",
    "                            )\n",
    "                axes[0].set_title(f'Avg. Main Accuracy') # Simplified title\n",
    "                axes[0].set_ylabel('Accuracy')\n",
    "                axes[0].grid(True, linestyle=':', linewidth=0.6)\n",
    "                # axes[0].tick_params(labelsize=TICK_LABEL_FONT_SIZE)\n",
    "                axes[0].set_ylim(-0.02, 1.02)\n",
    "\n",
    "\n",
    "            # Plot ASR\n",
    "            if 'asr' in averaged_time_series_df.columns:\n",
    "                ax_asr = axes[1] if num_subplots > 1 else axes[0] # Use same axis if only one metric\n",
    "                if CONFIG_ATTACK_METHOD != 'No Attack' and 'asr' in averaged_time_series_df.columns:\n",
    "                    sns.lineplot(data=averaged_time_series_df, x=\"round\", y=\"asr\",\n",
    "                                 hue=\"AGGREGATION_METHOD\" if show_legend else None,\n",
    "                                 palette=palette,\n",
    "                                 linewidth=LINE_WIDTH, ax=ax_asr, legend=False, # No redundant legend\n",
    "                                 errorbar=('ci', 95)\n",
    "                                )\n",
    "                    ax_asr.set_title(f'Avg. Attack Success Rate (ASR)') # Simplified\n",
    "                    ax_asr.set_ylabel('ASR')\n",
    "                elif 'asr' in averaged_time_series_df.columns: # If 'asr' exists but it's a No Attack scenario\n",
    "                    ax_asr.set_title('ASR (No Attack Scenario)',)\n",
    "                    ax_asr.text(0.5, 0.5, 'No Attack', ha='center', va='center', transform=ax_asr.transAxes)\n",
    "                ax_asr.grid(True, linestyle=':', linewidth=0.6)\n",
    "                # ax_asr.tick_params(labelsize=TICK_LABEL_FONT_SIZE)\n",
    "                ax_asr.set_ylim(-0.02, 1.02)\n",
    "\n",
    "\n",
    "            # Set common X-axis label for the last subplot\n",
    "            axes[-1].set_xlabel('Communication Round')\n",
    "\n",
    "            # Handle legend if it was created on the first plot and there are multiple aggregators\n",
    "            if show_legend and num_subplots > 1 and axes[0].get_legend() is not None:\n",
    "                handles, labels = axes[0].get_legend_handles_labels()\n",
    "                axes[0].get_legend().remove() # Remove from subplot\n",
    "                fig.legend(handles, labels, title='Aggregator', loc='upper center', \n",
    "                           bbox_to_anchor=(0.5, 0.01), ncol=unique_aggregators, frameon=False)\n",
    "                fig_rect_bottom = 0.12 if unique_aggregators <=3 else 0.15 # More space if more legend items\n",
    "            elif show_legend and num_subplots == 1 and axes[0].get_legend() is not None: # Legend inside for single plot\n",
    "                 plt.setp(axes[0].get_legend().get_texts(),)\n",
    "                 plt.setp(axes[0].get_legend().get_title(),)\n",
    "                 fig_rect_bottom = 0.05\n",
    "            else: # No legend shown\n",
    "                fig_rect_bottom = 0.05\n",
    "\n",
    "\n",
    "            # Concise suptitle\n",
    "            suptitle_text = f'{current_aggregation_method if not show_legend else \"Comparison\"}: Time Series'\n",
    "            # Add key config details to suptitle if needed, or keep it simple\n",
    "            # suptitle_text += f\"\\n(AdvRate:{CONFIG_ADV_RATE}, Atk:{CONFIG_ATTACK_METHOD.replace('Backdoor','BD')}, Syb:{CONFIG_IS_SYBIL}, Buyer:{CONFIG_BUYER_MODE}, DQ:{CONFIG_DISCOVERY_QUALITY})\"\n",
    "            fig.suptitle(suptitle_text, y=1.0, fontweight='bold') # Adjust y\n",
    "            \n",
    "            plt.tight_layout(rect=[0, fig_rect_bottom, 1, 0.95]) # Adjust rect for legend and suptitle\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Averaged time series data is empty. Check grouping columns and filters, or if source metrics were all NaN.\")\n",
    "    else:\n",
    "        print(f\"No data found for the specified time series configuration. Query parts: {' & '.join(query_parts)}\")\n",
    "else:\n",
    "    print(\"DataFrame 'all_rounds_df' is not available (empty or not loaded). Skipping Time Series plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.469754300Z"
    }
   },
   "id": "7412154446f0aea9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not summary_df_avg.empty:\n",
    "    # --- Select a specific aggregation and attack scenario ---\n",
    "    ADV_RATE_TO_ANALYZE = 0.3\n",
    "\n",
    "    focus_df = summary_df_avg[\n",
    "        (summary_df_avg['AGGREGATION_METHOD'] == AGG_METHOD_TO_ANALYZE) &\n",
    "        (summary_df_avg['ATTACK_METHOD'] == ATTACK_TO_ANALYZE) &\n",
    "        (summary_df_avg['ADV_RATE'] == ADV_RATE_TO_ANALYZE)\n",
    "    ].copy()\n",
    "\n",
    "    if not focus_df.empty:\n",
    "        # Ensure discovery_quality is numeric for proper sorting/plotting if it's read as string\n",
    "        focus_df['discovery_quality'] = pd.to_numeric(focus_df['discovery_quality'], errors='coerce')\n",
    "        focus_df.dropna(subset=['discovery_quality'], inplace=True)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.lineplot(\n",
    "            data=focus_df,\n",
    "            x='discovery_quality',\n",
    "            y='FINAL_MAIN_ACC',\n",
    "            hue='buyer_data_mode', # How buyer's baseline affects things\n",
    "            style='IS_SYBIL',      # How sybil/mimic interacts\n",
    "            markers=True,\n",
    "            errorbar=('ci', 95) if 'FINAL_MAIN_ACC_STD' in focus_df.columns else None\n",
    "        )\n",
    "        plt.xscale('log') # Discovery quality might be on a log scale (0.1, 1.0, 10.0)\n",
    "        plt.title(f'Impact of Buyer Baseline & Discovery Quality on Main Accuracy\\n(Agg: {AGG_METHOD_TO_ANALYZE}, Attack: {ATTACK_TO_ANALYZE}, AdvRate: {ADV_RATE_TO_ANALYZE})')\n",
    "        plt.xlabel('Discovery Quality (Log Scale)')\n",
    "        plt.ylabel('Final Main Accuracy')\n",
    "        plt.xticks(focus_df['discovery_quality'].unique(), labels=focus_df['discovery_quality'].unique()) # Show actual values\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        plt.legend(title='Buyer Mode (Hue) & Sybil (Style)', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No data found for the specific scenario in Plot 7 (Agg: {AGG_METHOD_TO_ANALYZE}, etc.). Adjust filters.\")\n",
    "else:\n",
    "    print(\"summary_df_avg is empty. Skipping Plot 7.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.470253800Z"
    }
   },
   "id": "3a6c6f3a5920a812"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Define the correct column name from your CSV\n",
    "ACTUAL_BENIGN_GINI_COLUMN_NAME = 'AVG_BENIGN_PAYMENT_GINI'\n",
    "\n",
    "if 'summary_df_avg' in locals() and not summary_df_avg.empty:\n",
    "    plot_data_benign_gini = summary_df_avg.copy()\n",
    "    current_aggregation_method = \"MartFL\" # Assuming 'MartFL'\n",
    "\n",
    "    if ACTUAL_BENIGN_GINI_COLUMN_NAME not in plot_data_benign_gini.columns:\n",
    "        print(f\"Error (Benign Gini Plot): '{ACTUAL_BENIGN_GINI_COLUMN_NAME}' column not found. Cannot create plot.\")\n",
    "    elif plot_data_benign_gini[ACTUAL_BENIGN_GINI_COLUMN_NAME].isna().all():\n",
    "        print(f\"Error (Benign Gini Plot): '{ACTUAL_BENIGN_GINI_COLUMN_NAME}' column contains only NaN values. Cannot create plot.\")\n",
    "    else:\n",
    "        # Column already preprocessed (numeric, rounded) by preprocess_experiment_data if listed in FLOAT_PRECISIONS\n",
    "        # Ensure it's numeric if it wasn't in FLOAT_PRECISIONS, though it should be\n",
    "        plot_data_benign_gini[ACTUAL_BENIGN_GINI_COLUMN_NAME] = pd.to_numeric(\n",
    "            plot_data_benign_gini[ACTUAL_BENIGN_GINI_COLUMN_NAME], errors='coerce'\n",
    "        )\n",
    "        rows_before_dropna_bg = len(plot_data_benign_gini)\n",
    "        plot_data_benign_gini.dropna(subset=[ACTUAL_BENIGN_GINI_COLUMN_NAME], inplace=True)\n",
    "        if len(plot_data_benign_gini) < rows_before_dropna_bg:\n",
    "            print(f\"Plot Benign Gini: Dropped {rows_before_dropna_bg - len(plot_data_benign_gini)} rows with NaN {ACTUAL_BENIGN_GINI_COLUMN_NAME} values.\")\n",
    "\n",
    "        # 1. \"No Attack\" Benign Gini Baseline (Averaged over IS_SYBIL)\n",
    "        no_attack_data_bg = plot_data_benign_gini[plot_data_benign_gini['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "        no_attack_avg_benign_gini = no_attack_data_bg[ACTUAL_BENIGN_GINI_COLUMN_NAME].mean() if not no_attack_data_bg.empty else np.nan\n",
    "\n",
    "        # 2. \"Backdoor Attack\" Benign Gini Data, distinguishing IS_SYBIL\n",
    "        adv_rates_to_plot_on_x = [0.2, 0.3, 0.4]\n",
    "        backdoor_benign_gini_data = plot_data_benign_gini[\n",
    "            (plot_data_benign_gini['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_benign_gini['ADV_RATE'].isin(adv_rates_to_plot_on_x))\n",
    "        ].copy()\n",
    "\n",
    "        if not backdoor_benign_gini_data.empty:\n",
    "            backdoor_benign_gini_by_sybil = backdoor_benign_gini_data.groupby(\n",
    "                ['ADV_RATE', 'IS_SYBIL'], as_index=False\n",
    "            )[ACTUAL_BENIGN_GINI_COLUMN_NAME].mean().sort_values(by=['IS_SYBIL', 'ADV_RATE'])\n",
    "            adv_rates_present_in_data = sorted(backdoor_benign_gini_by_sybil['ADV_RATE'].unique())\n",
    "        else:\n",
    "            print(f\"Warning (Benign Gini Plot): No 'Backdoor' data for Benign Gini for ADV_RATEs {adv_rates_to_plot_on_x}.\")\n",
    "            backdoor_benign_gini_by_sybil = pd.DataFrame()\n",
    "            adv_rates_present_in_data = []\n",
    "\n",
    "        # --- Plotting Benign Gini ---\n",
    "        if not backdoor_benign_gini_by_sybil.empty or pd.notna(no_attack_avg_benign_gini):\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            colors = { 'No Attack': 'dimgray', 'Backdoor (Standard)': 'orangered', 'Backdoor (Mimic)': 'darkviolet' }\n",
    "            linestyles = { 'No Attack': (0, (5, 2)), 'Backdoor (Standard)': '-', 'Backdoor (Mimic)': '--' }\n",
    "            markers = { 'Backdoor (Standard)': 'o', 'Backdoor (Mimic)': 's' }\n",
    "            legend_elements_gini = []\n",
    "\n",
    "            xmin_hline = min(adv_rates_present_in_data) if adv_rates_present_in_data else min(adv_rates_to_plot_on_x)\n",
    "            xmax_hline = max(adv_rates_present_in_data) if adv_rates_present_in_data else max(adv_rates_to_plot_on_x)\n",
    "\n",
    "            if pd.notna(no_attack_avg_benign_gini):\n",
    "                ax.hlines(y=no_attack_avg_benign_gini, xmin=xmin_hline, xmax=xmax_hline,\n",
    "                          color=colors['No Attack'], linestyle=linestyles['No Attack'])\n",
    "                legend_elements_gini.append(Line2D([0], [0], color=colors['No Attack'], linestyle=linestyles['No Attack'],\n",
    "                                                  lw=LINE_WIDTH, label=f'No Attack'))\n",
    "\n",
    "            if not backdoor_benign_gini_by_sybil.empty:\n",
    "                data_std = backdoor_benign_gini_by_sybil[backdoor_benign_gini_by_sybil['IS_SYBIL'] == 'False']\n",
    "                if not data_std.empty:\n",
    "                    ax.plot(data_std['ADV_RATE'], data_std[ACTUAL_BENIGN_GINI_COLUMN_NAME], # Use actual name\n",
    "                            color=colors['Backdoor (Standard)'], linestyle=linestyles['Backdoor (Standard)'],\n",
    "                            marker=markers['Backdoor (Standard)'], linewidth=LINE_WIDTH)\n",
    "                    legend_elements_gini.append(Line2D([0], [0], color=colors['Backdoor (Standard)'], linestyle=linestyles['Backdoor (Standard)'],\n",
    "                                                      marker=markers['Backdoor (Standard)'], lw=LINE_WIDTH,\n",
    "                                                      label='Backdoor (Standard)'))\n",
    "\n",
    "                data_mimic = backdoor_benign_gini_by_sybil[backdoor_benign_gini_by_sybil['IS_SYBIL'] == 'mimic']\n",
    "                if not data_mimic.empty:\n",
    "                    ax.plot(data_mimic['ADV_RATE'], data_mimic[ACTUAL_BENIGN_GINI_COLUMN_NAME], # Use actual name\n",
    "                            color=colors['Backdoor (Mimic)'], linestyle=linestyles['Backdoor (Mimic)'],\n",
    "                            marker=markers['Backdoor (Mimic)'], linewidth=LINE_WIDTH, markersize=MARKER_SIZE)\n",
    "                    legend_elements_gini.append(Line2D([0], [0], color=colors['Backdoor (Mimic)'], linestyle=linestyles['Backdoor (Mimic)'],\n",
    "                                                      marker=markers['Backdoor (Mimic)'], markersize=MARKER_SIZE, lw=LINE_WIDTH,\n",
    "                                                      label='Backdoor (Sybil)'))\n",
    "\n",
    "            ax.set_xlabel('Adversary Rate (Backdoor Attack)',)\n",
    "            ax.set_ylabel('Benign Seller Payment Gini\\n(0=Equal, 1=Unequal)')\n",
    "            ax.tick_params(axis='both', which='major', pad=6)\n",
    "            gini_values = backdoor_benign_gini_by_sybil[ACTUAL_BENIGN_GINI_COLUMN_NAME].tolist()\n",
    "            if pd.notna(no_attack_avg_benign_gini):\n",
    "                gini_values.append(no_attack_avg_benign_gini)\n",
    "            \n",
    "            if gini_values:\n",
    "                min_val = max(min(gini_values) - 0.03, 0)\n",
    "                max_val = min(max(gini_values) + 0.03, 1)\n",
    "                ax.set_ylim(min_val, max_val)\n",
    "            else:\n",
    "                ax.set_ylim(0.2, 0.6)  # fallback range            \n",
    "            plot_xticks_bg = adv_rates_present_in_data if adv_rates_present_in_data else adv_rates_to_plot_on_x\n",
    "            if plot_xticks_bg :\n",
    "                 ax.set_xticks(ticks=plot_xticks_bg); ax.set_xticklabels(labels=[f'{r:.1f}' for r in plot_xticks_bg])\n",
    "            \n",
    "            ax.grid(True, which='major', linestyle=':', linewidth=0.6)\n",
    "\n",
    "            if legend_elements_gini:\n",
    "                ax.legend(handles=legend_elements_gini, title='Attack Condition (Benign Gini)', loc='best', frameon=True, edgecolor='lightgray')\n",
    "            # fig.suptitle(f'{current_aggregation_method}: Robustness of Benign Seller Fairness to Attacks',\n",
    "            #              fontsize=TITLE_FONT_SIZE, y=0.99, fontweight='bold')\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            fig = plt.gcf()\n",
    "            save_figure_as_pdf(\n",
    "                fig=fig, \n",
    "                output_directory=FIGURE_SAVE_DIR, \n",
    "                base_filename=\"gini_benign_varying_adv\", # Base name describing the plot\n",
    "                current_aggregation_method=current_aggregation_method,\n",
    "                # other_details=f\"target{int(TARGET_ACCURACY_COC*100)}acc\" # Example other detail\n",
    "            )              \n",
    "else:\n",
    "    print(\"DataFrame 'summary_df_avg' is not available for Benign Gini plot (empty or not loaded).\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.471254700Z"
    }
   },
   "id": "7b5cbf3b34b91cfb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# This cell depends on 'summary_df_avg' being loaded and preprocessed by Cell 1.\n",
    "\n",
    "if 'summary_df_avg' in locals() and not summary_df_avg.empty:\n",
    "    plot_data_mal_select = summary_df_avg.copy()\n",
    "    \n",
    "    # Assuming AGGREGATION_METHOD is constant or you want to plot for a specific one.\n",
    "    # If multiple, you might need to filter. For this example, taking the first one.\n",
    "    aggregation_methods_present = plot_data_mal_select['AGGREGATION_METHOD'].unique()\n",
    "    current_aggregation_method = aggregation_methods_present[0] if len(aggregation_methods_present) > 0 else \"UnknownMethod\"\n",
    "    if len(aggregation_methods_present) > 1:\n",
    "        print(f\"Warning (Malicious Selection Plot): Multiple aggregation methods found. Plotting for '{current_aggregation_method}'. Filter if needed.\")\n",
    "        plot_data_mal_select = plot_data_mal_select[plot_data_mal_select['AGGREGATION_METHOD'] == current_aggregation_method]\n",
    "\n",
    "    # Define required columns\n",
    "    baseline_cols_map = {\n",
    "        0.1: 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1',\n",
    "        0.2: 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2',\n",
    "        0.3: 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3',\n",
    "        0.4: 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4'\n",
    "    }\n",
    "    actual_mal_select_col = 'AVG_ADVERSARY_SELECTION_RATE'\n",
    "    \n",
    "    # Check if all necessary columns exist\n",
    "    missing_baseline_cols = [col for col in baseline_cols_map.values() if col not in plot_data_mal_select.columns]\n",
    "    if actual_mal_select_col not in plot_data_mal_select.columns:\n",
    "        missing_cols_error = f\"Error: Column '{actual_mal_select_col}' not found. \"\n",
    "        if missing_baseline_cols:\n",
    "            missing_cols_error += f\"Additionally, baseline columns missing: {', '.join(missing_baseline_cols)}.\"\n",
    "        print(missing_cols_error + \" Cannot create plot.\")\n",
    "        # Set to empty to skip plotting\n",
    "        plot_data_mal_select = pd.DataFrame() \n",
    "    elif missing_baseline_cols:\n",
    "        print(f\"Warning (Malicious Selection Plot): Some baseline columns missing: {', '.join(missing_baseline_cols)}. Baseline plot might be incomplete.\")\n",
    "\n",
    "\n",
    "    # Proceed only if we have the actual malicious selection rate column\n",
    "    if not plot_data_mal_select.empty and actual_mal_select_col in plot_data_mal_select.columns:\n",
    "        # Drop rows if the AVG_ADVERSARY_SELECTION_RATE is NaN for attack data,\n",
    "        # or if ALL relevant NO_ATTACK_DESIG_MAL_SEL_RATE_X.X are NaN for No Attack data.\n",
    "        \n",
    "        # For attack data:\n",
    "        attack_data_check = plot_data_mal_select[plot_data_mal_select['ATTACK_METHOD'] == 'Backdoor']\n",
    "        if not attack_data_check.empty:\n",
    "            plot_data_mal_select.loc[plot_data_mal_select['ATTACK_METHOD'] == 'Backdoor'] = \\\n",
    "                attack_data_check.dropna(subset=[actual_mal_select_col])\n",
    "        \n",
    "        # For no attack data (more complex as we use multiple baseline columns)\n",
    "        # If a \"No Attack\" row has NaNs in ALL its NO_ATTACK_DESIG_MAL_SEL_RATE_X.X columns, it's not useful\n",
    "        no_attack_rows = plot_data_mal_select['ATTACK_METHOD'] == 'No Attack'\n",
    "        baseline_col_names_in_df = [col for col in baseline_cols_map.values() if col in plot_data_mal_select.columns]\n",
    "        if baseline_col_names_in_df: # Only if some baseline columns exist\n",
    "             plot_data_mal_select = plot_data_mal_select[~(no_attack_rows & plot_data_mal_select[baseline_col_names_in_df].isna().all(axis=1))]\n",
    "\n",
    "\n",
    "        # 1. Prepare \"No Attack - Designated Group\" Baseline Data\n",
    "        no_attack_runs = plot_data_mal_select[plot_data_mal_select['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "        baseline_points = {} \n",
    "        if not no_attack_runs.empty:\n",
    "            for adv_r_key, col_name in baseline_cols_map.items():\n",
    "                if col_name in no_attack_runs.columns:\n",
    "                    # Average over other variations (e.g. IS_SYBIL for \"No Attack\" runs)\n",
    "                    mean_rate = no_attack_runs[col_name].mean() \n",
    "                    if pd.notna(mean_rate):\n",
    "                        baseline_points[adv_r_key] = mean_rate\n",
    "        del baseline_points[0.1 ]\n",
    "        baseline_series_for_plot = pd.Series(baseline_points).sort_index()\n",
    "        if baseline_series_for_plot.empty and not no_attack_runs.empty:\n",
    "            print(\"Warning: Baseline series for 'No Attack' is empty after processing. Check NO_ATTACK_DESIG_MAL_SEL_RATE_X.X columns.\")\n",
    "\n",
    "\n",
    "        # 2. Prepare \"Backdoor Attack\" Data (Actual Malicious Selection Rate)\n",
    "        # X-axis values for the attack lines should match the keys/index of baseline_series_for_plot\n",
    "        adv_rates_for_attack_lines = baseline_series_for_plot.index.tolist() if not baseline_series_for_plot.empty else [0.2, 0.3, 0.4]\n",
    "\n",
    "        backdoor_attack_data = plot_data_mal_select[\n",
    "            (plot_data_mal_select['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_mal_select['ADV_RATE'].isin(adv_rates_for_attack_lines))\n",
    "        ].copy()\n",
    "\n",
    "        actual_mal_select_by_sybil = pd.DataFrame() # Initialize\n",
    "        if not backdoor_attack_data.empty:\n",
    "            actual_mal_select_by_sybil = backdoor_attack_data.groupby(\n",
    "                ['ADV_RATE', 'IS_SYBIL'], as_index=False\n",
    "            )[actual_mal_select_col].mean().sort_values(by=['IS_SYBIL', 'ADV_RATE'])\n",
    "        else:\n",
    "            print(\"Warning (Malicious Selection Plot): No 'Backdoor' attack data for plotting.\")\n",
    "\n",
    "\n",
    "        # --- Plotting ---\n",
    "        if not actual_mal_select_by_sybil.empty or not baseline_series_for_plot.empty:\n",
    "            LINE_WIDTH = 2.2; MARKER_SIZE = 7\n",
    "        \n",
    "            fig, ax = plt.subplots()\n",
    "        \n",
    "            color_no_atk_baseline = 'dimgray'\n",
    "            color_std_atk = 'orangered'    # Standard Backdoor (IS_SYBIL='False')\n",
    "            color_mimic_atk = 'darkviolet' # Mimicry Backdoor (IS_SYBIL='mimic')\n",
    "        \n",
    "            linestyle_no_atk_baseline = (0, (5, 2)) # Loosely Dotted\n",
    "            linestyle_std_atk = '-'         # Solid\n",
    "            linestyle_mimic_atk = '--'      # Dashed\n",
    "        \n",
    "            marker_no_atk_baseline = 'D'\n",
    "            marker_std_atk = 'o'\n",
    "            marker_mimic_atk = 's'\n",
    "        \n",
    "            legend_elements = []\n",
    "        \n",
    "            # 1. Plot Control Group (Designated Adv Group with No Attack)\n",
    "            if not baseline_series_for_plot.empty:\n",
    "                ax.plot(baseline_series_for_plot.index, baseline_series_for_plot.values,\n",
    "                        color=color_no_atk_baseline, linestyle=linestyle_no_atk_baseline,\n",
    "                        marker=marker_no_atk_baseline, linewidth=LINE_WIDTH, markersize=MARKER_SIZE-1)\n",
    "                legend_elements.append(Line2D([0],[0], color=color_no_atk_baseline, linestyle=linestyle_no_atk_baseline,\n",
    "                                              marker=marker_no_atk_baseline, markersize=MARKER_SIZE-1, lw=LINE_WIDTH,\n",
    "                                              label='Control Group (Same Data, No Attack)'))\n",
    "            else:\n",
    "                print(\"No baseline data to plot for 'No Attack - Designated Group'.\")\n",
    "        \n",
    "            # 2. Plot Attacker Group (Standard Backdoor)\n",
    "            if not actual_mal_select_by_sybil.empty:\n",
    "                data_std_backdoor = actual_mal_select_by_sybil[actual_mal_select_by_sybil['IS_SYBIL'] == 'False']\n",
    "                if not data_std_backdoor.empty:\n",
    "                    ax.plot(data_std_backdoor['ADV_RATE'], data_std_backdoor[actual_mal_select_col],\n",
    "                            color=color_std_atk, linestyle=linestyle_std_atk, marker=marker_std_atk,\n",
    "                            linewidth=LINE_WIDTH, markersize=MARKER_SIZE)\n",
    "                    legend_elements.append(Line2D([0],[0], color=color_std_atk, linestyle=linestyle_std_atk,\n",
    "                                                  marker=marker_std_atk, markersize=MARKER_SIZE,\n",
    "                                                  lw=LINE_WIDTH, label='Attacker Group (Standard Backdoor)'))\n",
    "                else:\n",
    "                    print(\"No data for Standard Backdoor (IS_SYBIL='False') line.\")\n",
    "        \n",
    "                # 3. Plot Attacker Group (Sybil Backdoor)\n",
    "                data_mimic_backdoor = actual_mal_select_by_sybil[actual_mal_select_by_sybil['IS_SYBIL'] == 'mimic']\n",
    "                if not data_mimic_backdoor.empty:\n",
    "                    ax.plot(data_mimic_backdoor['ADV_RATE'], data_mimic_backdoor[actual_mal_select_col],\n",
    "                            color=color_mimic_atk, linestyle=linestyle_mimic_atk, marker=marker_mimic_atk,\n",
    "                            linewidth=LINE_WIDTH, markersize=MARKER_SIZE)\n",
    "                    legend_elements.append(Line2D([0],[0], color=color_mimic_atk, linestyle=linestyle_mimic_atk,\n",
    "                                                  marker=marker_mimic_atk, markersize=MARKER_SIZE,\n",
    "                                                  lw=LINE_WIDTH, label='Attacker Group (Sybil Backdoor)'))\n",
    "                else:\n",
    "                    print(\"No data for Mimicry Backdoor (IS_SYBIL='mimic') line.\")\n",
    "        \n",
    "            ax.set_xlabel('Adversary Rate')\n",
    "            ax.set_ylabel('Avg. Selection Rate')\n",
    "            ax.tick_params(axis='both', which='major', pad=6)\n",
    "            selection_values = []\n",
    "            \n",
    "            # Add baseline (no attack control group) values\n",
    "            if not baseline_series_for_plot.empty:\n",
    "                selection_values.extend(baseline_series_for_plot.values.tolist())\n",
    "            \n",
    "            # Add standard backdoor values\n",
    "            if not actual_mal_select_by_sybil.empty:\n",
    "                std_data = actual_mal_select_by_sybil[actual_mal_select_by_sybil['IS_SYBIL'] == 'False']\n",
    "                mimic_data = actual_mal_select_by_sybil[actual_mal_select_by_sybil['IS_SYBIL'] == 'mimic']\n",
    "                if not std_data.empty:\n",
    "                    selection_values.extend(std_data[actual_mal_select_col].tolist())\n",
    "                if not mimic_data.empty:\n",
    "                    selection_values.extend(mimic_data[actual_mal_select_col].tolist())\n",
    "            \n",
    "            # Set y-limits with ±padding, clipped to [0, 1]\n",
    "            if selection_values:\n",
    "                y_min = max(min(selection_values) - 0.03, 0)\n",
    "                y_max = min(max(selection_values) + 0.03, 1)\n",
    "                ax.set_ylim(y_min, y_max)\n",
    "            else:\n",
    "                ax.set_ylim(0, 1)  # fallback if no data\n",
    "        \n",
    "            plot_xticks = baseline_series_for_plot.index.tolist() if not baseline_series_for_plot.empty else adv_rates_to_plot_on_x\n",
    "            if plot_xticks:\n",
    "                ax.set_xticks(ticks=plot_xticks)\n",
    "                ax.set_xticklabels(labels=[f'{r:.1f}' for r in plot_xticks])\n",
    "        \n",
    "            ax.grid(True, which='major', linestyle=':', linewidth=0.6)\n",
    "        \n",
    "            if legend_elements:\n",
    "                ax.legend(handles=legend_elements, title='Group & Behavior',\n",
    "                          loc='best', frameon=True, edgecolor='lightgray')\n",
    "        \n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            plt.show()\n",
    "            save_figure_as_pdf(\n",
    "                fig=fig, \n",
    "                output_directory=FIGURE_SAVE_DIR, \n",
    "                base_filename=\"selection_rate\", \n",
    "                current_aggregation_method=current_aggregation_method,\n",
    "            )\n",
    "        else:\n",
    "            print(\"Not enough data to plot Malicious Selection Rates after all filtering and preparation.\")\n",
    "else:\n",
    "    print(\"DataFrame 'summary_df_avg' is not available (empty or not loaded). Skipping Malicious Selection Rate plot.\")\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.471753700Z"
    }
   },
   "id": "602c7019b21e9599"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# This cell depends on 'summary_df_avg' being loaded and preprocessed by Cell 1.\n",
    "\n",
    "if 'summary_df_avg' in locals() and not summary_df_avg.empty:\n",
    "    plot_data_speed = summary_df_avg.copy()\n",
    "    current_aggregation_method = \"MartFL\" # Or get from df\n",
    "    \n",
    "    # --- CHOOSE THE ACCURACY MILESTONE TO PLOT ---\n",
    "    CHOSEN_MILESTONE_LABEL = \"80\" # e.g., \"70\", \"80\", \"85\"\n",
    "    rounds_col_to_plot = f'ROUNDS_TO_{CHOSEN_MILESTONE_LABEL}ACC'\n",
    "    TARGET_ACC_VALUE = int(CHOSEN_MILESTONE_LABEL) / 100.0\n",
    "\n",
    "    # Verify the chosen milestone column exists\n",
    "    if rounds_col_to_plot not in plot_data_speed.columns:\n",
    "        print(f\"Error (Speed Plot): Column '{rounds_col_to_plot}' not found for the chosen milestone. Available ROUNDS_TO_XXACC columns:\")\n",
    "        print([col for col in plot_data_speed.columns if \"ROUNDS_TO_\" in col])\n",
    "    elif plot_data_speed[rounds_col_to_plot].isna().all():\n",
    "        print(f\"Error (Speed Plot): Column '{rounds_col_to_plot}' is entirely NaN.\")\n",
    "    else:\n",
    "        # Ensure data is numeric (should be from preprocessing)\n",
    "        plot_data_speed[rounds_col_to_plot] = pd.to_numeric(plot_data_speed[rounds_col_to_plot], errors='coerce')\n",
    "        \n",
    "        # Handle NaNs in rounds_col_to_plot (meaning target not reached)\n",
    "        # Option: Plot them at a high value (e.g., MAX_ROUNDS_EXECUTED from your summary + penalty)\n",
    "        # For now, we will let NaNs break the lines, which clearly indicates non-convergence.\n",
    "        # If you want to plot them high, uncomment and adjust:\n",
    "        # MAX_ROUNDS_EXPERIMENT = summary_df_avg['TOTAL_ROUNDS_EXECUTED'].max() if 'TOTAL_ROUNDS_EXECUTED' in summary_df_avg else 200 # Default\n",
    "        # plot_data_speed[rounds_col_to_plot].fillna(MAX_ROUNDS_EXPERIMENT + 10, inplace=True)\n",
    "\n",
    "\n",
    "        # 1. \"No Attack\" - Rounds to Converge (averaged over IS_SYBIL for \"No Attack\")\n",
    "        no_attack_speed_data = plot_data_speed[plot_data_speed['ATTACK_METHOD'] == 'No Attack'].copy()\n",
    "        no_attack_avg_rounds = no_attack_speed_data[rounds_col_to_plot].mean() if not no_attack_speed_data.empty else np.nan\n",
    "\n",
    "        # 2. \"Backdoor Attack\" - Rounds to Converge, distinguishing IS_SYBIL\n",
    "        adv_rates_to_plot_on_x = [0.1, 0.2, 0.3, 0.4] # X-axis for attack lines\n",
    "        backdoor_attack_speed_data = plot_data_speed[\n",
    "            (plot_data_speed['ATTACK_METHOD'] == 'Backdoor') &\n",
    "            (plot_data_speed['ADV_RATE'].isin(adv_rates_to_plot_on_x))\n",
    "        ].copy()\n",
    "\n",
    "        backdoor_rounds_by_sybil = pd.DataFrame()\n",
    "        adv_rates_present_speed = []\n",
    "        if not backdoor_attack_speed_data.empty:\n",
    "            backdoor_rounds_by_sybil = backdoor_attack_speed_data.groupby(\n",
    "                ['ADV_RATE', 'IS_SYBIL'], as_index=False\n",
    "            )[rounds_col_to_plot].mean().sort_values(by=['IS_SYBIL', 'ADV_RATE'])\n",
    "            adv_rates_present_speed = sorted(backdoor_rounds_by_sybil['ADV_RATE'].unique())\n",
    "        else:\n",
    "            print(f\"Warning (Speed Plot): No 'Backdoor' data for {rounds_col_to_plot} at ADV_RATEs {adv_rates_to_plot_on_x}.\")\n",
    "\n",
    "\n",
    "        # --- Plotting Speed to Chosen Milestone ---\n",
    "        if not backdoor_rounds_by_sybil.empty or pd.notna(no_attack_avg_rounds):\n",
    "            TITLE_FONT_SIZE = 14; AXIS_LABEL_FONT_SIZE = 12; TICK_LABEL_FONT_SIZE = 11\n",
    "            LEGEND_FONT_SIZE = 10; LEGEND_TITLE_FONT_SIZE = 11\n",
    "            LINE_WIDTH = 2.2; MARKER_SIZE = 7\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            # Define visual properties for the 3 main conditions\n",
    "            colors = {\n",
    "                'No Attack': 'dimgray',\n",
    "                'Backdoor (Standard)': 'saddlebrown', # IS_SYBIL = 'False'\n",
    "                'Backdoor (Mimic)': 'darkgoldenrod'    # IS_SYBIL = 'mimic'\n",
    "            }\n",
    "            linestyles = {\n",
    "                'No Attack': (0, (5, 2)),       # Loosely dotted baseline\n",
    "                'Backdoor (Standard)': '-',     # Solid\n",
    "                'Backdoor (Mimic)': '--'        # Dashed\n",
    "            }\n",
    "            markers = {\n",
    "                'Backdoor (Standard)': 'o',\n",
    "                'Backdoor (Mimic)': 's'\n",
    "            }\n",
    "            legend_elements_speed = []\n",
    "\n",
    "            xmin_hline = min(adv_rates_present_speed) if adv_rates_present_speed else min(adv_rates_to_plot_on_x)\n",
    "            xmax_hline = max(adv_rates_present_speed) if adv_rates_present_speed else max(adv_rates_to_plot_on_x)\n",
    "\n",
    "            # 1. Plot \"No Attack\" Rounds Baseline\n",
    "            if pd.notna(no_attack_avg_rounds):\n",
    "                ax.hlines(y=no_attack_avg_rounds, xmin=xmin_hline, xmax=xmax_hline,\n",
    "                          color=colors['No Attack'], linestyle=linestyles['No Attack'], linewidth=LINE_WIDTH)\n",
    "                legend_elements_speed.append(Line2D([0],[0], color=colors['No Attack'], linestyle=linestyles['No Attack'],\n",
    "                                                  lw=LINE_WIDTH, label=f'No Attack ({no_attack_avg_rounds:.0f} Rnds)'))\n",
    "\n",
    "            # 2. Plot \"Backdoor Attack\" Rounds for Standard (IS_SYBIL='False')\n",
    "            if not backdoor_rounds_by_sybil.empty:\n",
    "                data_std_backdoor = backdoor_rounds_by_sybil[backdoor_rounds_by_sybil['IS_SYBIL'] == 'False']\n",
    "                if not data_std_backdoor.empty and not data_std_backdoor[rounds_col_to_plot].isna().all():\n",
    "                    ax.plot(data_std_backdoor['ADV_RATE'], data_std_backdoor[rounds_col_to_plot],\n",
    "                            color=colors['Backdoor (Standard)'], linestyle=linestyles['Backdoor (Standard)'],\n",
    "                            marker=markers['Backdoor (Standard)'], linewidth=LINE_WIDTH, markersize=MARKER_SIZE)\n",
    "                    legend_elements_speed.append(Line2D([0],[0], color=colors['Backdoor (Standard)'], linestyle=linestyles['Backdoor (Standard)'],\n",
    "                                                      marker=markers['Backdoor (Standard)'], markersize=MARKER_SIZE,\n",
    "                                                      lw=LINE_WIDTH, label='Backdoor (Standard)'))\n",
    "                else: print(f\"No data or all NaN for Standard Backdoor for {rounds_col_to_plot}\")\n",
    "\n",
    "            # 3. Plot \"Backdoor Attack\" Rounds for Mimicry (IS_SYBIL='mimic')\n",
    "                data_mimic_backdoor = backdoor_rounds_by_sybil[backdoor_rounds_by_sybil['IS_SYBIL'] == 'mimic']\n",
    "                if not data_mimic_backdoor.empty and not data_mimic_backdoor[rounds_col_to_plot].isna().all():\n",
    "                    ax.plot(data_mimic_backdoor['ADV_RATE'], data_mimic_backdoor[rounds_col_to_plot],\n",
    "                            color=colors['Backdoor (Mimic)'], linestyle=linestyles['Backdoor (Mimic)'],\n",
    "                            marker=markers['Backdoor (Mimic)'], linewidth=LINE_WIDTH, markersize=MARKER_SIZE)\n",
    "                    legend_elements_speed.append(Line2D([0],[0], color=colors['Backdoor (Mimic)'], linestyle=linestyles['Backdoor (Mimic)'],\n",
    "                                                      marker=markers['Backdoor (Mimic)'], markersize=MARKER_SIZE,\n",
    "                                                      lw=LINE_WIDTH, label='Backdoor (Sybil)'))\n",
    "                else: print(f\"No data or all NaN for Mimicry Backdoor for {rounds_col_to_plot}\")\n",
    "\n",
    "\n",
    "            ax.set_xlabel('Adversary Rate (Backdoor Attack)')\n",
    "            ax.set_ylabel(f'Rounds to Reach {TARGET_ACC_VALUE*100:.0f}% Accuracy')\n",
    "            ax.tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONT_SIZE, pad=6)\n",
    "            \n",
    "            # Dynamic Y-axis limit based on data, ensuring 0 is the bottom if no negative values.\n",
    "            all_y_values = []\n",
    "            if pd.notna(no_attack_avg_rounds): all_y_values.append(no_attack_avg_rounds)\n",
    "            if not backdoor_rounds_by_sybil.empty: all_y_values.extend(backdoor_rounds_by_sybil[rounds_col_to_plot].dropna().tolist())\n",
    "            \n",
    "            if all_y_values:\n",
    "                min_y = 0\n",
    "                max_y = max(all_y_values) * 1.1 if all_y_values else 200 # Default max if no data\n",
    "                ax.set_ylim(min_y, max_y)\n",
    "            else: # Fallback if no y-data at all\n",
    "                ax.set_ylim(0,200)\n",
    "\n",
    "\n",
    "            plot_xticks = adv_rates_present_speed if adv_rates_present_speed else adv_rates_to_plot_on_x\n",
    "            if plot_xticks:\n",
    "                 ax.set_xticks(ticks=plot_xticks)\n",
    "                 ax.set_xticklabels(labels=[f'{r:.1f}' for r in plot_xticks])\n",
    "            \n",
    "            ax.grid(True, which='major', linestyle=':', linewidth=0.6)\n",
    "\n",
    "            if legend_elements_speed:\n",
    "                ax.legend(handles=legend_elements_speed, title='Attack Condition (Convergence Speed)',\n",
    "                          loc='best', frameon=True, edgecolor='lightgray')\n",
    "\n",
    "            fig.suptitle(f'{current_aggregation_method}: Attack Impact on Convergence Speed to {TARGET_ACC_VALUE*100:.0f}% Acc.', y=0.99, fontweight='bold')\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Not enough data to plot speed to milestones after filtering.\")\n",
    "else:\n",
    "    print(\"DataFrame 'summary_df_avg' is not available. Skipping speed to milestones plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.472754200Z"
    }
   },
   "id": "3adf8e377d385a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D # For custom legend\n",
    "\n",
    "# This cell depends on 'summary_df_avg' being loaded and preprocessed by Cell 1.\n",
    "# It requires 'FINAL_ASR', 'ATTACK_METHOD', 'ADV_RATE', 'buyer_data_mode'.\n",
    "# We will average over 'IS_SYBIL' for this particular plot for simplicity.\n",
    "\n",
    "if 'summary_df_avg' in locals() and not summary_df_avg.empty:\n",
    "    plot_data_asr_buyer = summary_df_avg.copy()\n",
    "    current_aggregation_method = \"MartFL\" # Assuming for title\n",
    "\n",
    "    # Filter for only Backdoor attack scenarios\n",
    "    plot_data_asr_buyer = plot_data_asr_buyer[\n",
    "        plot_data_asr_buyer['ATTACK_METHOD'] == 'Backdoor' # Focus on when attack is active\n",
    "    ].copy()\n",
    "\n",
    "    # Ensure required columns exist and are not all NaN\n",
    "    required_metric_asr = 'FINAL_ASR'\n",
    "    required_group_cols_asr = ['ADV_RATE', 'buyer_data_mode'] # IS_SYBIL will be averaged out\n",
    "    \n",
    "    all_needed_plot_cols_asr = [required_metric_asr] + required_group_cols_asr\n",
    "    missing_plot_cols_asr = [col for col in all_needed_plot_cols_asr if col not in plot_data_asr_buyer.columns]\n",
    "\n",
    "    if missing_plot_cols_asr:\n",
    "        print(f\"Error (Buyer Baseline ASR Plot): Columns missing: {', '.join(missing_plot_cols_asr)}.\")\n",
    "    elif plot_data_asr_buyer[required_metric_asr].isna().all():\n",
    "        print(f\"Error (Buyer Baseline ASR Plot): Metric column '{required_metric_asr}' is all NaN.\")\n",
    "    elif plot_data_asr_buyer.empty:\n",
    "        print(\"Warning (Buyer Baseline ASR Plot): No 'Backdoor' attack data available after initial filtering.\")\n",
    "    else:\n",
    "        # Data already numeric and rounded from Cell 1 preprocessing.\n",
    "        # Drop rows if FINAL_ASR for this plot is NaN.\n",
    "        plot_data_asr_buyer.dropna(subset=[required_metric_asr], inplace=True)\n",
    "\n",
    "        # Group by ADV_RATE and buyer_data_mode, averaging over IS_SYBIL and any other variations\n",
    "        if not plot_data_asr_buyer.empty:\n",
    "            avg_asr_by_buyer_baseline = plot_data_asr_buyer.groupby(\n",
    "                ['ADV_RATE', 'buyer_data_mode'], as_index=False\n",
    "            )[required_metric_asr].mean().sort_values(by=['buyer_data_mode', 'ADV_RATE'])\n",
    "            \n",
    "            adv_rates_present_asr = sorted(avg_asr_by_buyer_baseline['ADV_RATE'].unique())\n",
    "            # Ensure we only plot the ADV_RATEs we are interested in for attacks\n",
    "            adv_rates_to_plot_on_x = [0.1, 0.2, 0.3, 0.4]\n",
    "            avg_asr_by_buyer_baseline = avg_asr_by_buyer_baseline[avg_asr_by_buyer_baseline['ADV_RATE'].isin(adv_rates_to_plot_on_x)]\n",
    "            adv_rates_present_asr = sorted(avg_asr_by_buyer_baseline['ADV_RATE'].unique()) # Update after filtering\n",
    "        else:\n",
    "            print(\"Warning (Buyer Baseline ASR Plot): Data became empty after dropna on FINAL_ASR.\")\n",
    "            avg_asr_by_buyer_baseline = pd.DataFrame()\n",
    "            adv_rates_present_asr = []\n",
    "\n",
    "        # --- Plotting ASR vs. ADV_RATE by Buyer Baseline Type ---\n",
    "        if not avg_asr_by_buyer_baseline.empty:\n",
    "            TITLE_FONT_SIZE = 14; AXIS_LABEL_FONT_SIZE = 12; TICK_LABEL_FONT_SIZE = 11\n",
    "            LEGEND_FONT_SIZE = 10; LEGEND_TITLE_FONT_SIZE = 11\n",
    "            LINE_WIDTH = 2.2; MARKER_SIZE = 7\n",
    "\n",
    "            fig, ax = plt.subplots() # Single panel plot\n",
    "\n",
    "            # Define visual properties for buyer_data_mode\n",
    "            # Using more distinct colors now\n",
    "            palette_buyer_mode = {'random': 'darkcyan', 'biased': 'sandybrown'}\n",
    "            linestyle_buyer_mode = {'random': '-', 'biased': '--'}\n",
    "            marker_buyer_mode = {'random': 'o', 'biased': 's'}\n",
    "\n",
    "            legend_elements_asr = []\n",
    "\n",
    "            for mode, group_df in avg_asr_by_buyer_baseline.groupby('buyer_data_mode'):\n",
    "                # Ensure the mode from data exists in our defined palette/styles\n",
    "                if mode in palette_buyer_mode:\n",
    "                    ax.plot(group_df['ADV_RATE'], group_df['FINAL_ASR'],\n",
    "                             color=palette_buyer_mode[mode],\n",
    "                             linestyle=linestyle_buyer_mode[mode],\n",
    "                             marker=marker_buyer_mode[mode],\n",
    "                             linewidth=LINE_WIDTH, markersize=MARKER_SIZE)\n",
    "                    if mode == \"random\":\n",
    "                        mode_name = \"unbiased\"\n",
    "                    else:\n",
    "                        mode_name = mode\n",
    "                    legend_elements_asr.append(Line2D([0],[0], color=palette_buyer_mode[mode],\n",
    "                                                      linestyle=linestyle_buyer_mode[mode], marker=marker_buyer_mode[mode],\n",
    "                                                      lw=LINE_WIDTH, markersize=MARKER_SIZE,\n",
    "                                                      label=f'Buyer Baseline: {mode_name.capitalize()}'))\n",
    "                else:\n",
    "                    print(f\"Warning: Unexpected buyer_data_mode '{mode}' found. Skipping its ASR line.\")\n",
    "\n",
    "\n",
    "            ax.set_xlabel('Adversary Rate (Backdoor Attack)',)\n",
    "            ax.set_ylabel('Final Attack Success Rate (ASR)',)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=TICK_LABEL_FONT_SIZE, pad=6)\n",
    "            ax.set_ylim(-0.02, 1.02) # ASR is 0-1\n",
    "\n",
    "            if adv_rates_present_asr:\n",
    "                ax.set_xticks(ticks=adv_rates_present_asr)\n",
    "                ax.set_xticklabels(labels=[f'{r:.1f}' for r in adv_rates_present_asr])\n",
    "            else: # Fallback if no data for specific ADV_RATEs\n",
    "                ax.set_xticks(ticks=adv_rates_to_plot_on_x)\n",
    "                ax.set_xticklabels(labels=[f'{r:.1f}' for r in adv_rates_to_plot_on_x])\n",
    "\n",
    "            ax.grid(True, which='major', linestyle=':', linewidth=0.6)\n",
    "\n",
    "            if legend_elements_asr:\n",
    "                ax.legend(handles=legend_elements_asr,\n",
    "                           title='Buyer Baseline Type',\n",
    "                           loc='best', frameon=True, edgecolor='lightgray') # 'best' or 'lower right' often good for ASR\n",
    "\n",
    "            fig.suptitle(f'{current_aggregation_method}: Backdoor ASR by Buyer Baseline Quality', y=0.98, fontweight='bold')\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "            # plt.savefig(f\"{current_aggregation_method}_asr_vs_buyer_baseline.pdf\", bbox_inches='tight')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Not enough data to plot ASR by Buyer Baseline Impact after filtering.\")\n",
    "else:\n",
    "    print(\"DataFrame 'summary_df_avg' is not available. Skipping ASR by Buyer Baseline Impact plot.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.473254300Z"
    }
   },
   "id": "45ebc0aae391e6e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ensure summary_df_avg is not empty and preprocessed\n",
    "if summary_df_avg.empty:\n",
    "    print(\"CRITICAL: summary_df_avg is empty. Cannot generate plots.\")\n",
    "else:\n",
    "    print(\"\\n--- Generating SIMPLIFIED Attack Performance Plots ---\")\n",
    "    print(\"Plotting Adversary Selection Rate vs. Adversary Rate (0.2, 0.3, 0.4), with lines for Data Discovery Quality.\")\n",
    "    print(\"Includes 'No Attack' baseline at ADV_RATE = 0.0.\")\n",
    "\n",
    "    # --- Configuration for these simplified plots ---\n",
    "    # Define metrics to plot: (column_name, y_axis_label, plot_title_suffix)\n",
    "    # We are focusing on Adversary Selection Rate as requested.\n",
    "    metrics_to_plot = [\n",
    "        ('AVG_ADVERSARY_SELECTION_RATE', 'Avg. Adversary Selection Rate', 'Adversary Selection Rate vs. Adversary Rate')\n",
    "    ]\n",
    "\n",
    "    # ADV_RATE values to display for active attacks\n",
    "    target_adv_rates_active = [0.2, 0.3, 0.4]\n",
    "    # All ADV_RATE values that will appear on the x-axis (including No Attack baseline)\n",
    "    all_plot_adv_rates = sorted(list(set([0.0] + target_adv_rates_active)))\n",
    "\n",
    "\n",
    "    # Get unique values for looping and consistent legend ordering\n",
    "    aggregation_methods = sorted(summary_df_avg['AGGREGATION_METHOD'].unique())\n",
    "    \n",
    "    # Active attack methods (e.g., 'Backdoor', excluding 'No Attack' for main lines)\n",
    "    active_attack_names = sorted([\n",
    "        am for am in summary_df_avg['ATTACK_METHOD'].unique() if am != 'No Attack'\n",
    "    ])\n",
    "    if not active_attack_names:\n",
    "        print(\"Warning: No active attack methods found (e.g., 'Backdoor') in 'ATTACK_METHOD' column.\")\n",
    "        print(\"Plots will only show 'No Attack' data if available.\")\n",
    "\n",
    "    # Ensure discovery_quality values are sorted numerically for the legend\n",
    "    unique_dq_values = sorted(summary_df_avg['discovery_quality'].dropna().unique())\n",
    "    discovery_quality_hue_order = [str(dq) for dq in unique_dq_values]\n",
    "\n",
    "    # --- Plotting Loop ---\n",
    "    for agg_method in aggregation_methods:\n",
    "        for y_metric, y_label, title_suffix in metrics_to_plot:\n",
    "            \n",
    "            if y_metric not in summary_df_avg.columns:\n",
    "                print(f\"Metric '{y_metric}' not found in summary_df_avg. Skipping plot for {agg_method}.\")\n",
    "                continue\n",
    "\n",
    "            plt.figure(figsize=(10, 6)) # Slightly smaller figure might be fine\n",
    "            plot_has_data_for_metric = False \n",
    "\n",
    "            # 1. Plot lines for active attack methods (filtered for specific ADV_RATEs)\n",
    "            df_active_attacks_filtered = summary_df_avg[\n",
    "                (summary_df_avg['AGGREGATION_METHOD'] == agg_method) &\n",
    "                (summary_df_avg['ATTACK_METHOD'].isin(active_attack_names)) &\n",
    "                (summary_df_avg['ADV_RATE'].isin(target_adv_rates_active)) # Key filter\n",
    "            ].copy()\n",
    "\n",
    "            if not df_active_attacks_filtered.empty:\n",
    "                df_active_attacks_filtered['discovery_quality_cat'] = pd.Categorical(\n",
    "                    df_active_attacks_filtered['discovery_quality'].astype(str),\n",
    "                    categories=discovery_quality_hue_order,\n",
    "                    ordered=True\n",
    "                )\n",
    "                df_active_attacks_filtered.sort_values(by=['ATTACK_METHOD', 'discovery_quality_cat', 'ADV_RATE'], inplace=True)\n",
    "\n",
    "                sns.lineplot(\n",
    "                    data=df_active_attacks_filtered,\n",
    "                    x='ADV_RATE',\n",
    "                    y=y_metric,\n",
    "                    hue='discovery_quality_cat',\n",
    "                    style='ATTACK_METHOD' if len(active_attack_names) > 1 else 'discovery_quality_cat',\n",
    "                    markers=True,\n",
    "                    ci=None,\n",
    "                )\n",
    "                plot_has_data_for_metric = True\n",
    "            else:\n",
    "                if active_attack_names:\n",
    "                    print(f\"No data for active attacks at ADV_RATEs {target_adv_rates_active} under Aggregation: {agg_method} for metric {y_metric}.\")\n",
    "\n",
    "            # 2. Plot 'No Attack' data as reference points (at ADV_RATE = 0.0)\n",
    "            df_no_attack = summary_df_avg[\n",
    "                (summary_df_avg['AGGREGATION_METHOD'] == agg_method) &\n",
    "                (summary_df_avg['ATTACK_METHOD'] == 'No Attack') &\n",
    "                (summary_df_avg['ADV_RATE'] == 0.0) \n",
    "            ].copy()\n",
    "\n",
    "            if not df_no_attack.empty:\n",
    "                df_no_attack['discovery_quality_cat'] = pd.Categorical(\n",
    "                    df_no_attack['discovery_quality'].astype(str),\n",
    "                    categories=discovery_quality_hue_order,\n",
    "                    ordered=True\n",
    "                )\n",
    "                df_no_attack.sort_values(by=['discovery_quality_cat'], inplace=True)\n",
    "                \n",
    "                sns.scatterplot(\n",
    "                    data=df_no_attack,\n",
    "                    x='ADV_RATE',\n",
    "                    y=y_metric,\n",
    "                    hue='discovery_quality_cat',\n",
    "                    marker='X', \n",
    "                    s=150,      \n",
    "                    legend=False, \n",
    "                    zorder=5      \n",
    "                )\n",
    "                # If there was no active attack data, but there IS 'No Attack' data,\n",
    "                # we still want to show a legend for discovery_quality from these points.\n",
    "                if not plot_has_data_for_metric and not df_no_attack.empty:\n",
    "                    # Need to manually create a legend if only scatterplot points are shown\n",
    "                    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "                    if not handles: # if scatterplot didn't auto-create handles (e.g. due to legend=False)\n",
    "                                    # This part might need refinement if only scatter is plotted\n",
    "                        # Create dummy lines for legend if only scatter points exist\n",
    "                        # This is a bit of a hack, usually lineplot provides the primary legend\n",
    "                        temp_handles = []\n",
    "                        temp_labels = []\n",
    "                        palette = sns.color_palette(n_colors=len(discovery_quality_hue_order))\n",
    "                        color_map = {dq: palette[i] for i, dq in enumerate(discovery_quality_hue_order)}\n",
    "\n",
    "                        for dq_val_str in df_no_attack['discovery_quality_cat'].unique():\n",
    "                            if dq_val_str in color_map:\n",
    "                                temp_handles.append(Line2D([0], [0], marker='X', color='w', label=str(dq_val_str),\n",
    "                                                      markerfacecolor=color_map[dq_val_str], markersize=10))\n",
    "                                temp_labels.append(str(dq_val_str))\n",
    "                        if temp_handles:\n",
    "                             plt.legend(handles=temp_handles, labels=temp_labels, title=\"Discovery Quality\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "                plot_has_data_for_metric = True # Even if only 'No Attack' data is plotted\n",
    "            else:\n",
    "                print(f\"No 'No Attack' data found for Aggregation: {agg_method} for metric {y_metric} at ADV_RATE=0.\")\n",
    "\n",
    "\n",
    "            # --- Finalize Plot ---\n",
    "            if plot_has_data_for_metric:\n",
    "                title_parts = [title_suffix]\n",
    "                if active_attack_names and not df_active_attacks_filtered.empty:\n",
    "                    title_parts.append(f\"(Active Attack(s): {', '.join(active_attack_names)})\")\n",
    "                title_parts.append(f\"Aggregation: {agg_method}\")\n",
    "                \n",
    "                plt.title('\\n'.join(title_parts))\n",
    "                plt.xlabel('Adversary Rate (ADV_RATE)')\n",
    "                plt.ylabel(y_label)\n",
    "                \n",
    "                # Ensure legend exists and is correctly titled\n",
    "                current_handles, current_labels = plt.gca().get_legend_handles_labels()\n",
    "                if current_handles: # Only add legend if there are items to show\n",
    "                    legend_title = \"Discovery Quality\"\n",
    "                    if len(active_attack_names) > 1 and 'ATTACK_METHOD' in df_active_attacks_filtered.columns:\n",
    "                         pass # Seaborn's default title based on hue/style is usually fine\n",
    "                    plt.legend(title=legend_title, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "                plt.grid(True)\n",
    "                plt.axhline(0, color='grey', linestyle=':', linewidth=0.8) \n",
    "                \n",
    "                # Set specific x-axis ticks and limits\n",
    "                plt.xticks(all_plot_adv_rates)\n",
    "                plt.xlim(left=min(all_plot_adv_rates) - 0.05, right=max(all_plot_adv_rates) + 0.05)\n",
    "\n",
    "                # Set y-axis limits for selection rate (0-1)\n",
    "                if y_metric == 'AVG_ADVERSARY_SELECTION_RATE':\n",
    "                    plt.ylim(bottom=-0.05, top=1.05)\n",
    "                \n",
    "                plt.tight_layout(rect=[0, 0, 0.85, 1]) \n",
    "                \n",
    "                sanitized_agg_method = agg_method.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                sanitized_y_metric = y_metric.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                plot_filename = f\"{OUTPUT_DIR}/plot_simplified_{sanitized_agg_method}_{sanitized_y_metric}_vs_ADV_RATE_by_DQ.png\"\n",
    "                try:\n",
    "                    plt.savefig(plot_filename, bbox_inches='tight')\n",
    "                    print(f\"Saved plot: {plot_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving plot {plot_filename}: {e}\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close() \n",
    "\n",
    "    print(\"--- Finished generating SIMPLIFIED attack performance plots ---\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.473754600Z"
    }
   },
   "id": "a5402c3b8348b3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D # For custom legend\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "FMNIST_DATASET_NAME = 'FMNIST'\n",
    "MARTFL_ALGO_NAME = 'martfl'\n",
    "YOUR_BACKDOOR_ATTACK_NAME = 'Backdoor'\n",
    "FIXED_TRIGGER_RATE = 0.1\n",
    "\n",
    "# Figure (a) settings: Impact of Buyer Data Quality\n",
    "MEDIUM_DISCOVERY_QUALITY_FOR_A = 1.0\n",
    "UNBIASED_BUYER_MODE = 'random'\n",
    "BIASED_BUYER_MODE = 'biased'\n",
    "# X-axis for (a) is ADV_RATE, e.g., [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "# Figure (b) settings: Impact of Seller Data Relevance\n",
    "DISCOVERY_QUALITY_LEVELS_FOR_B = sorted([0.1, 1.0, 10.0]) # X-axis for (b)\n",
    "FIXED_ADV_RATE_FOR_B = 0.3\n",
    "FIXED_BUYER_MODE_FOR_B = UNBIASED_BUYER_MODE\n",
    "\n",
    "# --- Output Paths ---\n",
    "BASE_SAVE_DIR = \"./results/paper_figures/\"\n",
    "os.makedirs(BASE_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Filenames (made more specific)\n",
    "FILENAME_A = f\"{BASE_SAVE_DIR}fmnist_robustness_vs_buyer_mode_trig{FIXED_TRIGGER_RATE:.2f}_dq{MEDIUM_DISCOVERY_QUALITY_FOR_A:.1f}.pdf\"\n",
    "FILENAME_B = f\"{BASE_SAVE_DIR}fmnist_robustness_vs_seller_relevance_trig{FIXED_TRIGGER_RATE:.2f}_adv{FIXED_ADV_RATE_FOR_B:.1f}.pdf\"\n",
    "\n",
    "\n",
    "# --- Dummy Data for Testing (if summary_df_avg is not available) ---\n",
    "if 'summary_df_avg' not in locals() or summary_df_avg.empty:\n",
    "    print(\"CRITICAL ERROR: 'summary_df_avg' DataFrame not found. Using dummy data for layout.\")\n",
    "    adv_rates_a_axis = [0.1, 0.2, 0.3, 0.4]\n",
    "    dummy_data_a_list = []\n",
    "    for adv_rate in adv_rates_a_axis:\n",
    "        for buyer_mode in [UNBIASED_BUYER_MODE, BIASED_BUYER_MODE]:\n",
    "            dummy_data_a_list.append({\n",
    "                'AGGREGATION_METHOD': MARTFL_ALGO_NAME, 'TRIGGER_RATE': FIXED_TRIGGER_RATE,\n",
    "                'ATTACK_METHOD': YOUR_BACKDOOR_ATTACK_NAME, 'ADV_RATE': adv_rate,\n",
    "                'buyer_data_mode': buyer_mode, 'discovery_quality': MEDIUM_DISCOVERY_QUALITY_FOR_A,\n",
    "                'FINAL_MAIN_ACC': np.random.uniform(0.5, 0.9), 'FINAL_ASR': np.random.uniform(0.1, 0.6)\n",
    "            })\n",
    "    dummy_df_a = pd.DataFrame(dummy_data_a_list)\n",
    "\n",
    "    dummy_data_b_list = []\n",
    "    for dq_level in DISCOVERY_QUALITY_LEVELS_FOR_B:\n",
    "        dummy_data_b_list.append({\n",
    "            'AGGREGATION_METHOD': MARTFL_ALGO_NAME, 'TRIGGER_RATE': FIXED_TRIGGER_RATE,\n",
    "            'ATTACK_METHOD': YOUR_BACKDOOR_ATTACK_NAME, 'ADV_RATE': FIXED_ADV_RATE_FOR_B,\n",
    "            'buyer_data_mode': FIXED_BUYER_MODE_FOR_B, 'discovery_quality': dq_level,\n",
    "            'FINAL_MAIN_ACC': np.random.uniform(0.6, 0.85) - (dq_level * 0.01 if dq_level <=1 else dq_level *0.005) , # Simulating relevance impact\n",
    "            'FINAL_ASR': np.random.uniform(0.15, 0.5) + (dq_level * 0.01 if dq_level <=1 else dq_level *0.005)\n",
    "        })\n",
    "    dummy_df_b = pd.DataFrame(dummy_data_b_list)\n",
    "    summary_df_avg = pd.concat([dummy_df_a, dummy_df_b], ignore_index=True).drop_duplicates()\n",
    "else:\n",
    "    print(\"'summary_df_avg' DataFrame is available.\")\n",
    "\n",
    "# --- Helper function for grouping and averaging ---\n",
    "def get_averaged_data(df, group_by_cols, metrics_to_avg=['FINAL_MAIN_ACC', 'FINAL_ASR']):\n",
    "    if df.empty:\n",
    "        # print(f\"Info: get_averaged_data received an empty DataFrame for groups: {group_by_cols}.\")\n",
    "        return pd.DataFrame(columns=group_by_cols + metrics_to_avg)\n",
    "    actual_metrics_to_avg = [m for m in metrics_to_avg if m in df.columns]\n",
    "    if not actual_metrics_to_avg:\n",
    "        # print(f\"Warning: None of metrics {metrics_to_avg} found for averaging. Group: {group_by_cols}\")\n",
    "        return pd.DataFrame(columns=group_by_cols + metrics_to_avg)\n",
    "    df_cleaned = df.dropna(subset=actual_metrics_to_avg, how='any').copy()\n",
    "    if df_cleaned.empty:\n",
    "        # if not df.empty: print(f\"Warning: Data became empty after dropping NaNs for metrics {actual_metrics_to_avg}. Group: {group_by_cols}\")\n",
    "        return pd.DataFrame(columns=group_by_cols + actual_metrics_to_avg)\n",
    "    for metric in actual_metrics_to_avg: # Ensure numeric before mean\n",
    "        df_cleaned[metric] = pd.to_numeric(df_cleaned[metric], errors='coerce')\n",
    "    df_cleaned.dropna(subset=actual_metrics_to_avg, how='any', inplace=True)\n",
    "    if df_cleaned.empty:\n",
    "        # print(f\"Warning: Data became empty after coercing metrics. Group: {group_by_cols}\")\n",
    "        return pd.DataFrame(columns=group_by_cols + actual_metrics_to_avg)\n",
    "    averaged_df = df_cleaned.groupby(group_by_cols, as_index=False)[actual_metrics_to_avg].mean()\n",
    "    if 'ADV_RATE' in group_by_cols and group_by_cols[0] == 'ADV_RATE':\n",
    "        averaged_df = averaged_df.sort_values('ADV_RATE')\n",
    "    elif 'discovery_quality' in group_by_cols and group_by_cols[0] == 'discovery_quality':\n",
    "        averaged_df = averaged_df.sort_values('discovery_quality')\n",
    "    return averaged_df\n",
    "\n",
    "# --- Base Filtering (applied once) ---\n",
    "base_filter_conditions = (\n",
    "    (summary_df_avg['AGGREGATION_METHOD'].str.lower() == MARTFL_ALGO_NAME.lower()) &\n",
    "    (summary_df_avg['TRIGGER_RATE'] == FIXED_TRIGGER_RATE) &\n",
    "    (summary_df_avg['ATTACK_METHOD'] == YOUR_BACKDOOR_ATTACK_NAME)\n",
    ")\n",
    "df_filtered_base_for_all = summary_df_avg[base_filter_conditions].copy()\n",
    "\n",
    "if df_filtered_base_for_all.empty:\n",
    "     print(f\"Warning: No data found after applying common base filter. Plots may be empty.\")\n",
    "\n",
    "\n",
    "# --- FIGURE A: Impact of Buyer Data Quality ---\n",
    "print(\"\\n--- Preparing Data for Figure A (Buyer Mode Impact) ---\")\n",
    "df_a_filtered = df_filtered_base_for_all[\n",
    "    (df_filtered_base_for_all['discovery_quality'] == MEDIUM_DISCOVERY_QUALITY_FOR_A) &\n",
    "    (df_filtered_base_for_all['ADV_RATE'] > 0) # ADV_RATE > 0 for attack plots\n",
    "].copy()\n",
    "\n",
    "if df_a_filtered.empty:\n",
    "    print(f\"Warning: No data for Figure A after filtering for discovery_quality == {MEDIUM_DISCOVERY_QUALITY_FOR_A} and ADV_RATE > 0\")\n",
    "\n",
    "df_a_unbiased_avg = get_averaged_data(\n",
    "    df_a_filtered[df_a_filtered['buyer_data_mode'] == UNBIASED_BUYER_MODE],\n",
    "    group_by_cols=['ADV_RATE']\n",
    ")\n",
    "df_a_biased_avg = get_averaged_data(\n",
    "    df_a_filtered[df_a_filtered['buyer_data_mode'] == BIASED_BUYER_MODE],\n",
    "    group_by_cols=['ADV_RATE']\n",
    ")\n",
    "main_acc_color_attack = 'mediumblue'\n",
    "asr_color_attack = 'crimson'\n",
    "no_attack_acc_color = 'dimgray'  # Changed for better contrast with blue/red\n",
    "no_attack_asr_color = 'salmon'  # Changed for better contrast\n",
    "\n",
    "# --- Plotting Figure A ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "metrics_present_a_unbiased = all(m in df_a_unbiased_avg.columns for m in ['FINAL_MAIN_ACC', 'FINAL_ASR'])\n",
    "metrics_present_a_biased = all(m in df_a_biased_avg.columns for m in ['FINAL_MAIN_ACC', 'FINAL_ASR'])\n",
    "\n",
    "if not df_a_unbiased_avg.empty and not df_a_biased_avg.empty and metrics_present_a_unbiased and metrics_present_a_biased:\n",
    "    fig_a, ax_a = plt.subplots() # Single panel\n",
    "    ax_a_twin = ax_a.twinx()\n",
    "    adv_rates_a_plot = sorted(pd.concat([df_a_unbiased_avg['ADV_RATE'], df_a_biased_avg['ADV_RATE']]).unique())\n",
    "\n",
    "    ax_a.plot(df_a_unbiased_avg['ADV_RATE'], df_a_unbiased_avg['FINAL_MAIN_ACC'], marker='o', linestyle='-', color='royalblue', label='Unbiased Buyer (Acc)')\n",
    "    ax_a_twin.plot(df_a_unbiased_avg['ADV_RATE'], df_a_unbiased_avg['FINAL_ASR'], marker='o', linestyle='--', color='deepskyblue', label='Unbiased Buyer (ASR)')\n",
    "\n",
    "    ax_a.plot(df_a_biased_avg['ADV_RATE'], df_a_biased_avg['FINAL_MAIN_ACC'], marker='s', linestyle='-', color='firebrick', label='Biased Buyer (Acc)')\n",
    "    ax_a_twin.plot(df_a_biased_avg['ADV_RATE'], df_a_biased_avg['FINAL_ASR'], marker='s', linestyle='--', color='lightcoral', label='Biased Buyer (ASR)')\n",
    "\n",
    "    ax_a.set_xlabel('Adversary Rate')\n",
    "    ax_a.set_ylabel('Main Accuracy')\n",
    "    ax_a_twin.set_ylabel('Attack Success Rate (ASR)')\n",
    "    ax_a.grid(True, linestyle=':', linewidth=0.7); ax_a_twin.grid(False)\n",
    "\n",
    "    acc_vals_a = pd.concat([df_a_unbiased_avg['FINAL_MAIN_ACC'], df_a_biased_avg['FINAL_MAIN_ACC']]).dropna()\n",
    "    asr_vals_a = pd.concat([df_a_unbiased_avg['FINAL_ASR'], df_a_biased_avg['FINAL_ASR']]).dropna()\n",
    "    \n",
    "    if not acc_vals_a.empty:\n",
    "        acc_min, acc_max = acc_vals_a.min(), acc_vals_a.max()\n",
    "        ax_a.set_ylim(\n",
    "            bottom=max(acc_min - 0.05, 0),\n",
    "            top=min(acc_max + 0.05, 1.05)\n",
    "        )\n",
    "    else:\n",
    "        ax_a.set_ylim(0.4, 1.05)\n",
    "    \n",
    "    if not asr_vals_a.empty:\n",
    "        asr_min, asr_max = asr_vals_a.min(), asr_vals_a.max()\n",
    "        ax_a_twin.set_ylim(\n",
    "            bottom=max(asr_min - 0.05, 0),\n",
    "            top=min(asr_max + 0.05, 1.05)\n",
    "        )\n",
    "    else:\n",
    "        ax_a_twin.set_ylim(0.0, 1.0)\n",
    "\n",
    "\n",
    "    if adv_rates_a_plot:\n",
    "        ax_a.set_xticks(ticks=adv_rates_a_plot)\n",
    "        ax_a.set_xticklabels(labels=[f'{r:.1f}' for r in adv_rates_a_plot])\n",
    "\n",
    "    legend_elements_a = [\n",
    "        Line2D([0], [0], color='royalblue', lw=2, linestyle='-', marker='o', label='Unbiased Buyer (Acc)'),\n",
    "        Line2D([0], [0], color='deepskyblue', lw=2, linestyle='--', marker='o', label='Unbiased Buyer (ASR)'),\n",
    "        Line2D([0], [0], color='firebrick', lw=2, linestyle='-', marker='s', label='Biased Buyer (Acc)'),\n",
    "        Line2D([0], [0], color='lightcoral', lw=2, linestyle='--', marker='s', label='Biased Buyer (ASR)')\n",
    "    ]\n",
    "    ax_a.legend(handles=legend_elements_a, loc='lower right')\n",
    "    # fig_a.suptitle(f'Impact of Buyer Data Quality (DQ fixed at {MEDIUM_DISCOVERY_QUALITY_FOR_A:.1f})', y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "    try:\n",
    "        plt.savefig(FILENAME_A, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Figure A saved to: {FILENAME_A}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Figure A: {e}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warning: Not enough averaged data for Figure A (Buyer Mode Impact). Plot not generated.\")\n",
    "\n",
    "\n",
    "# --- FIGURE B: Impact of Seller Data Relevance ---\n",
    "print(\"\\n--- Preparing Data for Figure B (Seller Relevance Impact) ---\")\n",
    "df_b_filtered = df_filtered_base_for_all[\n",
    "    (df_filtered_base_for_all['ADV_RATE'] == FIXED_ADV_RATE_FOR_B) &\n",
    "    (df_filtered_base_for_all['buyer_data_mode'] == FIXED_BUYER_MODE_FOR_B) &\n",
    "    (df_filtered_base_for_all['discovery_quality'].isin(DISCOVERY_QUALITY_LEVELS_FOR_B))\n",
    "].copy()\n",
    "\n",
    "if df_b_filtered.empty:\n",
    "    print(f\"Warning: No data for Figure B after filtering for ADV_RATE={FIXED_ADV_RATE_FOR_B}, buyer_mode={FIXED_BUYER_MODE_FOR_B}, and DQ in {DISCOVERY_QUALITY_LEVELS_FOR_B}\")\n",
    "\n",
    "df_b_avg = get_averaged_data(\n",
    "    df_b_filtered,\n",
    "    group_by_cols=['discovery_quality'] # X-axis for figure (b)\n",
    ")\n",
    "\n",
    "# --- Plotting Figure B ---\n",
    "metrics_present_b = all(m in df_b_avg.columns for m in ['FINAL_MAIN_ACC', 'FINAL_ASR'])\n",
    "\n",
    "if not df_b_avg.empty and metrics_present_b:\n",
    "    fig_b, ax_b = plt.subplots() # Single panel\n",
    "    ax_b_twin = ax_b.twinx()\n",
    "\n",
    "    discovery_qualities_to_plot_b = sorted(df_b_avg['discovery_quality'].unique())\n",
    "    x_positions_b = np.arange(len(discovery_qualities_to_plot_b))\n",
    "\n",
    "    ax_b.plot(x_positions_b, df_b_avg['FINAL_MAIN_ACC'], marker='D', linestyle='-', color=main_acc_color_attack, label='Accuracy')\n",
    "    ax_b_twin.plot(x_positions_b, df_b_avg['FINAL_ASR'], marker='X', linestyle='--', color=asr_color_attack, label='ASR')\n",
    "\n",
    "    ax_b.set_xlabel('Seller Data Relevance (Discovery Quality)')\n",
    "    ax_b.set_ylabel('Main Accuracy', color=main_acc_color_attack)\n",
    "    ax_b_twin.set_ylabel('Attack Success Rate (ASR)', color=asr_color_attack)\n",
    "    ax_b.grid(True, linestyle=':', linewidth=0.7); ax_b_twin.grid(False)\n",
    "\n",
    "    # --- Dynamically set Y-limits for Figure B ---\n",
    "    acc_vals_b = df_b_avg['FINAL_MAIN_ACC'].dropna()\n",
    "    asr_vals_b = df_b_avg['FINAL_ASR'].dropna()\n",
    "    \n",
    "    if not acc_vals_b.empty:\n",
    "        acc_min_b, acc_max_b = acc_vals_b.min(), acc_vals_b.max()\n",
    "        ax_b.set_ylim(\n",
    "            bottom=max(acc_min_b - 0.05, 0),\n",
    "            top=min(acc_max_b + 0.05, 1.05)\n",
    "        )\n",
    "    else:\n",
    "        ax_b.set_ylim(0.4, 1.05)\n",
    "    \n",
    "    if not asr_vals_b.empty:\n",
    "        asr_min_b, asr_max_b = asr_vals_b.min(), asr_vals_b.max()\n",
    "        ax_b_twin.set_ylim(\n",
    "            bottom=max(asr_min_b - 0.05, 0),\n",
    "            top=min(asr_max_b + 0.05, 1.05)\n",
    "        )\n",
    "    else:\n",
    "        ax_b_twin.set_ylim(0.0, 1.0)\n",
    "\n",
    "\n",
    "    if discovery_qualities_to_plot_b:\n",
    "        ax_b.set_xticks(ticks=x_positions_b)\n",
    "        x_tick_labels_b = [f'{dq:.1f}' if dq < 1 else f'{int(dq)}' if dq == int(dq) else f'{dq:.1f}' for dq in discovery_qualities_to_plot_b]\n",
    "        ax_b.set_xticklabels(labels=x_tick_labels_b)\n",
    "    else: # Fallback for x-ticks\n",
    "        fallback_x_pos_b = np.arange(len(DISCOVERY_QUALITY_LEVELS_FOR_B))\n",
    "        ax_b.set_xticks(ticks=fallback_x_pos_b)\n",
    "        ax_b.set_xticklabels(labels=[f'{dq:.1f}' if dq<1 else f'{int(dq)}' for dq in DISCOVERY_QUALITY_LEVELS_FOR_B], )\n",
    "\n",
    "\n",
    "    legend_elements_b = [\n",
    "        Line2D([0], [0], color=main_acc_color_attack, lw=2, linestyle='-', marker='D', label='Accuracy'),\n",
    "        Line2D([0], [0], color=asr_color_attack, lw=2, linestyle='--', marker='X', label='ASR')\n",
    "    ]\n",
    "    ax_b.legend(handles=legend_elements_b, loc='best',\n",
    "                title=f'Adv Rate={FIXED_ADV_RATE_FOR_B:.1f}, Buyer Unbiased')\n",
    "\n",
    "    # fig_b.suptitle(f'Impact of Seller Data Relevance (Adv Rate fixed at {FIXED_ADV_RATE_FOR_B:.1f})', y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "    try:\n",
    "        plt.savefig(FILENAME_B, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Figure B saved to: {FILENAME_B}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Figure B: {e}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warning: Not enough averaged data for Figure B (Seller Relevance Impact). Plot not generated.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.474756900Z"
    }
   },
   "id": "128bfddd4e6979a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns # For a nice color palette\n",
    "\n",
    "# --- Configuration ---\n",
    "MARTFL_ALGO_NAME = 'martfl'\n",
    "YOUR_BACKDOOR_ATTACK_NAME = 'Backdoor'\n",
    "\n",
    "# Fixed parameters for these plots (ADJUST AS NEEDED FOR YOUR EXPERIMENT SET)\n",
    "FIXED_DISCOVERY_QUALITY = 1.0\n",
    "FIXED_BUYER_MODE = 'random' # Or 'biased', or whatever you want to fix\n",
    "# ADV_RATES_TO_PLOT will be used for different lines/colors in each plot\n",
    "ADV_RATES_TO_PLOT_AS_LINES = sorted([0.1, 0.2, 0.3, 0.4]) # Or other relevant adversary rates\n",
    "\n",
    "# X-axis: Trigger Rates\n",
    "# Ensure these trigger rates exist in your data.\n",
    "# If they are continuous, the plot will connect points. If categorical, ensure data for each.\n",
    "# For this example, let's assume trigger_rate is a continuous variable in your data\n",
    "# or you have specific discrete values you ran experiments for.\n",
    "# We will plot the unique trigger rates found in the filtered data.\n",
    "\n",
    "# --- Output Paths ---\n",
    "BASE_SAVE_DIR = \"./results/paper_figures/trigger_rate_impact/\"\n",
    "os.makedirs(BASE_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "FILENAME_ASR_VS_TRIGGER = f\"{BASE_SAVE_DIR}asr_vs_trigger_rate_dq{FIXED_DISCOVERY_QUALITY:.1f}_bm{FIXED_BUYER_MODE}.pdf\"\n",
    "FILENAME_MAL_SEL_VS_TRIGGER = f\"{BASE_SAVE_DIR}mal_sel_vs_trigger_rate_dq{FIXED_DISCOVERY_QUALITY:.1f}_bm{FIXED_BUYER_MODE}.pdf\"\n",
    "\n",
    "# --- Dummy Data for Testing (if summary_df_avg is not available) ---\n",
    "if 'summary_df_avg' not in locals() or summary_df_avg.empty:\n",
    "    print(\"CRITICAL ERROR: 'summary_df_avg' DataFrame not found. Using dummy data.\")\n",
    "    dummy_data_list = []\n",
    "    trigger_rates_dummy = np.linspace(0.05, 0.5, 5) # Example trigger rates\n",
    "    for adv_rate in ADV_RATES_TO_PLOT_AS_LINES:\n",
    "        for tr in trigger_rates_dummy:\n",
    "            dummy_data_list.append({\n",
    "                'AGGREGATION_METHOD': MARTFL_ALGO_NAME,\n",
    "                'TRIGGER_RATE': tr,\n",
    "                'ATTACK_METHOD': YOUR_BACKDOOR_ATTACK_NAME,\n",
    "                'ADV_RATE': adv_rate,\n",
    "                'buyer_data_mode': FIXED_BUYER_MODE,\n",
    "                'discovery_quality': FIXED_DISCOVERY_QUALITY,\n",
    "                'FINAL_ASR': (adv_rate * 0.8 + tr * 1.5) * np.random.uniform(0.7, 1.0) if (adv_rate * 0.8 + tr * 1.5) < 1 else 0.95, # Simulating ASR increase\n",
    "                'AVG_ADVERSARY_SELECTION_RATE': (adv_rate * 0.5 + tr * 0.2 + 0.1) * np.random.uniform(0.8,1.0) # Simulating selection\n",
    "            })\n",
    "    summary_df_avg = pd.DataFrame(dummy_data_list)\n",
    "    summary_df_avg['FINAL_ASR'] = summary_df_avg['FINAL_ASR'].clip(0,1)\n",
    "    summary_df_avg['AVG_ADVERSARY_SELECTION_RATE'] = summary_df_avg['AVG_ADVERSARY_SELECTION_RATE'].clip(0,1)\n",
    "else:\n",
    "    print(\"'summary_df_avg' DataFrame is available.\")\n",
    "\n",
    "# --- Helper function for grouping and averaging (same as before) ---\n",
    "def get_averaged_data(df, group_by_cols, metrics_to_avg):\n",
    "    if df.empty: return pd.DataFrame(columns=group_by_cols + metrics_to_avg)\n",
    "    actual_metrics_to_avg = [m for m in metrics_to_avg if m in df.columns]\n",
    "    if not actual_metrics_to_avg: return pd.DataFrame(columns=group_by_cols + metrics_to_avg)\n",
    "    df_cleaned = df.dropna(subset=actual_metrics_to_avg, how='any').copy()\n",
    "    if df_cleaned.empty: return pd.DataFrame(columns=group_by_cols + actual_metrics_to_avg)\n",
    "    for metric in actual_metrics_to_avg:\n",
    "        df_cleaned[metric] = pd.to_numeric(df_cleaned[metric], errors='coerce')\n",
    "    df_cleaned.dropna(subset=actual_metrics_to_avg, how='any', inplace=True)\n",
    "    if df_cleaned.empty: return pd.DataFrame(columns=group_by_cols + actual_metrics_to_avg)\n",
    "    \n",
    "    averaged_df = df_cleaned.groupby(group_by_cols, as_index=False)[actual_metrics_to_avg].mean()\n",
    "    \n",
    "    # Sort by the primary x-axis of the plot (which is TRIGGER_RATE here)\n",
    "    if 'TRIGGER_RATE' in group_by_cols:\n",
    "        averaged_df = averaged_df.sort_values('TRIGGER_RATE')\n",
    "    return averaged_df\n",
    "\n",
    "# --- Base Filtering ---\n",
    "base_filter_conditions_trigger = (\n",
    "    (summary_df_avg['AGGREGATION_METHOD'].str.lower() == MARTFL_ALGO_NAME.lower()) &\n",
    "    (summary_df_avg['ATTACK_METHOD'] == YOUR_BACKDOOR_ATTACK_NAME) &\n",
    "    (summary_df_avg['discovery_quality'] == FIXED_DISCOVERY_QUALITY) &\n",
    "    (summary_df_avg['buyer_data_mode'] == FIXED_BUYER_MODE) &\n",
    "    (summary_df_avg['ADV_RATE'].isin(ADV_RATES_TO_PLOT_AS_LINES)) # Filter for specific ADV_RATEs to show as lines\n",
    "    # TRIGGER_RATE will be the x-axis, so we don't filter it here initially\n",
    ")\n",
    "df_filtered_for_trigger_plots = summary_df_avg[base_filter_conditions_trigger].copy()\n",
    "\n",
    "if df_filtered_for_trigger_plots.empty:\n",
    "     print(f\"Warning: No data found after applying base filter for trigger rate plots. Plots may be empty.\")\n",
    "     print(f\"  Filters: AGG_METHOD='{MARTFL_ALGO_NAME}', ATTACK='{YOUR_BACKDOOR_ATTACK_NAME}', DQ={FIXED_DISCOVERY_QUALITY}, BM='{FIXED_BUYER_MODE}', ADV_RATES in {ADV_RATES_TO_PLOT_AS_LINES}\")\n",
    "\n",
    "\n",
    "# --- Data for FIGURE 1: ASR vs. Trigger Rate ---\n",
    "print(\"\\n--- Preparing Data for Figure 1 (ASR vs. Trigger Rate) ---\")\n",
    "metric_for_fig1 = 'FINAL_ASR'\n",
    "# Group by TRIGGER_RATE (x-axis) and ADV_RATE (lines/hue)\n",
    "# The get_averaged_data function will average over any other variations (e.g., seeds)\n",
    "df_fig1_avg = get_averaged_data(\n",
    "    df_filtered_for_trigger_plots,\n",
    "    group_by_cols=['TRIGGER_RATE', 'ADV_RATE'], # ADV_RATE will differentiate lines\n",
    "    metrics_to_avg=[metric_for_fig1]\n",
    ")\n",
    "\n",
    "# --- Plotting FIGURE 1: ASR vs. Trigger Rate ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "palette = sns.color_palette(\"viridis\", n_colors=len(ADV_RATES_TO_PLOT_AS_LINES)) # Or \"mako\", \"rocket\"\n",
    "\n",
    "\n",
    "if not df_fig1_avg.empty and metric_for_fig1 in df_fig1_avg.columns:\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    \n",
    "    for i, adv_rate in enumerate(ADV_RATES_TO_PLOT_AS_LINES):\n",
    "        data_for_line = df_fig1_avg[df_fig1_avg['ADV_RATE'] == adv_rate]\n",
    "        if not data_for_line.empty:\n",
    "            ax1.plot(data_for_line['TRIGGER_RATE'], data_for_line[metric_for_fig1],\n",
    "                     marker='o', linestyle='-', color=palette[i],\n",
    "                     label=f'Adv. Rate = {adv_rate:.1f}')\n",
    "\n",
    "    ax1.set_xlabel('Trigger Pattern Rate (Intensity)')\n",
    "    ax1.set_ylabel('Final Attack Success Rate (ASR)')\n",
    "    ax1.grid(True, linestyle=':', linewidth=0.7)\n",
    "    ax1.set_ylim(bottom=-0.02, top=1.02)\n",
    "    \n",
    "    # X-ticks: Show unique trigger rates from data or define explicitly\n",
    "    unique_trigger_rates_plot1 = sorted(df_fig1_avg['TRIGGER_RATE'].unique())\n",
    "    if unique_trigger_rates_plot1:\n",
    "        ax1.set_xticks(ticks=unique_trigger_rates_plot1)\n",
    "        ax1.set_xticklabels(labels=[f'{tr:.2f}' for tr in unique_trigger_rates_plot1], rotation=0, ha=\"right\")\n",
    "\n",
    "    ax1.legend(title='Adversary Rate', loc='best', )\n",
    "    fig1.suptitle(f'ASR vs. Trigger Rate (DQ={FIXED_DISCOVERY_QUALITY:.1f}, Buyer={FIXED_BUYER_MODE.capitalize()})', y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    try:\n",
    "        plt.savefig(FILENAME_ASR_VS_TRIGGER, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Figure 1 (ASR vs Trigger Rate) saved to: {FILENAME_ASR_VS_TRIGGER}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Figure 1: {e}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warning: Not enough averaged data for Figure 1 (ASR vs. Trigger Rate). Plot not generated.\")\n",
    "\n",
    "\n",
    "# --- Data for FIGURE 2: Malicious Selection Rate vs. Trigger Rate ---\n",
    "print(\"\\n--- Preparing Data for Figure 2 (Malicious Selection vs. Trigger Rate) ---\")\n",
    "metric_for_fig2 = 'AVG_ADVERSARY_SELECTION_RATE'\n",
    "df_fig2_avg = get_averaged_data(\n",
    "    df_filtered_for_trigger_plots,\n",
    "    group_by_cols=['TRIGGER_RATE', 'ADV_RATE'],\n",
    "    metrics_to_avg=[metric_for_fig2]\n",
    ")\n",
    "\n",
    "# --- Plotting FIGURE 2: Malicious Selection Rate vs. Trigger Rate ---\n",
    "if not df_fig2_avg.empty and metric_for_fig2 in df_fig2_avg.columns:\n",
    "    fig2, ax2 = plt.subplots()\n",
    "\n",
    "    for i, adv_rate in enumerate(ADV_RATES_TO_PLOT_AS_LINES):\n",
    "        data_for_line = df_fig2_avg[df_fig2_avg['ADV_RATE'] == adv_rate]\n",
    "        if not data_for_line.empty:\n",
    "            ax2.plot(data_for_line['TRIGGER_RATE'], data_for_line[metric_for_fig2],\n",
    "                     marker='s', linestyle='--', color=palette[i], # Different marker/linestyle\n",
    "                     label=f'Adv. Rate = {adv_rate:.1f}')\n",
    "\n",
    "    ax2.set_xlabel('Trigger Pattern Rate (Intensity)')\n",
    "    ax2.set_ylabel('Avg. Adversary Selection Rate')\n",
    "    ax2.grid(True, linestyle=':', linewidth=0.7)\n",
    "    ax2.set_ylim(bottom=-0.02, top=1.02) # Selection rate is also 0-1\n",
    "\n",
    "    unique_trigger_rates_plot2 = sorted(df_fig2_avg['TRIGGER_RATE'].unique())\n",
    "    if unique_trigger_rates_plot2:\n",
    "        ax2.set_xticks(ticks=unique_trigger_rates_plot2)\n",
    "        ax2.set_xticklabels(labels=[f'{tr:.2f}' for tr in unique_trigger_rates_plot2], rotation=0, ha=\"right\")\n",
    "\n",
    "    ax2.legend(title='Adversary Rate', loc='best')\n",
    "    fig2.suptitle(f'Adversary Selection vs. Trigger Rate (DQ={FIXED_DISCOVERY_QUALITY:.1f}, Buyer={FIXED_BUYER_MODE.capitalize()})', y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    try:\n",
    "        plt.savefig(FILENAME_MAL_SEL_VS_TRIGGER, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Figure 2 (Malicious Selection vs Trigger Rate) saved to: {FILENAME_MAL_SEL_VS_TRIGGER}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Figure 2: {e}\")\n",
    "    save_figure_as_pdf(\n",
    "        fig=fig2, \n",
    "        output_directory=FIGURE_SAVE_DIR, \n",
    "        base_filename=\"asr_trigger_rate\", # Base name describing the plot\n",
    "        current_aggregation_method=current_aggregation_method,\n",
    "        # other_details=f\"target{int(TARGET_ACCURACY_COC*100)}acc\" # Example other detail\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Warning: Not enough averaged data for Figure 2 (Malicious Selection vs. Trigger Rate). Plot not generated.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-15T23:39:39.475255Z"
    }
   },
   "id": "72d50dad124323fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
