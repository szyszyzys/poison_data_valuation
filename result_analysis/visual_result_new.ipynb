{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preprocessing summary_avg.csv ---\n",
      "Column 'ATTACK_METHOD' before mapping. Unique values (as str): ['single', 'nan']\n",
      "Column 'ATTACK_METHOD' mapped. New unique values: ['Backdoor' 'No Attack']\n",
      "Column 'IS_SYBIL' before mapping. Unique values (as str): ['False', 'mimic']\n",
      "Column 'IS_SYBIL' mapped. New unique values: ['False' 'mimic']\n",
      "Processing float column: ADV_RATE with precision 1\n",
      "  Column 'ADV_RATE' rounded. NaNs after rounding: 0\n",
      "Processing float column: discovery_quality with precision 1\n",
      "  Column 'discovery_quality' rounded. NaNs after rounding: 0\n",
      "Processing float column: FINAL_MAIN_ACC with precision 4\n",
      "  Column 'FINAL_MAIN_ACC' rounded. NaNs after rounding: 0\n",
      "Processing float column: FINAL_ASR with precision 4\n",
      "  Column 'FINAL_ASR' rounded. NaNs after rounding: 0\n",
      "Processing float column: PAYMENT_GINI_COEFFICIENT with precision 3\n",
      "  Column 'PAYMENT_GINI_COEFFICIENT' rounded. NaNs after rounding: 0\n",
      "Processing float column: AVG_BENIGN_PAYMENT_GINI with precision 3\n",
      "  Column 'AVG_BENIGN_PAYMENT_GINI' rounded. NaNs after rounding: 0\n",
      "Processing float column: AVG_ADVERSARY_SELECTION_RATE with precision 3\n",
      "  Column 'AVG_ADVERSARY_SELECTION_RATE' rounded. NaNs after rounding: 0\n",
      "Processing float column: AVG_BENIGN_SELLER_SELECTION_RATE with precision 3\n",
      "  Column 'AVG_BENIGN_SELLER_SELECTION_RATE' rounded. NaNs after rounding: 0\n",
      "Processing float column: AVG_COST_PER_ROUND with precision 2\n",
      "  Column 'AVG_COST_PER_ROUND' rounded. NaNs after rounding: 0\n",
      "Processing float column: COST_OF_CONVERGENCE with precision 0\n",
      "  Column 'COST_OF_CONVERGENCE' rounded. NaNs after rounding: 33\n",
      "Processing float column: TOTAL_COST with precision 0\n",
      "  Column 'TOTAL_COST' rounded. NaNs after rounding: 0\n",
      "Processing float column: NO_ATTACK_DESIG_MAL_SEL_RATE_0.1 with precision 3\n",
      "  Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1' rounded. NaNs after rounding: 90\n",
      "Processing float column: NO_ATTACK_DESIG_MAL_SEL_RATE_0.2 with precision 3\n",
      "  Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2' rounded. NaNs after rounding: 90\n",
      "Processing float column: NO_ATTACK_DESIG_MAL_SEL_RATE_0.3 with precision 3\n",
      "  Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3' rounded. NaNs after rounding: 90\n",
      "Processing float column: NO_ATTACK_DESIG_MAL_SEL_RATE_0.4 with precision 3\n",
      "  Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4' rounded. NaNs after rounding: 90\n",
      "Warning: Column 'AVG_COST_PER_ROUND_BENIGN' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_COST_PER_ROUND_MALICIOUS' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Set ADV_RATE to 0.0 for 'No Attack' scenarios.\n",
      "Deriving cost composition (benign/malicious) from AVG_COST_PER_ROUND and AVG_ADVERSARY_SELECTION_RATE.\n",
      "Derived and processed cost composition columns.\n",
      "Processed summary_df_avg shape: (186, 48)\n",
      "\n",
      "First 5 rows of processed summary_df_avg (after potential derivation):\n"
     ]
    },
    {
     "data": {
      "text/plain": "   run AGGREGATION_METHOD DATA_SPLIT_MODE  discovery_quality buyer_data_mode  \\\n0    2             martfl       discovery                0.1          random   \n1    9             martfl       discovery                0.1          biased   \n2    3             martfl       discovery                1.0          random   \n3    9             martfl       discovery                1.0          biased   \n4    0             martfl       discovery               10.0          random   \n\n   N_CLIENTS ATTACK_METHOD  TRIGGER_RATE IS_SYBIL  ADV_RATE  ...  \\\n0       30.0      Backdoor           0.1    False       0.2  ...   \n1       30.0      Backdoor           0.1    False       0.2  ...   \n2       30.0      Backdoor           0.1    False       0.2  ...   \n3       30.0      Backdoor           0.1    False       0.2  ...   \n4       30.0      Backdoor           0.1    False       0.2  ...   \n\n   ROUNDS_TO_85ACC COST_TO_85ACC  ROUNDS_TO_90ACC COST_TO_90ACC  \\\n0        20.333333    395.666667              NaN           NaN   \n1        28.300000    528.900000              NaN           NaN   \n2        18.250000    320.750000              NaN           NaN   \n3        25.300000    448.800000              NaN           NaN   \n4              NaN           NaN              NaN           NaN   \n\n   NO_ATTACK_DESIG_MAL_SEL_RATE_0.1  NO_ATTACK_DESIG_MAL_SEL_RATE_0.2  \\\n0                               NaN                               NaN   \n1                               NaN                               NaN   \n2                               NaN                               NaN   \n3                               NaN                               NaN   \n4                               NaN                               NaN   \n\n   NO_ATTACK_DESIG_MAL_SEL_RATE_0.3  NO_ATTACK_DESIG_MAL_SEL_RATE_0.4  \\\n0                               NaN                               NaN   \n1                               NaN                               NaN   \n2                               NaN                               NaN   \n3                               NaN                               NaN   \n4                               NaN                               NaN   \n\n   AVG_COST_PER_ROUND_MALICIOUS  AVG_COST_PER_ROUND_BENIGN  \n0                          1.84                      13.40  \n1                          1.82                      14.17  \n2                          2.53                      12.29  \n3                          2.54                      13.35  \n4                          5.27                       6.88  \n\n[5 rows x 48 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run</th>\n      <th>AGGREGATION_METHOD</th>\n      <th>DATA_SPLIT_MODE</th>\n      <th>discovery_quality</th>\n      <th>buyer_data_mode</th>\n      <th>N_CLIENTS</th>\n      <th>ATTACK_METHOD</th>\n      <th>TRIGGER_RATE</th>\n      <th>IS_SYBIL</th>\n      <th>ADV_RATE</th>\n      <th>...</th>\n      <th>ROUNDS_TO_85ACC</th>\n      <th>COST_TO_85ACC</th>\n      <th>ROUNDS_TO_90ACC</th>\n      <th>COST_TO_90ACC</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.1</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.2</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.3</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.4</th>\n      <th>AVG_COST_PER_ROUND_MALICIOUS</th>\n      <th>AVG_COST_PER_ROUND_BENIGN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>martfl</td>\n      <td>discovery</td>\n      <td>0.1</td>\n      <td>random</td>\n      <td>30.0</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>20.333333</td>\n      <td>395.666667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.84</td>\n      <td>13.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>martfl</td>\n      <td>discovery</td>\n      <td>0.1</td>\n      <td>biased</td>\n      <td>30.0</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>28.300000</td>\n      <td>528.900000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.82</td>\n      <td>14.17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>martfl</td>\n      <td>discovery</td>\n      <td>1.0</td>\n      <td>random</td>\n      <td>30.0</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>18.250000</td>\n      <td>320.750000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.53</td>\n      <td>12.29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>martfl</td>\n      <td>discovery</td>\n      <td>1.0</td>\n      <td>biased</td>\n      <td>30.0</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>25.300000</td>\n      <td>448.800000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.54</td>\n      <td>13.35</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>martfl</td>\n      <td>discovery</td>\n      <td>10.0</td>\n      <td>random</td>\n      <td>30.0</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.27</td>\n      <td>6.88</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Info of processed summary_df_avg:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186 entries, 0 to 185\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   run                                     186 non-null    int64  \n",
      " 1   AGGREGATION_METHOD                      186 non-null    object \n",
      " 2   DATA_SPLIT_MODE                         186 non-null    object \n",
      " 3   discovery_quality                       186 non-null    float64\n",
      " 4   buyer_data_mode                         186 non-null    object \n",
      " 5   N_CLIENTS                               186 non-null    float64\n",
      " 6   ATTACK_METHOD                           186 non-null    object \n",
      " 7   TRIGGER_RATE                            186 non-null    float64\n",
      " 8   IS_SYBIL                                186 non-null    object \n",
      " 9   ADV_RATE                                186 non-null    float64\n",
      " 10  CHANGE_BASE                             186 non-null    bool   \n",
      " 11  TRIGGER_MODE                            186 non-null    object \n",
      " 12  benign_rounds                           186 non-null    float64\n",
      " 13  trigger_mode                            186 non-null    object \n",
      " 14  MAX_ASR                                 186 non-null    float64\n",
      " 15  FINAL_ASR                               186 non-null    float64\n",
      " 16  FINAL_MAIN_ACC                          186 non-null    float64\n",
      " 17  FINAL_CLEAN_ACC                         186 non-null    float64\n",
      " 18  FINAL_TRIGGERED_ACC                     186 non-null    float64\n",
      " 19  AVG_SELECTED_DISTRIBUTION_SIMILARITY    186 non-null    float64\n",
      " 20  AVG_UNSELECTED_DISTRIBUTION_SIMILARITY  186 non-null    float64\n",
      " 21  AVG_ADVERSARY_SELECTION_RATE            186 non-null    float64\n",
      " 22  AVG_BENIGN_SELECTION_RATE               186 non-null    float64\n",
      " 23  AVG_COST_PER_ROUND                      186 non-null    float64\n",
      " 24  COST_OF_CONVERGENCE                     153 non-null    float64\n",
      " 25  TARGET_ACC_FOR_COC                      186 non-null    float64\n",
      " 26  COC_TARGET_REACHED_ROUND                186 non-null    float64\n",
      " 27  PAYMENT_GINI_COEFFICIENT                186 non-null    float64\n",
      " 28  TOTAL_COST                              186 non-null    float64\n",
      " 29  TOTAL_ROUNDS                            186 non-null    float64\n",
      " 30  AVG_BENIGN_SELLER_SELECTION_RATE        186 non-null    float64\n",
      " 31  AVG_BENIGN_PAYMENT_GINI                 186 non-null    float64\n",
      " 32  ROUNDS_TO_70ACC                         180 non-null    float64\n",
      " 33  COST_TO_70ACC                           180 non-null    float64\n",
      " 34  ROUNDS_TO_75ACC                         177 non-null    float64\n",
      " 35  COST_TO_75ACC                           177 non-null    float64\n",
      " 36  ROUNDS_TO_80ACC                         153 non-null    float64\n",
      " 37  COST_TO_80ACC                           153 non-null    float64\n",
      " 38  ROUNDS_TO_85ACC                         129 non-null    float64\n",
      " 39  COST_TO_85ACC                           129 non-null    float64\n",
      " 40  ROUNDS_TO_90ACC                         0 non-null      float64\n",
      " 41  COST_TO_90ACC                           0 non-null      float64\n",
      " 42  NO_ATTACK_DESIG_MAL_SEL_RATE_0.1        96 non-null     float64\n",
      " 43  NO_ATTACK_DESIG_MAL_SEL_RATE_0.2        96 non-null     float64\n",
      " 44  NO_ATTACK_DESIG_MAL_SEL_RATE_0.3        96 non-null     float64\n",
      " 45  NO_ATTACK_DESIG_MAL_SEL_RATE_0.4        96 non-null     float64\n",
      " 46  AVG_COST_PER_ROUND_MALICIOUS            186 non-null    float64\n",
      " 47  AVG_COST_PER_ROUND_BENIGN               186 non-null    float64\n",
      "dtypes: bool(1), float64(39), int64(1), object(7)\n",
      "memory usage: 68.6+ KB\n",
      "\n",
      "all_rounds.csv loaded successfully.\n",
      "Column 'ATTACK_METHOD' before mapping. Unique values (as str): ['single', 'nan']\n",
      "Column 'ATTACK_METHOD' mapped. New unique values: ['Backdoor' 'No Attack']\n",
      "Column 'IS_SYBIL' before mapping. Unique values (as str): ['False', 'mimic']\n",
      "Column 'IS_SYBIL' mapped. New unique values: ['False' 'mimic']\n",
      "Processing float column: ADV_RATE with precision 1\n",
      "  Column 'ADV_RATE' rounded. NaNs after rounding: 0\n",
      "Processing float column: discovery_quality with precision 1\n",
      "  Column 'discovery_quality' rounded. NaNs after rounding: 0\n",
      "Warning: Column 'FINAL_MAIN_ACC' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'FINAL_ASR' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'PAYMENT_GINI_COEFFICIENT' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_BENIGN_PAYMENT_GINI' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_ADVERSARY_SELECTION_RATE' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_BENIGN_SELLER_SELECTION_RATE' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_COST_PER_ROUND' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'COST_OF_CONVERGENCE' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'TOTAL_COST' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_COST_PER_ROUND_BENIGN' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Warning: Column 'AVG_COST_PER_ROUND_MALICIOUS' (listed in FLOAT_PRECISIONS) not found in DataFrame.\n",
      "Set ADV_RATE to 0.0 for 'No Attack' scenarios.\n",
      "Processed all_rounds_df shape: (75795, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zeyu song\\AppData\\Local\\Temp\\ipykernel_285484\\3136579133.py:194: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_rounds_df_raw = pd.read_csv(f\"{OUTPUT_DIR}/all_rounds.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "   run  round ATTACK_METHOD  TRIGGER_RATE IS_SYBIL  ADV_RATE  CHANGE_BASE  \\\n0    0      0      Backdoor           0.1    False       0.2         True   \n1    0      1      Backdoor           0.1    False       0.2         True   \n2    0      2      Backdoor           0.1    False       0.2         True   \n3    0      3      Backdoor           0.1    False       0.2         True   \n4    0      4      Backdoor           0.1    False       0.2         True   \n\n  TRIGGER_MODE  benign_rounds trigger_mode  ...  \\\n0       static              0       static  ...   \n1       static              0       static  ...   \n2       static              0       static  ...   \n3       static              0       static  ...   \n4       static              0       static  ...   \n\n  NO_ATTACK_DESIG_MAL_SEL_RATE_0.2_ROUND  \\\n0                                    NaN   \n1                                    NaN   \n2                                    NaN   \n3                                    NaN   \n4                                    NaN   \n\n  NO_ATTACK_DESIG_MAL_SEL_RATE_0.3_ROUND  \\\n0                                    NaN   \n1                                    NaN   \n2                                    NaN   \n3                                    NaN   \n4                                    NaN   \n\n   NO_ATTACK_DESIG_MAL_SEL_RATE_0.4_ROUND main_acc  main_loss  clean_acc  \\\n0                                     NaN   0.5518   1.175421     0.5518   \n1                                     NaN   0.6757   0.824391     0.6757   \n2                                     NaN   0.7089   0.709304     0.7089   \n3                                     NaN   0.7316   0.654981     0.7316   \n4                                     NaN   0.7550   0.616033     0.7550   \n\n  triggered_acc     asr  avg_selected_data_distribution_similarity  \\\n0        0.5701  0.1184                                   0.998623   \n1        0.6704  0.1236                                   0.998641   \n2        0.6917  0.1114                                   0.998603   \n3        0.7118  0.0949                                   0.998700   \n4        0.7322  0.1147                                   0.998637   \n\n   avg_unselected_data_distribution_similarity  \n0                                     0.998623  \n1                                     0.998623  \n2                                     0.998623  \n3                                     0.998623  \n4                                     0.998623  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run</th>\n      <th>round</th>\n      <th>ATTACK_METHOD</th>\n      <th>TRIGGER_RATE</th>\n      <th>IS_SYBIL</th>\n      <th>ADV_RATE</th>\n      <th>CHANGE_BASE</th>\n      <th>TRIGGER_MODE</th>\n      <th>benign_rounds</th>\n      <th>trigger_mode</th>\n      <th>...</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.2_ROUND</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.3_ROUND</th>\n      <th>NO_ATTACK_DESIG_MAL_SEL_RATE_0.4_ROUND</th>\n      <th>main_acc</th>\n      <th>main_loss</th>\n      <th>clean_acc</th>\n      <th>triggered_acc</th>\n      <th>asr</th>\n      <th>avg_selected_data_distribution_similarity</th>\n      <th>avg_unselected_data_distribution_similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.5518</td>\n      <td>1.175421</td>\n      <td>0.5518</td>\n      <td>0.5701</td>\n      <td>0.1184</td>\n      <td>0.998623</td>\n      <td>0.998623</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.6757</td>\n      <td>0.824391</td>\n      <td>0.6757</td>\n      <td>0.6704</td>\n      <td>0.1236</td>\n      <td>0.998641</td>\n      <td>0.998623</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.7089</td>\n      <td>0.709304</td>\n      <td>0.7089</td>\n      <td>0.6917</td>\n      <td>0.1114</td>\n      <td>0.998603</td>\n      <td>0.998623</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.7316</td>\n      <td>0.654981</td>\n      <td>0.7316</td>\n      <td>0.7118</td>\n      <td>0.0949</td>\n      <td>0.998700</td>\n      <td>0.998623</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>Backdoor</td>\n      <td>0.1</td>\n      <td>False</td>\n      <td>0.2</td>\n      <td>True</td>\n      <td>static</td>\n      <td>0</td>\n      <td>static</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.7550</td>\n      <td>0.616033</td>\n      <td>0.7550</td>\n      <td>0.7322</td>\n      <td>0.1147</td>\n      <td>0.998637</td>\n      <td>0.998623</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processed Summary Data Verification (Post-Preprocessing & Derivation) ---\n",
      "Unique values in 'AGGREGATION_METHOD': ['martfl']\n",
      "  NaNs in 'AGGREGATION_METHOD': 0\n",
      "Unique values in 'ATTACK_METHOD': ['Backdoor', 'No Attack']\n",
      "  NaNs in 'ATTACK_METHOD': 0\n",
      "Unique values in 'IS_SYBIL': ['False', 'mimic']\n",
      "  NaNs in 'IS_SYBIL': 0\n",
      "Unique values in 'ADV_RATE': [np.float64(0.0), np.float64(0.2), np.float64(0.3), np.float64(0.4)]\n",
      "  NaNs in 'ADV_RATE': 0\n",
      "VERIFICATION WARNING: Column 'BENIGN_PAYMENT_GINI_COEFFICIENT' NOT FOUND in processed summary_df_avg.\n",
      "Unique values in 'AVG_BENIGN_SELLER_SELECTION_RATE': [np.float64(0.22), np.float64(0.225), np.float64(0.246), np.float64(0.262), np.float64(0.292), np.float64(0.295), np.float64(0.298), np.float64(0.304), np.float64(0.328), np.float64(0.329), np.float64(0.33), np.float64(0.34), np.float64(0.341), np.float64(0.347), np.float64(0.355), np.float64(0.357), np.float64(0.362), np.float64(0.365), np.float64(0.374), np.float64(0.387), np.float64(0.391), np.float64(0.398), np.float64(0.403), np.float64(0.409), np.float64(0.41), np.float64(0.414), np.float64(0.424), np.float64(0.429), np.float64(0.434), np.float64(0.449), np.float64(0.452), np.float64(0.456), np.float64(0.462), np.float64(0.47), np.float64(0.478), np.float64(0.482), np.float64(0.487), np.float64(0.488), np.float64(0.489), np.float64(0.493), np.float64(0.495), np.float64(0.499), np.float64(0.5), np.float64(0.502), np.float64(0.503), np.float64(0.504), np.float64(0.506), np.float64(0.509), np.float64(0.511), np.float64(0.515), np.float64(0.52), np.float64(0.525), np.float64(0.531), np.float64(0.534), np.float64(0.545), np.float64(0.549), np.float64(0.55), np.float64(0.551), np.float64(0.552), np.float64(0.553), np.float64(0.554), np.float64(0.557), np.float64(0.56), np.float64(0.562), np.float64(0.564), np.float64(0.565), np.float64(0.567), np.float64(0.568), np.float64(0.569), np.float64(0.577), np.float64(0.578), np.float64(0.579), np.float64(0.583), np.float64(0.584), np.float64(0.598), np.float64(0.603), np.float64(0.605), np.float64(0.616), np.float64(0.623), np.float64(0.626), np.float64(0.634), np.float64(0.638), np.float64(0.645), np.float64(0.657), np.float64(0.668), np.float64(0.671), np.float64(0.675), np.float64(0.678), np.float64(0.68), np.float64(0.683), np.float64(0.684), np.float64(0.69), np.float64(0.693), np.float64(0.697), np.float64(0.712), np.float64(0.715), np.float64(0.73), np.float64(0.733), np.float64(0.742)]\n",
      "  NaNs in 'AVG_BENIGN_SELLER_SELECTION_RATE': 0\n",
      "Unique values in 'AVG_ADVERSARY_SELECTION_RATE': [np.float64(0.0), np.float64(0.007), np.float64(0.038), np.float64(0.039), np.float64(0.04), np.float64(0.041), np.float64(0.044), np.float64(0.051), np.float64(0.06), np.float64(0.064), np.float64(0.065), np.float64(0.069), np.float64(0.071), np.float64(0.073), np.float64(0.077), np.float64(0.084), np.float64(0.09), np.float64(0.094), np.float64(0.097), np.float64(0.1), np.float64(0.101), np.float64(0.103), np.float64(0.104), np.float64(0.107), np.float64(0.11), np.float64(0.114), np.float64(0.115), np.float64(0.121), np.float64(0.133), np.float64(0.144), np.float64(0.147), np.float64(0.152), np.float64(0.154), np.float64(0.16), np.float64(0.162), np.float64(0.163), np.float64(0.171), np.float64(0.173), np.float64(0.174), np.float64(0.176), np.float64(0.179), np.float64(0.191), np.float64(0.193), np.float64(0.194), np.float64(0.197), np.float64(0.202), np.float64(0.204), np.float64(0.206), np.float64(0.21), np.float64(0.211), np.float64(0.212), np.float64(0.215), np.float64(0.221), np.float64(0.222), np.float64(0.224), np.float64(0.234), np.float64(0.239), np.float64(0.246), np.float64(0.249), np.float64(0.26), np.float64(0.274), np.float64(0.276), np.float64(0.279), np.float64(0.284), np.float64(0.288), np.float64(0.29), np.float64(0.293), np.float64(0.295), np.float64(0.297), np.float64(0.3), np.float64(0.303), np.float64(0.305), np.float64(0.308), np.float64(0.327), np.float64(0.335), np.float64(0.356), np.float64(0.358), np.float64(0.362), np.float64(0.363), np.float64(0.374), np.float64(0.382), np.float64(0.384), np.float64(0.394), np.float64(0.397), np.float64(0.399), np.float64(0.401), np.float64(0.402), np.float64(0.403), np.float64(0.404), np.float64(0.418), np.float64(0.421), np.float64(0.425), np.float64(0.43), np.float64(0.434), np.float64(0.438), np.float64(0.452), np.float64(0.456), np.float64(0.477), np.float64(0.49), np.float64(0.51), np.float64(0.521), np.float64(0.56), np.float64(0.568), np.float64(0.717)]\n",
      "  NaNs in 'AVG_ADVERSARY_SELECTION_RATE': 0\n",
      "Unique values in 'AVG_COST_PER_ROUND_BENIGN': [np.float64(2.91), np.float64(3.68), np.float64(4.45), np.float64(4.97), np.float64(5.12), np.float64(5.34), np.float64(5.41), np.float64(5.69), np.float64(5.76), np.float64(5.93), np.float64(6.26), np.float64(6.27), np.float64(6.4), np.float64(6.5), np.float64(6.68), np.float64(6.72), np.float64(6.82), np.float64(6.88), np.float64(7.07), np.float64(7.08), np.float64(7.37), np.float64(7.63), np.float64(7.68), np.float64(7.8), np.float64(7.85), np.float64(7.89), np.float64(7.99), np.float64(8.1), np.float64(8.38), np.float64(8.69), np.float64(8.87), np.float64(9.02), np.float64(9.12), np.float64(9.25), np.float64(9.4), np.float64(9.73), np.float64(9.75), np.float64(9.9), np.float64(10.0), np.float64(10.21), np.float64(10.22), np.float64(10.28), np.float64(10.29), np.float64(10.54), np.float64(10.65), np.float64(10.66), np.float64(10.7), np.float64(10.93), np.float64(11.17), np.float64(11.18), np.float64(11.41), np.float64(11.52), np.float64(11.61), np.float64(11.76), np.float64(11.88), np.float64(12.02), np.float64(12.09), np.float64(12.18), np.float64(12.19), np.float64(12.29), np.float64(12.34), np.float64(12.48), np.float64(12.57), np.float64(12.59), np.float64(12.65), np.float64(12.88), np.float64(13.21), np.float64(13.35), np.float64(13.4), np.float64(13.44), np.float64(13.45), np.float64(13.57), np.float64(13.64), np.float64(14.17), np.float64(14.27), np.float64(14.4), np.float64(14.43), np.float64(14.49), np.float64(14.76), np.float64(15.12), np.float64(15.35), np.float64(15.8), np.float64(16.15), np.float64(16.18), np.float64(16.26), np.float64(16.29), np.float64(16.51), np.float64(16.59), np.float64(16.85), np.float64(17.0), np.float64(17.04), np.float64(17.16), np.float64(17.25)]\n",
      "  NaNs in 'AVG_COST_PER_ROUND_BENIGN': 0\n",
      "Unique values in 'AVG_COST_PER_ROUND_MALICIOUS': [np.float64(0.0), np.float64(0.05), np.float64(0.64), np.float64(0.66), np.float64(0.69), np.float64(0.7), np.float64(0.73), np.float64(0.78), np.float64(0.83), np.float64(0.92), np.float64(0.99), np.float64(1.01), np.float64(1.06), np.float64(1.11), np.float64(1.13), np.float64(1.2), np.float64(1.22), np.float64(1.23), np.float64(1.33), np.float64(1.37), np.float64(1.45), np.float64(1.47), np.float64(1.48), np.float64(1.54), np.float64(1.58), np.float64(1.66), np.float64(1.71), np.float64(1.78), np.float64(1.82), np.float64(1.84), np.float64(1.85), np.float64(1.9), np.float64(1.94), np.float64(2.0), np.float64(2.1), np.float64(2.18), np.float64(2.34), np.float64(2.53), np.float64(2.54), np.float64(2.6), np.float64(2.64), np.float64(2.99), np.float64(3.04), np.float64(3.05), np.float64(3.19), np.float64(3.2), np.float64(3.22), np.float64(3.23), np.float64(3.24), np.float64(3.26), np.float64(3.36), np.float64(3.46), np.float64(3.64), np.float64(3.75), np.float64(3.95), np.float64(4.05), np.float64(4.12), np.float64(4.14), np.float64(4.16), np.float64(4.18), np.float64(4.29), np.float64(4.3), np.float64(4.78), np.float64(4.83), np.float64(4.84), np.float64(4.9), np.float64(4.98), np.float64(5.15), np.float64(5.25), np.float64(5.27), np.float64(5.36), np.float64(5.41), np.float64(5.44), np.float64(5.54), np.float64(5.63), np.float64(5.68), np.float64(5.71), np.float64(5.84), np.float64(6.32), np.float64(6.44), np.float64(7.07), np.float64(7.38), np.float64(8.23)]\n",
      "  NaNs in 'AVG_COST_PER_ROUND_MALICIOUS': 0\n",
      "Unique values in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1': [np.float64(0.09), np.float64(0.097), np.float64(0.1), np.float64(0.104), np.float64(0.107), np.float64(0.114), np.float64(0.115)]\n",
      "  NaNs in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1': 90\n",
      "Unique values in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2': [np.float64(0.162), np.float64(0.173), np.float64(0.193), np.float64(0.197), np.float64(0.206), np.float64(0.211), np.float64(0.221)]\n",
      "  NaNs in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2': 90\n",
      "Unique values in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3': [np.float64(0.206), np.float64(0.224), np.float64(0.293), np.float64(0.295), np.float64(0.303), np.float64(0.305), np.float64(0.327)]\n",
      "  NaNs in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3': 90\n",
      "Unique values in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4': [np.float64(0.249), np.float64(0.29), np.float64(0.394), np.float64(0.397), np.float64(0.401), np.float64(0.403), np.float64(0.438)]\n",
      "  NaNs in 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4': 90\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Configuration ---\n",
    "OUTPUT_DIR = \"../result_new\"  # Or your actual path\n",
    "\n",
    "\n",
    "# TARGET_ACCURACY_COC = 0.8 # Not used in Gini/Selection plots, but good to have if other plots use it\n",
    "\n",
    "# --- Helper Function for Preprocessing ---\n",
    "def preprocess_experiment_data(df, float_cols_precision=None, categorical_maps=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Preprocesses a DataFrame by converting columns, rounding floats, and mapping categoricals.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        if verbose: print(\"Input DataFrame is empty. Skipping preprocessing.\")\n",
    "        return df.copy()  # Return a copy even if empty\n",
    "\n",
    "    processed_df = df.copy()\n",
    "\n",
    "    # 1. Map categorical values\n",
    "    if categorical_maps:\n",
    "        for col, value_map in categorical_maps.items():\n",
    "            if col in processed_df.columns:\n",
    "                original_unique_vals_str = list(map(str, processed_df[col].unique()))  # For robust printing\n",
    "                if verbose: print(f\"Column '{col}' before mapping. Unique values (as str): {original_unique_vals_str}\")\n",
    "                # Handle NaN mapping first if present in keys\n",
    "                if np.nan in value_map:\n",
    "                    processed_df[col] = processed_df[col].fillna(value_map[np.nan])\n",
    "                    value_map_no_nan = {k: v for k, v in value_map.items() if not pd.isna(k)}\n",
    "                    if value_map_no_nan:\n",
    "                        processed_df[col] = processed_df[col].replace(value_map_no_nan)\n",
    "                else:  # No specific NaN mapping, just replace\n",
    "                    processed_df[col] = processed_df[col].replace(value_map)\n",
    "                if verbose: print(f\"Column '{col}' mapped. New unique values: {processed_df[col].unique()}\")\n",
    "            elif verbose:\n",
    "                print(f\"Warning: Column '{col}' for categorical mapping not found in DataFrame.\")\n",
    "\n",
    "    # 2. Convert to numeric and round specified float columns\n",
    "    if float_cols_precision:\n",
    "        for col, precision in float_cols_precision.items():\n",
    "            if col in processed_df.columns:  # Check if column exists BEFORE trying to process\n",
    "                if verbose: print(f\"Processing float column: {col} with precision {precision}\")\n",
    "                original_nan_count = processed_df[col].isna().sum()\n",
    "                numeric_col = pd.to_numeric(processed_df[col], errors='coerce')\n",
    "                coerced_nan_count = numeric_col.isna().sum()\n",
    "                if verbose and coerced_nan_count > original_nan_count:\n",
    "                    print(\n",
    "                        f\"  Warning: Column '{col}' had {coerced_nan_count - original_nan_count} new NaNs after to_numeric (were {original_nan_count}).\")\n",
    "\n",
    "                processed_df[col] = numeric_col.round(precision)\n",
    "                if verbose: print(f\"  Column '{col}' rounded. NaNs after rounding: {processed_df[col].isna().sum()}\")\n",
    "            elif verbose:\n",
    "                print(f\"Warning: Column '{col}' (listed in FLOAT_PRECISIONS) not found in DataFrame.\")\n",
    "\n",
    "    # 3. Specific logic: Set ADV_RATE to 0.0 for 'No Attack' scenarios\n",
    "    if 'ATTACK_METHOD' in processed_df.columns and 'ADV_RATE' in processed_df.columns:\n",
    "        if 'No Attack' in processed_df['ATTACK_METHOD'].unique():  # Check if 'No Attack' exists after mapping\n",
    "            # Ensure ADV_RATE is numeric before this assignment\n",
    "            if not pd.api.types.is_numeric_dtype(processed_df['ADV_RATE']):\n",
    "                processed_df['ADV_RATE'] = pd.to_numeric(processed_df['ADV_RATE'], errors='coerce')\n",
    "\n",
    "            processed_df.loc[processed_df['ATTACK_METHOD'] == 'No Attack', 'ADV_RATE'] = 0.0\n",
    "            if verbose: print(\"Set ADV_RATE to 0.0 for 'No Attack' scenarios.\")\n",
    "        elif verbose:\n",
    "            print(\"'No Attack' not found in ATTACK_METHOD after mapping; ADV_RATE for 'No Attack' not set to 0.\")\n",
    "\n",
    "    return processed_df\n",
    "\n",
    "\n",
    "# --- Define Preprocessing Parameters ---\n",
    "FLOAT_PRECISIONS = {\n",
    "    'ADV_RATE': 1,\n",
    "    'discovery_quality': 1,\n",
    "    'FINAL_MAIN_ACC': 4,\n",
    "    'FINAL_ASR': 4,\n",
    "    'PAYMENT_GINI_COEFFICIENT': 3,\n",
    "    'AVG_BENIGN_PAYMENT_GINI': 3,  # Assuming this is AVG_BENIGN_PAYMENT_GINI from your CSV\n",
    "    'AVG_ADVERSARY_SELECTION_RATE': 3,  # This is the proportion of *selected* clients that are adversaries\n",
    "    'AVG_BENIGN_SELLER_SELECTION_RATE': 3,  # This might be rate among available benign, or proportion of selected\n",
    "    'AVG_COST_PER_ROUND': 2,  # Overall average cost per round\n",
    "    'COST_OF_CONVERGENCE': 0,  # Assuming integer rounds/costs\n",
    "    'TOTAL_COST': 0,  # Assuming integer rounds/costs\n",
    "    'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1': 3,\n",
    "    'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2': 3,\n",
    "    'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3': 3,\n",
    "    'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4': 3,\n",
    "    # Add derived columns here if you want them rounded by the helper,\n",
    "    # otherwise, round them after derivation.\n",
    "    'AVG_COST_PER_ROUND_BENIGN': 2,\n",
    "    'AVG_COST_PER_ROUND_MALICIOUS': 2\n",
    "}\n",
    "\n",
    "CATEGORICAL_MAPPINGS = {\n",
    "    'ATTACK_METHOD': {\n",
    "        'single': 'Backdoor',\n",
    "        np.nan: 'No Attack',  # Handles empty cells in CSV read as pandas NaN\n",
    "        'None': 'No Attack',  # Handles cells with string 'None'\n",
    "        'no_attack': 'No Attack'  # Handles cells with string 'no_attack'\n",
    "    },\n",
    "    'IS_SYBIL': {\n",
    "        # Assuming your CSV has string 'False' and string 'mimic'\n",
    "        # If it's boolean True/False, you'd map them:\n",
    "        # True: 'mimic', \n",
    "        # False: 'False' # Keep 'False' as string 'False' for consistency\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Load and Preprocess Data ---\n",
    "summary_df_avg = pd.DataFrame()  # Initialize as empty\n",
    "\n",
    "try:\n",
    "    summary_df_avg_raw = pd.read_csv(f\"{OUTPUT_DIR}/summary_avg.csv\")\n",
    "    print(\"--- Preprocessing summary_avg.csv ---\")\n",
    "    summary_df_avg = preprocess_experiment_data(\n",
    "        summary_df_avg_raw,\n",
    "        float_cols_precision=FLOAT_PRECISIONS,\n",
    "        categorical_maps=CATEGORICAL_MAPPINGS,\n",
    "        verbose=True  # Enable verbose output for debugging\n",
    "    )\n",
    "\n",
    "    # --- DERIVE COST COMPOSITION COLUMNS (Benign vs. Malicious Cost per Round) ---\n",
    "    cost_benign_col = 'AVG_COST_PER_ROUND_BENIGN'\n",
    "    cost_mal_col = 'AVG_COST_PER_ROUND_MALICIOUS'\n",
    "\n",
    "    # Check if derivation is sensible (i.e., source columns exist)\n",
    "    if 'AVG_COST_PER_ROUND' in summary_df_avg.columns and \\\n",
    "            'AVG_ADVERSARY_SELECTION_RATE' in summary_df_avg.columns:\n",
    "\n",
    "        print(\"Deriving cost composition (benign/malicious) from AVG_COST_PER_ROUND and AVG_ADVERSARY_SELECTION_RATE.\")\n",
    "\n",
    "        # Ensure source columns are numeric (they should be after preprocess_experiment_data if listed in FLOAT_PRECISIONS)\n",
    "        # If not listed, convert them here explicitly before use.\n",
    "        for col_to_check in ['AVG_COST_PER_ROUND', 'AVG_ADVERSARY_SELECTION_RATE']:\n",
    "            if col_to_check not in FLOAT_PRECISIONS:  # If not already processed by helper\n",
    "                if col_to_check in summary_df_avg.columns:\n",
    "                    summary_df_avg[col_to_check] = pd.to_numeric(summary_df_avg[col_to_check], errors='coerce')\n",
    "                    print(f\"  Ensured column '{col_to_check}' is numeric for derivation.\")\n",
    "                else:\n",
    "                    print(f\"  Warning: Source column '{col_to_check}' for derivation not found.\")\n",
    "                    # Create empty columns to prevent later key errors if derivation fails\n",
    "                    summary_df_avg[cost_mal_col] = np.nan\n",
    "                    summary_df_avg[cost_benign_col] = np.nan\n",
    "\n",
    "        # For \"No Attack\" runs, AVG_ADVERSARY_SELECTION_RATE should be 0 for this calculation.\n",
    "        # The preprocess_experiment_data sets ADV_RATE to 0.\n",
    "        # Your data generation script should ensure AVG_ADVERSARY_SELECTION_RATE is 0 for No Attack runs.\n",
    "        # If it might be NaN for No Attack runs, fill it with 0 before calculation.\n",
    "        adv_sel_rate_for_calc = summary_df_avg['AVG_ADVERSARY_SELECTION_RATE'].copy()\n",
    "        # If ATTACK_METHOD is 'No Attack', this rate is definitionally 0.\n",
    "        # Also, if it's NaN for an attack run (shouldn't happen if data is good), treat as 0 for safety here.\n",
    "        adv_sel_rate_for_calc[summary_df_avg['ATTACK_METHOD'] == 'No Attack'] = 0.0\n",
    "        adv_sel_rate_for_calc.fillna(0.0, inplace=True)  # Fill any other NaNs with 0 to avoid NaN propagation\n",
    "\n",
    "        # Calculate derived costs\n",
    "        summary_df_avg[cost_mal_col] = summary_df_avg['AVG_COST_PER_ROUND'] * adv_sel_rate_for_calc\n",
    "        summary_df_avg[cost_benign_col] = summary_df_avg['AVG_COST_PER_ROUND'] * (1 - adv_sel_rate_for_calc)\n",
    "\n",
    "        # Round the newly derived columns if they weren't already in FLOAT_PRECISIONS\n",
    "        # or if derivation might have introduced new float precision issues.\n",
    "        if cost_mal_col in summary_df_avg.columns:\n",
    "            summary_df_avg[cost_mal_col] = summary_df_avg[cost_mal_col].round(FLOAT_PRECISIONS.get(cost_mal_col, 2))\n",
    "        if cost_benign_col in summary_df_avg.columns:\n",
    "            summary_df_avg[cost_benign_col] = summary_df_avg[cost_benign_col].round(\n",
    "                FLOAT_PRECISIONS.get(cost_benign_col, 2))\n",
    "        print(\"Derived and processed cost composition columns.\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            \"Warning: Cannot derive cost composition. Missing 'AVG_COST_PER_ROUND' or 'AVG_ADVERSARY_SELECTION_RATE'.\")\n",
    "        # Ensure columns exist as NaN if derivation fails, for consistency in later plotting cells\n",
    "        if cost_mal_col not in summary_df_avg.columns: summary_df_avg[cost_mal_col] = np.nan\n",
    "        if cost_benign_col not in summary_df_avg.columns: summary_df_avg[cost_benign_col] = np.nan\n",
    "\n",
    "    print(f\"Processed summary_df_avg shape: {summary_df_avg.shape}\")\n",
    "    if not summary_df_avg.empty:\n",
    "        print(\"\\nFirst 5 rows of processed summary_df_avg (after potential derivation):\")\n",
    "        display(summary_df_avg.head())\n",
    "        print(\"\\nInfo of processed summary_df_avg:\")\n",
    "        summary_df_avg.info()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"CRITICAL ERROR: summary_avg.csv not found in {OUTPUT_DIR}. Cannot proceed with plotting.\")\n",
    "    summary_df_avg = pd.DataFrame()  # Ensure it's an empty DF if load fails\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: An error occurred during summary_df_avg loading or preprocessing: {e}\")\n",
    "    summary_df_avg = pd.DataFrame()\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"muted\")\n",
    "try:\n",
    "    all_rounds_df_raw = pd.read_csv(f\"{OUTPUT_DIR}/all_rounds.csv\")\n",
    "    print(\"\\nall_rounds.csv loaded successfully.\")\n",
    "    all_rounds_df = preprocess_experiment_data(\n",
    "        all_rounds_df_raw,\n",
    "        float_cols_precision=FLOAT_PRECISIONS,\n",
    "        categorical_maps=CATEGORICAL_MAPPINGS\n",
    "    )\n",
    "    print(f\"Processed all_rounds_df shape: {all_rounds_df.shape}\")\n",
    "    if not all_rounds_df.empty: display(all_rounds_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: all_rounds.csv not found in {OUTPUT_DIR}. Please check the path.\")\n",
    "    all_rounds_df = pd.DataFrame()\n",
    "\n",
    "# Set a consistent style for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"muted\")\n",
    "\n",
    "# --- Verification ---\n",
    "if not summary_df_avg.empty:\n",
    "    print(\"\\n--- Processed Summary Data Verification (Post-Preprocessing & Derivation) ---\")\n",
    "    check_cols = [\n",
    "        'AGGREGATION_METHOD', 'ATTACK_METHOD', 'IS_SYBIL', 'ADV_RATE',\n",
    "        'BENIGN_PAYMENT_GINI_COEFFICIENT',  # This is your AVG_BENIGN_PAYMENT_GINI\n",
    "        'AVG_BENIGN_SELLER_SELECTION_RATE',\n",
    "        'AVG_ADVERSARY_SELECTION_RATE',\n",
    "        'AVG_COST_PER_ROUND_BENIGN',  # New derived/processed\n",
    "        'AVG_COST_PER_ROUND_MALICIOUS',  # New derived/processed\n",
    "        'NO_ATTACK_DESIG_MAL_SEL_RATE_0.1', 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.2',\n",
    "        'NO_ATTACK_DESIG_MAL_SEL_RATE_0.3', 'NO_ATTACK_DESIG_MAL_SEL_RATE_0.4'\n",
    "    ]\n",
    "    for col in check_cols:\n",
    "        if col in summary_df_avg.columns:\n",
    "            unique_vals = summary_df_avg[col].unique()\n",
    "            try:\n",
    "                if pd.api.types.is_numeric_dtype(summary_df_avg[col].dtype) and not summary_df_avg[col].empty:\n",
    "                    valid_numeric_vals = summary_df_avg[col].dropna().unique()\n",
    "                    unique_vals = sorted(list(valid_numeric_vals)) if len(valid_numeric_vals) > 0 else []\n",
    "                elif not summary_df_avg[col].empty:\n",
    "                    # Attempt to sort strings, handle mixed types by converting all to string for sorting\n",
    "                    unique_vals = sorted(list(map(str, unique_vals)))\n",
    "            except TypeError:\n",
    "                print(f\"    (Could not sort unique values for {col} due to mixed types or NaNs)\")\n",
    "                pass\n",
    "            print(f\"Unique values in '{col}': {unique_vals}\")\n",
    "            print(f\"  NaNs in '{col}': {summary_df_avg[col].isna().sum()}\")\n",
    "        else:\n",
    "            print(f\"VERIFICATION WARNING: Column '{col}' NOT FOUND in processed summary_df_avg.\")\n",
    "else:\n",
    "    print(\"\\nsummary_df_avg is empty. Verification skipped. Subsequent plots will likely fail.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T04:20:14.348953100Z",
     "start_time": "2025-05-13T04:20:14.179193800Z"
    }
   },
   "id": "b92b3f86e59d2310"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-13T04:20:45.369999600Z",
     "start_time": "2025-05-13T04:20:43.951324300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'summary_df_avg' DataFrame is available.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'DATASET'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Users\\Public\\minikuda\\envs\\poison_data_valuation_new\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3804\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3805\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._engine.get_loc(casted_key)\n\u001B[32m   3806\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'DATASET'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 68\u001B[39m\n\u001B[32m     65\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[33msummary_df_avg\u001B[39m\u001B[33m'\u001B[39m\u001B[33m DataFrame is available.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     67\u001B[39m \u001B[38;5;66;03m# Dynamically get unique datasets and aggregation methods if not hardcoded\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m DATASETS_TO_ANALYZE = \u001B[38;5;28msorted\u001B[39m(summary_df_avg[\u001B[33m'\u001B[39m\u001B[33mDATASET\u001B[39m\u001B[33m'\u001B[39m].unique())\n\u001B[32m     69\u001B[39m AGGREGATION_METHODS_TO_ANALYZE = \u001B[38;5;28msorted\u001B[39m(summary_df_avg[\u001B[33m'\u001B[39m\u001B[33mAGGREGATION_METHOD\u001B[39m\u001B[33m'\u001B[39m].unique())\n\u001B[32m     70\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAnalyzing Datasets: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mDATASETS_TO_ANALYZE\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Users\\Public\\minikuda\\envs\\poison_data_valuation_new\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4100\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4102\u001B[39m indexer = \u001B[38;5;28mself\u001B[39m.columns.get_loc(key)\n\u001B[32m   4103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4104\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Users\\Public\\minikuda\\envs\\poison_data_valuation_new\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3808\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3809\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3810\u001B[39m     ):\n\u001B[32m   3811\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3814\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3815\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3816\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3817\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'DATASET'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Ensure these match your DataFrame's unique values\n",
    "# DATASETS_TO_ANALYZE = sorted(summary_df_avg['DATASET'].unique()) # Detect dynamically\n",
    "# AGGREGATION_METHODS_TO_ANALYZE = sorted(summary_df_avg['AGGREGATION_METHOD'].unique()) # Detect dynamically\n",
    "YOUR_PRIMARY_BACKDOOR_ATTACK_NAME = 'Backdoor' # The main attack to focus on\n",
    "\n",
    "# Fixed parameters for some overview plots (ADJUST AS NEEDED)\n",
    "FIXED_ADV_RATE_FOR_OVERVIEW = 0.3 # A challenging adversary rate for bar chart comparisons\n",
    "FIXED_DISCOVERY_QUALITY_OVERVIEW = 1.0\n",
    "FIXED_BUYER_MODE_OVERVIEW = 'random'\n",
    "FIXED_TRIGGER_RATE_OVERVIEW = 0.1 # Or your relevant fixed trigger rate\n",
    "\n",
    "# For line plots (ADV_RATE on X-axis)\n",
    "ADV_RATES_X_AXIS = sorted([0.1, 0.2, 0.3, 0.4]) # Or detect from data if more varied\n",
    "\n",
    "# --- Output Paths ---\n",
    "BASE_SAVE_DIR_FULL_ANALYSIS = \"./results/paper_figures/full_analysis/\"\n",
    "os.makedirs(BASE_SAVE_DIR_FULL_ANALYSIS, exist_ok=True)\n",
    "\n",
    "# --- Dummy Data for Testing (if summary_df_avg is not available) ---\n",
    "if 'summary_df_avg' not in locals() or summary_df_avg.empty:\n",
    "    print(\"CRITICAL ERROR: 'summary_df_avg' DataFrame not found. Using dummy data.\")\n",
    "    dummy_data_list_full = []\n",
    "    datasets_dummy = ['FMNIST', 'CIFAR10']\n",
    "    aggregators_dummy = ['MartFL', 'FedAvg', 'Krum']\n",
    "    adv_rates_dummy_line = ADV_RATES_X_AXIS\n",
    "    trigger_rates_dummy_fixed = [FIXED_TRIGGER_RATE_OVERVIEW]\n",
    "\n",
    "    for ds in datasets_dummy:\n",
    "        for agg in aggregators_dummy:\n",
    "            for adv_rate_line in adv_rates_dummy_line: # For line plots\n",
    "                 for run_seed in range(3): # 3 runs per setting\n",
    "                    acc_base = 0.9 if agg == 'MartFL' else (0.85 if agg == 'FedAvg' else 0.8)\n",
    "                    asr_base = 0.1 if agg == 'MartFL' else (0.3 if agg == 'FedAvg' else 0.4)\n",
    "                    if ds == 'CIFAR10':\n",
    "                        acc_base -= 0.1\n",
    "                        asr_base += 0.05\n",
    "                    dummy_data_list_full.append({\n",
    "                        'DATASET': ds, 'AGGREGATION_METHOD': agg, 'ATTACK_METHOD': YOUR_PRIMARY_BACKDOOR_ATTACK_NAME,\n",
    "                        'ADV_RATE': adv_rate_line, 'discovery_quality': FIXED_DISCOVERY_QUALITY_OVERVIEW,\n",
    "                        'buyer_data_mode': FIXED_BUYER_MODE_OVERVIEW, 'TRIGGER_RATE': FIXED_TRIGGER_RATE_OVERVIEW,\n",
    "                        'FINAL_MAIN_ACC': max(0, acc_base - adv_rate_line * (0.8 if agg != 'MartFL' else 0.4) + np.random.normal(0,0.02)),\n",
    "                        'FINAL_ASR': min(1, asr_base + adv_rate_line * (0.9 if agg != 'MartFL' else 0.5) + np.random.normal(0,0.03)),\n",
    "                        'AVG_ADVERSARY_SELECTION_RATE': min(1, (0.2 + adv_rate_line * 0.5 if agg == 'MartFL' else 0.5 + adv_rate_line*0.3) + np.random.normal(0,0.05))\n",
    "                    })\n",
    "            # Add 'No Attack' data for baseline\n",
    "            dummy_data_list_full.append({\n",
    "                'DATASET': ds, 'AGGREGATION_METHOD': agg, 'ATTACK_METHOD': 'No Attack',\n",
    "                'ADV_RATE': 0.0, 'discovery_quality': FIXED_DISCOVERY_QUALITY_OVERVIEW,\n",
    "                'buyer_data_mode': FIXED_BUYER_MODE_OVERVIEW, 'TRIGGER_RATE': 0.0, # Trigger rate usually 0 for no attack\n",
    "                'FINAL_MAIN_ACC': acc_base + 0.05 + np.random.normal(0,0.01), 'FINAL_ASR': 0.0,\n",
    "                'AVG_ADVERSARY_SELECTION_RATE': 0.0\n",
    "            })\n",
    "    summary_df_avg = pd.DataFrame(dummy_data_list_full)\n",
    "    summary_df_avg['FINAL_MAIN_ACC'] = summary_df_avg['FINAL_MAIN_ACC'].clip(0,1)\n",
    "    summary_df_avg['FINAL_ASR'] = summary_df_avg['FINAL_ASR'].clip(0,1)\n",
    "    summary_df_avg['AVG_ADVERSARY_SELECTION_RATE'] = summary_df_avg['AVG_ADVERSARY_SELECTION_RATE'].clip(0,1)\n",
    "else:\n",
    "    print(\"'summary_df_avg' DataFrame is available.\")\n",
    "\n",
    "# Dynamically get unique datasets and aggregation methods if not hardcoded\n",
    "DATASETS_TO_ANALYZE = sorted(summary_df_avg['DATASET'].unique())\n",
    "AGGREGATION_METHODS_TO_ANALYZE = sorted(summary_df_avg['AGGREGATION_METHOD'].unique())\n",
    "print(f\"Analyzing Datasets: {DATASETS_TO_ANALYZE}\")\n",
    "print(f\"Analyzing Aggregation Methods: {AGGREGATION_METHODS_TO_ANALYZE}\")\n",
    "\n",
    "\n",
    "# --- Helper function for grouping and averaging (reusable) ---\n",
    "def get_averaged_data_multi(df, group_by_cols, metrics_to_avg):\n",
    "    if df.empty: return pd.DataFrame(columns=group_by_cols + metrics_to_avg)\n",
    "    actual_metrics_to_avg = [m for m in metrics_to_avg if m in df.columns]\n",
    "    if not actual_metrics_to_avg: return pd.DataFrame(columns=group_by_cols + metrics_to_avg)\n",
    "    \n",
    "    # Store original dtypes for group_by_cols\n",
    "    original_dtypes = {col: df[col].dtype for col in group_by_cols if col in df.columns}\n",
    "\n",
    "    df_cleaned = df.dropna(subset=actual_metrics_to_avg, how='any').copy()\n",
    "    if df_cleaned.empty: return pd.DataFrame(columns=group_by_cols + metrics_to_avg)\n",
    "    \n",
    "    for metric in actual_metrics_to_avg: # Ensure metrics are numeric\n",
    "        df_cleaned[metric] = pd.to_numeric(df_cleaned[metric], errors='coerce')\n",
    "    df_cleaned.dropna(subset=actual_metrics_to_avg, how='any', inplace=True) # Drop if coerce made NaNs\n",
    "    \n",
    "    if df_cleaned.empty: return pd.DataFrame(columns=group_by_cols + metrics_to_avg)\n",
    "    \n",
    "    averaged_df = df_cleaned.groupby(group_by_cols, as_index=False, observed=True)[actual_metrics_to_avg].mean() # observed=True for categoricals\n",
    "\n",
    "    # Restore original dtypes for group_by_cols if they were changed by groupby\n",
    "    for col, dtype in original_dtypes.items():\n",
    "        if col in averaged_df.columns and averaged_df[col].dtype != dtype:\n",
    "            try:\n",
    "                averaged_df[col] = averaged_df[col].astype(dtype)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not restore dtype for {col}: {e}\")\n",
    "\n",
    "    return averaged_df\n",
    "\n",
    "\n",
    "# --- PLOT TYPE 1: Overview Bar Charts (ACC & ASR at fixed ADV_RATE) ---\n",
    "print(\"\\n--- Generating Overview Bar Charts ---\")\n",
    "metrics_for_bar = ['FINAL_MAIN_ACC', 'FINAL_ASR']\n",
    "\n",
    "# Filter data for these bar charts\n",
    "bar_chart_filter_conditions = (\n",
    "    (summary_df_avg['ATTACK_METHOD'] == YOUR_PRIMARY_BACKDOOR_ATTACK_NAME) &\n",
    "    (summary_df_avg['ADV_RATE'] == FIXED_ADV_RATE_FOR_OVERVIEW) &\n",
    "    (summary_df_avg['discovery_quality'] == FIXED_DISCOVERY_QUALITY_OVERVIEW) &\n",
    "    (summary_df_avg['buyer_data_mode'] == FIXED_BUYER_MODE_OVERVIEW) &\n",
    "    (summary_df_avg['TRIGGER_RATE'] == FIXED_TRIGGER_RATE_OVERVIEW) &\n",
    "    (summary_df_avg['DATASET'].isin(DATASETS_TO_ANALYZE)) &\n",
    "    (summary_df_avg['AGGREGATION_METHOD'].isin(AGGREGATION_METHODS_TO_ANALYZE))\n",
    ")\n",
    "df_for_bar_charts_raw = summary_df_avg[bar_chart_filter_conditions].copy()\n",
    "\n",
    "# Average over any remaining variations (e.g., seeds)\n",
    "df_for_bar_charts_avg = get_averaged_data_multi(\n",
    "    df_for_bar_charts_raw,\n",
    "    group_by_cols=['DATASET', 'AGGREGATION_METHOD'], # These are the primary groups for the bars\n",
    "    metrics_to_avg=metrics_for_bar\n",
    ")\n",
    "\n",
    "if not df_for_bar_charts_avg.empty:\n",
    "    for metric in metrics_for_bar:\n",
    "        if metric not in df_for_bar_charts_avg.columns:\n",
    "            print(f\"Metric {metric} not found in averaged data for bar charts. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        plt.figure(figsize=(7 + 0.7 * len(AGGREGATION_METHODS_TO_ANALYZE), 5)) # Adjust width\n",
    "        sns.barplot(\n",
    "            x='DATASET',\n",
    "            y=metric,\n",
    "            hue='AGGREGATION_METHOD',\n",
    "            data=df_for_bar_charts_avg,\n",
    "            palette='muted',\n",
    "            hue_order=AGGREGATION_METHODS_TO_ANALYZE # Ensure consistent legend order\n",
    "        )\n",
    "        plt.title(f'{metric.replace(\"_\", \" \")} across Datasets & Aggregators\\n(Adv. Rate={FIXED_ADV_RATE_FOR_OVERVIEW}, Trigger Rate={FIXED_TRIGGER_RATE_OVERVIEW})', fontsize=13)\n",
    "        plt.ylabel(metric.replace(\"_\", \" \"))\n",
    "        plt.xlabel('Dataset')\n",
    "        plt.xticks(rotation=0, ha='center')\n",
    "        plt.legend(title='Aggregation Method', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        plt.ylim(0, 1.05 if 'ACC' in metric or 'ASR' in metric else None)\n",
    "        plt.grid(axis='y', linestyle=':', linewidth=0.7)\n",
    "        plt.tight_layout(rect=[0, 0, 0.85 if len(AGGREGATION_METHODS_TO_ANALYZE) > 3 else 1, 0.95]) # Adjust for legend\n",
    "\n",
    "        filename_bar = f\"{BASE_SAVE_DIR_FULL_ANALYSIS}overview_bar_{metric}_adv{FIXED_ADV_RATE_FOR_OVERVIEW}_trig{FIXED_TRIGGER_RATE_OVERVIEW}.pdf\"\n",
    "        try:\n",
    "            plt.savefig(filename_bar, bbox_inches='tight', dpi=300)\n",
    "            print(f\"Saved bar chart: {filename_bar}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving bar chart {filename_bar}: {e}\")\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Warning: No data available for overview bar charts after filtering and averaging.\")\n",
    "\n",
    "\n",
    "# --- PLOT TYPE 2: Line Plots (Sensitivity to ADV_RATE) ---\n",
    "print(\"\\n--- Generating Line Plots (Sensitivity to ADV_RATE) ---\")\n",
    "metrics_for_line = ['FINAL_MAIN_ACC', 'FINAL_ASR', 'AVG_ADVERSARY_SELECTION_RATE']\n",
    "\n",
    "# Filter data for these line plots (fixed DQ, BuyerMode, TriggerRate)\n",
    "line_plot_filter_conditions = (\n",
    "    # ATTACK_METHOD can be Backdoor or No Attack (for baseline)\n",
    "    (summary_df_avg['ATTACK_METHOD'].isin([YOUR_PRIMARY_BACKDOOR_ATTACK_NAME, 'No Attack'])) &\n",
    "    (summary_df_avg['discovery_quality'] == FIXED_DISCOVERY_QUALITY_OVERVIEW) &\n",
    "    (summary_df_avg['buyer_data_mode'] == FIXED_BUYER_MODE_OVERVIEW) &\n",
    "    # For 'No Attack', TRIGGER_RATE is often 0. For attacks, it's your fixed value.\n",
    "    ( (summary_df_avg['ATTACK_METHOD'] == 'No Attack') & (summary_df_avg['TRIGGER_RATE'] == 0.0) |\n",
    "      (summary_df_avg['ATTACK_METHOD'] == YOUR_PRIMARY_BACKDOOR_ATTACK_NAME) & (summary_df_avg['TRIGGER_RATE'] == FIXED_TRIGGER_RATE_OVERVIEW) ) &\n",
    "    (summary_df_avg['DATASET'].isin(DATASETS_TO_ANALYZE)) &\n",
    "    (summary_df_avg['AGGREGATION_METHOD'].isin(AGGREGATION_METHODS_TO_ANALYZE)) &\n",
    "    ( # ADV_RATE conditions: 0.0 for No Attack, or in ADV_RATES_X_AXIS for active attacks\n",
    "        (summary_df_avg['ATTACK_METHOD'] == 'No Attack' ) & (summary_df_avg['ADV_RATE'] == 0.0) |\n",
    "        (summary_df_avg['ATTACK_METHOD'] == YOUR_PRIMARY_BACKDOOR_ATTACK_NAME ) & (summary_df_avg['ADV_RATE'].isin(ADV_RATES_X_AXIS))\n",
    "    )\n",
    ")\n",
    "df_for_line_plots_raw = summary_df_avg[line_plot_filter_conditions].copy()\n",
    "\n",
    "# Average over any remaining variations (e.g., seeds)\n",
    "df_for_line_plots_avg = get_averaged_data_multi(\n",
    "    df_for_line_plots_raw,\n",
    "    group_by_cols=['DATASET', 'AGGREGATION_METHOD', 'ATTACK_METHOD', 'ADV_RATE'],\n",
    "    metrics_to_avg=metrics_for_line\n",
    ")\n",
    "\n",
    "if not df_for_line_plots_avg.empty:\n",
    "    for dataset in DATASETS_TO_ANALYZE:\n",
    "        df_dataset_lines = df_for_line_plots_avg[df_for_line_plots_avg['DATASET'] == dataset]\n",
    "        if df_dataset_lines.empty:\n",
    "            print(f\"No data for line plots for dataset: {dataset}\")\n",
    "            continue\n",
    "\n",
    "        for metric in metrics_for_line:\n",
    "            if metric not in df_dataset_lines.columns:\n",
    "                print(f\"Metric {metric} not found for line plots for dataset: {dataset}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            plt.figure(figsize=(8, 5.5))\n",
    "            \n",
    "            # Use a good color palette for aggregators\n",
    "            line_palette = sns.color_palette(\"tab10\", n_colors=len(AGGREGATION_METHODS_TO_ANALYZE))\n",
    "            agg_color_map = {agg: line_palette[i] for i, agg in enumerate(AGGREGATION_METHODS_TO_ANALYZE)}\n",
    "\n",
    "            # Plot 'No Attack' baseline first if present (as points)\n",
    "            df_no_attack_baseline = df_dataset_lines[\n",
    "                (df_dataset_lines['ATTACK_METHOD'] == 'No Attack') &\n",
    "                (df_dataset_lines['ADV_RATE'] == 0.0)\n",
    "            ]\n",
    "            if not df_no_attack_baseline.empty:\n",
    "                for agg_method in AGGREGATION_METHODS_TO_ANALYZE:\n",
    "                    data_no_attack_agg = df_no_attack_baseline[df_no_attack_baseline['AGGREGATION_METHOD'] == agg_method]\n",
    "                    if not data_no_attack_agg.empty and metric in data_no_attack_agg.columns:\n",
    "                        plt.scatter(\n",
    "                            data_no_attack_agg['ADV_RATE'], data_no_attack_agg[metric],\n",
    "                            color=agg_color_map.get(agg_method, 'gray'), marker='X', s=100, zorder=5,\n",
    "                            label=f'{agg_method} (No Attack)' if metric == 'FINAL_MAIN_ACC' else None # Avoid duplicate legend for ASR/SelRate\n",
    "                        )\n",
    "            \n",
    "            # Plot lines for active attack\n",
    "            df_active_attack_lines = df_dataset_lines[df_dataset_lines['ATTACK_METHOD'] == YOUR_PRIMARY_BACKDOOR_ATTACK_NAME]\n",
    "            if not df_active_attack_lines.empty:\n",
    "                sns.lineplot(\n",
    "                    x='ADV_RATE',\n",
    "                    y=metric,\n",
    "                    hue='AGGREGATION_METHOD',\n",
    "                    hue_order=AGGREGATION_METHODS_TO_ANALYZE, # Consistent legend\n",
    "                    style='AGGREGATION_METHOD', # Different linestyles\n",
    "                    style_order=AGGREGATION_METHODS_TO_ANALYZE,\n",
    "                    markers=True, # Add markers\n",
    "                    data=df_active_attack_lines,\n",
    "                    palette=agg_color_map,\n",
    "                    errorbar=None # Data is already averaged\n",
    "                )\n",
    "\n",
    "            plt.title(f'{metric.replace(\"_\", \" \")} vs. Adversary Rate on {dataset}\\n(DQ={FIXED_DISCOVERY_QUALITY_OVERVIEW}, Buyer={FIXED_BUYER_MODE_OVERVIEW.capitalize()}, Trigger={FIXED_TRIGGER_RATE_OVERVIEW})', fontsize=13)\n",
    "            plt.xlabel('Adversary Rate')\n",
    "            plt.ylabel(metric.replace(\"_\", \" \"))\n",
    "            plt.ylim(0, 1.05 if 'ACC' in metric or 'ASR' in metric or 'RATE' in metric else None)\n",
    "            plt.xticks(ADV_RATES_X_AXIS + [0.0] if 0.0 not in ADV_RATES_X_AXIS else ADV_RATES_X_AXIS) # Ensure 0.0 is a tick\n",
    "            plt.grid(True, linestyle=':', linewidth=0.7)\n",
    "\n",
    "            # Consolidate legend if No Attack points were plotted\n",
    "            handles, labels = plt.gca().get_legend_handles_labels()\n",
    "            # Remove \"AGGREGATION_METHOD\" title from legend if seaborn adds it\n",
    "            if labels and labels[0] == 'AGGREGATION_METHOD':\n",
    "                handles = handles[1:]\n",
    "                labels = labels[1:]\n",
    "            \n",
    "            # Create a cleaner legend if No Attack points were plotted\n",
    "            # This is a bit complex to get perfect, seaborn sometimes makes it tricky with scatter + line\n",
    "            unique_labels = {}\n",
    "            final_handles = []\n",
    "            final_labels = []\n",
    "            for handle, label in zip(handles, labels):\n",
    "                if label not in unique_labels:\n",
    "                    unique_labels[label] = handle\n",
    "                    final_handles.append(handle)\n",
    "                    final_labels.append(label)\n",
    "\n",
    "            if final_handles:\n",
    "                 plt.legend(handles=final_handles, labels=final_labels, title='Aggregation Method', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0, 0.83 if len(AGGREGATION_METHODS_TO_ANALYZE)>2 else 1, 0.95])\n",
    "\n",
    "            filename_line = f\"{BASE_SAVE_DIR_FULL_ANALYSIS}{dataset}_line_{metric}_vs_adv_rate_trig{FIXED_TRIGGER_RATE_OVERVIEW}.pdf\"\n",
    "            try:\n",
    "                plt.savefig(filename_line, bbox_inches='tight', dpi=300)\n",
    "                print(f\"Saved line plot: {filename_line}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving line plot {filename_line}: {e}\")\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"Warning: No data available for line plots after filtering and averaging.\")\n",
    "\n",
    "print(\"\\n--- Full Analysis Plot Generation Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
